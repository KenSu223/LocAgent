{"instance_id": "scikit-learn__scikit-learn-25525", "file_changes": [{"file": "examples/feature_selection/plot_select_from_model_diabetes.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "559609fe98ec2145788133687e64a6e87766bc77", "problem_statement": "Extend SequentialFeatureSelector example to demonstrate how to use negative tol\n\n### Describe the bug\r\n\r\nI utilized the **SequentialFeatureSelector** for feature selection in my code, with the direction set to \"backward.\" The tolerance value is negative and the selection process stops when the decrease in the metric, AUC in this case, is less than the specified tolerance. Generally, increasing the number of features results in a higher AUC, but sacrificing some features, especially correlated ones that offer little contribution, can produce a pessimistic model with a lower AUC. The code worked as expected in **sklearn 1.1.1**, but when I updated to **sklearn 1.2.1**, I encountered the following error.\r\n\r\n### Steps/Code to Reproduce\r\n\r\n```python\r\nfrom sklearn.datasets import load_breast_cancer\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.feature_selection import SequentialFeatureSelector\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.pipeline import Pipeline\r\n\r\nX, y = load_breast_cancer(return_X_y=True)\r\n\r\nTOL = -0.001\r\nfeature_selector = SequentialFeatureSelector(\r\n                    LogisticRegression(max_iter=1000),\r\n                    n_features_to_select=\"auto\",\r\n                    direction=\"backward\",\r\n                    scoring=\"roc_auc\",\r\n                    tol=TOL\r\n                )\r\n\r\n\r\npipe = Pipeline(\r\n    [('scaler', StandardScaler()), \r\n    ('feature_selector', feature_selector), \r\n    ('log_reg', LogisticRegression(max_iter=1000))]\r\n    )\r\n\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    pipe.fit(X, y)\r\n    print(pipe['log_reg'].coef_[0])\r\n\r\n```\r\n\r\n### Expected Results\r\n\r\n```\r\n$ python sfs_tol.py \r\n[-2.0429818   0.5364346  -1.35765488 -2.85009904 -2.84603016]\r\n```\r\n\r\n### Actual Results\r\n\r\n```python-traceback\r\n$ python sfs_tol.py \r\nTraceback (most recent call last):\r\n  File \"/home/modelling/users-workspace/nsofinij/lab/open-source/sfs_tol.py\", line 28, in <module>\r\n    pipe.fit(X, y)\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/pipeline.py\", line 401, in fit\r\n    Xt = self._fit(X, y, **fit_params_steps)\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/pipeline.py\", line 359, in _fit\r\n    X, fitted_transformer = fit_transform_one_cached(\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\r\n    return self.func(*args, **kwargs)\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\r\n    res = transformer.fit_transform(X, y, **fit_params)\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\r\n    data_to_wrap = f(self, X, *args, **kwargs)\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/base.py\", line 862, in fit_transform\r\n    return self.fit(X, y, **fit_params).transform(X)\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/feature_selection/_sequential.py\", line 201, in fit\r\n    self._validate_params()\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/base.py\", line 581, in _validate_params\r\n    validate_parameter_constraints(\r\n  File \"/home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\r\n    raise InvalidParameterError(\r\nsklearn.utils._param_validation.InvalidParameterError: The 'tol' parameter of SequentialFeatureSelector must be None or a float in the range (0, inf). Got -0.001 instead.\r\n\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\nSystem:\r\n    python: 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]\r\nexecutable: /home/modelling/opt/anaconda3/envs/py310/bin/python\r\n   machine: Linux-4.14.301-224.520.amzn2.x86_64-x86_64-with-glibc2.26\r\n\r\nPython dependencies:\r\n      sklearn: 1.2.1\r\n          pip: 23.0\r\n   setuptools: 66.1.1\r\n        numpy: 1.24.1\r\n        scipy: 1.10.0\r\n       Cython: None\r\n       pandas: 1.5.3\r\n   matplotlib: 3.6.3\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       user_api: openmp\r\n   internal_api: openmp\r\n         prefix: libgomp\r\n       filepath: /home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/scikit_learn.libs/libgomp-a34b3233.so.1.0.0\r\n        version: None\r\n    num_threads: 64\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so\r\n        version: 0.3.21\r\nthreading_layer: pthreads\r\n   architecture: SkylakeX\r\n    num_threads: 64\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /home/modelling/opt/anaconda3/envs/py310/lib/python3.10/site-packages/scipy.libs/libopenblasp-r0-41284840.3.18.so\r\n        version: 0.3.18\r\nthreading_layer: pthreads\r\n   architecture: SkylakeX\r\n    num_threads: 64\r\n```", "patch": ""}
{"instance_id": "pallets__flask-2264", "file_changes": [{"file": "flask/cli.py", "changes": {"edited_modules": ["flask/cli.py:find_best_app", "flask/cli.py:call_factory", "flask/cli.py:locate_app"], "edited_entities": ["flask/cli.py:find_best_app", "flask/cli.py:call_factory", "flask/cli.py:locate_app"]}}, {"file": "tests/test_cli.py", "changes": {"edited_modules": ["tests/test_cli.py:test_locate_app"], "edited_entities": ["tests/test_cli.py:test_locate_app"]}}], "repo": "pallets/flask", "base_commit": "cb94f4c5d3d4e1797207fd03d20d06c7bc0d05b4", "problem_statement": "Handle app factory in FLASK_APP\n\n`FLASK_APP=myproject.app:create_app('dev')`\r\n[\r\nGunicorn does this with `eval`](https://github.com/benoitc/gunicorn/blob/fbd151e9841e2c87a18512d71475bcff863a5171/gunicorn/util.py#L364), which I'm not super happy with. Instead, we could use `literal_eval` to allow a simple list of arguments. The line should never be so complicated that `eval` would be necessary anyway.\r\n\r\n~~~python\r\n# might need to fix this regex\r\nm = re.search(r'(\\w+)(\\(.*\\))', app_obj)\r\n\r\nif m:\r\n    app = getattr(mod, m.group(1))(*literal_eval(m.group(2)))\r\n~~~", "patch": ""}
{"instance_id": "huggingface__transformers-30", "file_changes": [{"file": "src/transformers/modeling_utils.py", "changes": {"edited_modules": ["src/transformers/modeling_utils.py:PreTrainedModel", "src/transformers/modeling_utils.py:load_state_dict"], "edited_entities": ["src/transformers/modeling_utils.py:PreTrainedModel.from_pretrained", "src/transformers/modeling_utils.py:load_state_dict", "src/transformers/modeling_utils.py:PreTrainedModel._load_pretrained_model"]}}, {"file": "src/transformers/trainer.py", "changes": {"edited_modules": ["src/transformers/trainer.py:Trainer"], "edited_entities": ["src/transformers/trainer.py:Trainer.__init__", "src/transformers/trainer.py:Trainer._wrap_model", "src/transformers/trainer.py:Trainer.train", "src/transformers/trainer.py:Trainer._inner_training_loop", "src/transformers/trainer.py:Trainer.create_accelerator_and_postprocess"]}}, {"file": "src/transformers/training_args.py", "changes": {"edited_modules": ["src/transformers/training_args.py:TrainingArguments"], "edited_entities": ["src/transformers/training_args.py:TrainingArguments", "src/transformers/training_args.py:TrainingArguments.__post_init__"]}}], "repo": "huggingface/transformers", "base_commit": "d2871b29754abd0f72cf42c299bb1c041519f7bc", "problem_statement": "[Feature request] Add example of finetuning the pretrained models on custom corpus", "patch": ""}
{"instance_id": "pandas-dev__pandas-11080", "file_changes": [{"file": "asv_bench/benchmarks/frame_methods.py", "changes": {}}, {"file": "doc/source/whatsnew/v0.17.1.txt", "changes": {}}, {"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame.sort_index"]}}], "repo": "pandas-dev/pandas", "base_commit": "51a70dcb7133bc7cb8e6bea5da39a2cf58fa8319", "problem_statement": "PERF: checking is_monotonic_increasing/decreasing before sorting on an index\n\nWe don't keep the sortedness state in an index per-se, but it is rather cheap to check\n- `is_monotonic_increasing` or `is_monotonic_decreasing` on a reg-index \n- MultiIndex should check `is_lexsorted` (this might be done already)\n\n```\nIn [8]: df = DataFrame(np.random.randn(1000000,2),columns=list('AB'))\n\nIn [9]: %timeit df.sort_index()\n10 loops, best of 3: 37.1 ms per loop\n\nIn [10]: %timeit -n 1 -r 1 df.index.is_monotonic_increasing\n1 loops, best of 1: 2.01 ms per loop\n\nIn [11]: %timeit -n 1 -r 1 df.index.is_monotonic_increasin^C\nKeyboardInterrupt\n\nIn [11]: %timeit df.set_index('A').sort_index()\n10 loops, best of 3: 175 ms per loop\n\nIn [12]: %timeit -n 1 -r 1 df.set_index('A').index.is_monotonic_increasing\n1 loops, best of 1: 9.54 ms per loop\n```", "patch": ""}
{"instance_id": "huggingface__transformers-9", "file_changes": [{"file": "tests/big_bird/test_modeling_big_bird.py", "changes": {"edited_modules": ["tests/big_bird/test_modeling_big_bird.py:BigBirdModelTester", "tests/big_bird/test_modeling_big_bird.py:BigBirdModelTest"], "edited_entities": ["tests/big_bird/test_modeling_big_bird.py:BigBirdModelTester.__init__", "tests/big_bird/test_modeling_big_bird.py:BigBirdModelTest.test_fast_integration"]}}], "repo": "huggingface/transformers", "base_commit": "9fef668338b15e508bac99598dd139546fece00b", "problem_statement": "Crash at the end of training\n\nHi, I tried running the Squad model this morning (on a single GPU with gradient accumulation over 3 steps) but after 3 hours of training, my job failed with the following output:\r\n\r\nI was running the code, unmodified, from commit 3bfbc21376af691b912f3b6256bbeaf8e0046ba8\r\n\r\nIs this an issue you know about?\r\n```\r\n11/08/2018 17:50:03 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\r\n11/08/2018 17:50:18 - INFO - __main__ -   *** Example ***\r\n11/08/2018 17:50:18 - INFO - __main__ -   unique_id: 1000000000\r\n11/08/2018 17:50:18 - INFO - __main__ -   example_index: 0\r\n11/08/2018 17:50:18 - INFO - __main__ -   doc_span_index: 0\r\n11/08/2018 17:50:18 - INFO - __main__ -   tokens: [CLS] to whom did the virgin mary allegedly appear in 1858 in lou ##rdes france ? [SEP] architectural ##ly , the school has a catholic character . atop the main building ' s gold dome is a golden statue of the virgin mary . immediately in front of the main building and facing it , is a copper statue of christ with arms up ##rai ##sed with the legend \" ve ##ni ##te ad me om ##nes \" . next to the main building is the basilica of the sacred heart . immediately behind the basilica is the gr ##otto , a marian place of prayer and reflection . it is a replica of the gr ##otto at lou ##rdes , france where the virgin mary reputed ##ly appeared to saint bern ##ade ##tte so ##ub ##iro ##us in 1858 . at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ) , is a simple , modern stone statue of mary . [SEP]\r\n11/08/2018 17:50:18 - INFO - __main__ -   token_to_orig_map: 17:0 18:0 19:0 20:1 21:2 22:3 23:4 24:5 25:6 26:6 27:7 28:8 29:9 30:10 31:10 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:20 44:21 45:22 46:23 47:24 48:25 49:26 50:27 51:28 52:29 53:30 54:30 55:31 56:32 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:39 65:39 66:40 67:41 68:42 69:43 70:43 71:43 72:43 73:44 74:45 75:46 76:46 77:46 78:46 79:47 80:48 81:49 82:50 83:51 84:52 85:53 86:54 87:55 88:56 89:57 90:58 91:58 92:59 93:60 94:61 95:62 96:63 97:64 98:65 99:65 100:65 101:66 102:67 103:68 104:69 105:70 106:71 107:72 108:72 109:73 110:74 111:75 112:76 113:77 114:78 115:79 116:79 117:80 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:86 126:87 127:87 128:88 129:89 130:90 131:91 132:91 133:91 134:92 135:92 136:92 137:92 138:93 139:94 140:94 141:95 142:96 143:97 144:98 145:99 146:100 147:101 148:102 149:102 150:103 151:104 152:105 153:106 154:107 155:108 156:109 157:110 158:111 159:112 160:113 161:114 162:115 163:115 164:115 165:116 166:117 167:118 168:118 169:119 170:120 171:121 172:122 173:123 174:123\r\n11/08/2018 17:50:18 - INFO - __main__ -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True\r\n11/08/2018 17:50:18 - INFO - __main__ -   input_ids: 101 2000 3183 2106 1996 6261 2984 9382 3711 1999 8517 1999 10223 26371 2605 1029 102 6549 2135 1010 1996 2082 2038 1037 3234 2839 1012 10234 1996 2364 2311 1005 1055 2751 8514 2003 1037 3585 6231 1997 1996 6261 2984 1012 3202 1999 2392 1997 1996 2364 2311 1998 5307 2009 1010 2003 1037 6967 6231 1997 4828 2007 2608 2039 14995 6924 2007 1996 5722 1000 2310 3490 2618 4748 2033 18168 5267 1000 1012 2279 2000 1996 2364 2311 2003 1996 13546 1997 1996 6730 2540 1012 3202 2369 1996 13546 2003 1996 24665 23052 1010 1037 14042 2173 1997 7083 1998 9185 1012 2009 2003 1037 15059 1997 1996 24665 23052 2012 10223 26371 1010 2605 2073 1996 6261 2984 22353 2135 2596 2000 3002 16595 9648 4674 2061 12083 9711 2271 1999 8517 1012 2012 1996 2203 1997 1996 2364 3298 1006 1998 1999 1037 3622 2240 2008 8539 2083 1017 11342 1998 1996 2751 8514 1007 1010 2003 1037 3722 1010 2715 2962 6231 1997 2984 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n11/08/2018 17:50:18 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n\r\n... [truncated] ...\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29314/29324 [3:27:55<00:04,  2.36it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29315/29324 [3:27:55<00:03,  2.44it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29316/29324 [3:27:56<00:03,  2.26it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29317/29324 [3:27:56<00:02,  2.35it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29318/29324 [3:27:56<00:02,  2.44it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29319/29324 [3:27:57<00:02,  2.25it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29320/29324 [3:27:57<00:01,  2.35it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29321/29324 [3:27:58<00:01,  2.41it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29322/29324 [3:27:58<00:00,  2.25it/s]\u001b[A\r\n\r\nIteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29323/29324 [3:27:59<00:00,  2.36it/s]\u001b[ATraceback (most recent call last):\r\n  File \"code/run_squad.py\", line 929, in <module>\r\n    main()\r\n  File \"code/run_squad.py\", line 862, in main\r\n    loss = model(input_ids, segment_ids, input_mask, start_positions, end_positions)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/0x0d4ff90d01fa4168983197b17d73bb0c_dependencies/code/modeling.py\", line 467, in forward\r\n    start_loss = loss_fct(start_logits, start_positions)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\", line 862, in forward\r\n    ignore_index=self.ignore_index, reduction=self.reduction)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1550, in cross_entropy\r\n    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1403, in nll_loss\r\n    if input.size(0) != target.size(0):\r\nRuntimeError: dimension specified as 0 but tensor has no dimensions\r\n\r\nException ignored in: <bound method tqdm.__del__ of Iteration: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 29323/29324 [3:27:59<00:00,  2.36it/s]>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 931, in __del__\r\n    self.close()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 1133, in close\r\n    self._decr_instances(self)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 496, in _decr_instances\r\n    cls.monitor.exit()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py\", line 52, in exit\r\n    self.join()\r\n  File \"/usr/lib/python3.6/threading.py\", line 1053, in join\r\n    raise RuntimeError(\"cannot join current thread\")\r\nRuntimeError: cannot join current thread\r\n```", "patch": ""}
{"instance_id": "psf__requests-3698", "file_changes": [{"file": "requests/models.py", "changes": {"edited_modules": ["requests/models.py:Response"], "edited_entities": ["requests/models.py:Response.content"]}}, {"file": "tests/test_requests.py", "changes": {"edited_modules": ["tests/test_requests.py:TestRequests"], "edited_entities": ["tests/test_requests.py:TestRequests"]}}], "repo": "psf/requests", "base_commit": "ccabcf1fca906bfa6b65a3189c1c41061e6c1042", "problem_statement": "AttributeError: 'NoneType' object has no attribute 'read'\n\nHello :)\r\n\r\nAfter a recent upgrade for our [coala](https://github.com/coala/coala) project to `requests` 2.12.1 we encounter an exception in our test suites which seems to be caused by `requests`.\r\n\r\nBuild: https://ci.appveyor.com/project/coala/coala-bears/build/1.0.3537/job/1wm7b4u9yhgkxkgn\r\n\r\nRelevant part:\r\n```\r\n================================== FAILURES ===================================\r\n_________________ InvalidLinkBearTest.test_redirect_threshold _________________\r\nself = <tests.general.InvalidLinkBearTest.InvalidLinkBearTest testMethod=test_redirect_threshold>\r\n    def test_redirect_threshold(self):\r\n    \r\n        long_url_redirect = \"\"\"\r\n            https://bitbucket.org/api/301\r\n            https://bitbucket.org/api/302\r\n            \"\"\".splitlines()\r\n    \r\n        short_url_redirect = \"\"\"\r\n            http://httpbin.org/status/301\r\n            \"\"\".splitlines()\r\n    \r\n        self.assertResult(valid_file=long_url_redirect,\r\n                          invalid_file=short_url_redirect,\r\n>                         settings={'follow_redirects': 'yeah'})\r\ntests\\general\\InvalidLinkBearTest.py:157: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\ntests\\general\\InvalidLinkBearTest.py:75: in assertResult\r\n    out = list(uut.run(\"valid\", valid_file, **settings))\r\nbears\\general\\InvalidLinkBear.py:80: in run\r\n    file, timeout, link_ignore_regex):\r\nbears\\general\\InvalidLinkBear.py:53: in find_links_in_file\r\n    code = InvalidLinkBear.get_status_code(link, timeout)\r\nbears\\general\\InvalidLinkBear.py:37: in get_status_code\r\n    timeout=timeout).status_code\r\nC:\\Python34\\lib\\site-packages\\requests\\api.py:96: in head\r\n    return request('head', url, **kwargs)\r\nC:\\Python34\\lib\\site-packages\\requests\\api.py:56: in request\r\n    return session.request(method=method, url=url, **kwargs)\r\nC:\\Python34\\lib\\site-packages\\requests\\sessions.py:488: in request\r\n    resp = self.send(prep, **send_kwargs)\r\nC:\\Python34\\lib\\site-packages\\requests_mock\\mocker.py:69: in _fake_send\r\n    return self._real_send(session, request, **kwargs)\r\nC:\\Python34\\lib\\site-packages\\requests\\sessions.py:641: in send\r\n    r.content\r\nC:\\Python34\\lib\\site-packages\\requests\\models.py:772: in content\r\n    self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n    def generate():\r\n        # Special case for urllib3.\r\n        if hasattr(self.raw, 'stream'):\r\n            try:\r\n                for chunk in self.raw.stream(chunk_size, decode_content=True):\r\n                    yield chunk\r\n            except ProtocolError as e:\r\n                raise ChunkedEncodingError(e)\r\n            except DecodeError as e:\r\n                raise ContentDecodingError(e)\r\n            except ReadTimeoutError as e:\r\n                raise ConnectionError(e)\r\n        else:\r\n            # Standard file-like object.\r\n            while True:\r\n>               chunk = self.raw.read(chunk_size)\r\nE               AttributeError: 'NoneType' object has no attribute 'read'\r\nC:\\Python34\\lib\\site-packages\\requests\\models.py:705: AttributeError\r\n```\r\nhappens on Windows and Linux.\r\n\r\nThanks in advance :)", "patch": ""}
{"instance_id": "pallets__flask-593", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "docs/blueprints.rst", "changes": {}}, {"file": "src/flask/app.py", "changes": {"edited_modules": ["src/flask/app.py:Flask"], "edited_entities": ["src/flask/app.py:Flask.__call__", "src/flask/app.py:Flask.update_template_context", "src/flask/app.py:Flask.register_blueprint", "src/flask/app.py:Flask._find_error_handler", "src/flask/app.py:Flask.preprocess_request", "src/flask/app.py:Flask.process_response", "src/flask/app.py:Flask.do_teardown_request"]}}, {"file": "src/flask/blueprints.py", "changes": {"edited_modules": ["src/flask/blueprints.py:BlueprintSetupState", "src/flask/blueprints.py:Blueprint"], "edited_entities": ["src/flask/blueprints.py:BlueprintSetupState.__init__", "src/flask/blueprints.py:Blueprint.__init__", "src/flask/blueprints.py:Blueprint.register", "src/flask/blueprints.py:BlueprintSetupState.add_url_rule", "src/flask/blueprints.py:Blueprint"]}}, {"file": "tests/test_blueprints.py", "changes": {"edited_modules": ["tests/test_blueprints.py:test_app_url_processors"], "edited_entities": ["tests/test_blueprints.py:test_app_url_processors"]}}], "repo": "pallets/flask", "base_commit": "85dce2c836fe03aefc07b7f4e0aec575e170f1cd", "problem_statement": "Nestable blueprints\n\nI'd like to be able to register \"sub-blueprints\" using `Blueprint.register_blueprint(*args, **kwargs)`. This would register the nested blueprints with an app when the \"parent\" is registered with it. All parameters are preserved, other than `url_prefix`, which is handled similarly to in `add_url_rule`. A na\u00edve implementation could look like this:\n\n``` python\nclass Blueprint(object):\n    ...\n\n    def register_blueprint(self, blueprint, **options):\n        def deferred(state):\n            url_prefix = options.get('url_prefix')\n            if url_prefix is None:\n                url_prefix = blueprint.url_prefix\n            if 'url_prefix' in options:\n                del options['url_prefix']\n\n            state.app.register_blueprint(blueprint, url_prefix, **options)\n        self.record(deferred)\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-26948", "file_changes": [{"file": "doc/install.rst", "changes": {}}, {"file": "doc/themes/scikit-learn-modern/static/css/theme.css", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "96b5814de70ad2435b6db5f49b607b136921f701", "problem_statement": "The copy button on install copies an extensive comman including env activation\n\n### Describe the issue linked to the documentation\n\nhttps://scikit-learn.org/stable/install.html\r\n\r\nAbove link will lead you to the sklearn downlanding for link . \r\nwhen you link copy link button it will copy \r\n`python3 -m venv sklearn-venvpython -m venv sklearn-venvpython -m venv sklearn-venvsource sklearn-venv/bin/activatesource sklearn-venv/bin/activatesklearn-venv\\Scripts\\activatepip install -U scikit-learnpip install -U scikit-learnpip install -U scikit-learnpip3 install -U scikit-learnconda create -n sklearn-env -c conda-forge scikit-learnconda activate sklearn-env`\r\n\r\ninstead of  `pip3 install -U scikit-learn`\r\n\r\nif this is the issue so please issue i want to create a pull request for it and tell in which file this issue reside\r\nThanks\n\n### Suggest a potential alternative/fix\n\nBy resoving above issue", "patch": ""}
{"instance_id": "psf__requests-2654", "file_changes": [{"file": "requests/utils.py", "changes": {"edited_modules": ["requests/utils.py:get_netrc_auth"], "edited_entities": ["requests/utils.py:get_netrc_auth"]}}], "repo": "psf/requests", "base_commit": "f5dacf84468ab7e0631cc61a3f1431a32e3e143c", "problem_statement": "utils.get_netrc_auth silently fails when netrc exists but fails to parse\n\nMy .netrc contains a line for the github auth, [like this](https://gist.github.com/wikimatze/9790374).\n\nIt turns out that `netrc.netrc()` doesn't like that:\n\n```\n>>> from netrc import netrc\n>>> netrc()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/netrc.py\", line 35, in __init__\n    self._parse(file, fp, default_netrc)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/netrc.py\", line 117, in _parse\n    file, lexer.lineno)\nnetrc.NetrcParseError: bad follower token 'protocol' (/Users/david/.netrc, line 9)\n```\n\n`get_netrc_auth` catches the `NetrcParseError` [but just ignores it](https://github.com/kennethreitz/requests/blob/master/requests/utils.py#L106).\n\nAt least having it emit a warning would have saved some hair-pulling.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-26590", "file_changes": [{"file": "doc/whats_new/v1.3.rst", "changes": {}}, {"file": "sklearn/impute/_knn.py", "changes": {"edited_modules": ["sklearn/impute/_knn.py:KNNImputer"], "edited_entities": ["sklearn/impute/_knn.py:KNNImputer.transform"]}}, {"file": "sklearn/impute/tests/test_common.py", "changes": {"edited_modules": ["sklearn/impute/tests/test_common.py:test_keep_empty_features"], "edited_entities": ["sklearn/impute/tests/test_common.py:test_keep_empty_features"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "e04b8e70e60df88751af5cd667cafb66dc32b397", "problem_statement": "KNNImputer add_indicator fails to persist where missing data had been present in training\n\n### Describe the bug\r\n\r\nHello, I've encountered an issue where the KNNImputer fails to record the fields where there were missing data at the time when `.fit` is called, but not recognised if `.transform` is called on a dense matrix. I would have expected it to return a 2x3 matrix rather than 2x2, with `missingindicator_A = False` for all cases.\r\n\r\nReproduction steps below. Any help much appreciated :)\r\n\r\n### Steps/Code to Reproduce\r\n\r\n```python\r\n>>> import pandas as pd\r\n>>> from sklearn.impute import KNNImputer\r\n>>> knn = KNNImputer(add_indicator=True)\r\n>>> df = pd.DataFrame({'A': [0, None], 'B': [1, 2]})\r\n>>> df\r\n     A  B\r\n0  0.0  1\r\n1  NaN  2\r\n>>> knn.fit(df)\r\nKNNImputer(add_indicator=True)\r\n>>> pd.DataFrame(knn.transform(df), columns=knn.get_feature_names_out())\r\n     A    B  missingindicator_A\r\n0  0.0  1.0                 0.0\r\n1  0.0  2.0                 1.0\r\n>>> df['A'] = 0\r\n>>> pd.DataFrame(knn.transform(df), columns=knn.get_feature_names_out())\r\n```\r\n\r\n### Expected Results\r\n\r\n```\r\n     A    B  missingindicator_A\r\n0  0.0  1.0                 0.0\r\n1  0.0  2.0                 0.0\r\n```\r\n\r\n### Actual Results\r\n\r\n```pytb\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[30], line 1\r\n----> 1 pd.DataFrame(knn.transform(df), columns=knn.get_feature_names_out())\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:694, in DataFrame.__init__(self, data, index, columns, dtype, copy)\r\n    684         mgr = dict_to_mgr(\r\n    685             # error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\r\n    686             # attribute \"name\"\r\n   (...)\r\n    691             typ=manager,\r\n    692         )\r\n    693     else:\r\n--> 694         mgr = ndarray_to_mgr(\r\n    695             data,\r\n    696             index,\r\n    697             columns,\r\n    698             dtype=dtype,\r\n    699             copy=copy,\r\n    700             typ=manager,\r\n    701         )\r\n    703 # For data is list-like, or Iterable (will consume into list)\r\n    704 elif is_list_like(data):\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:351, in ndarray_to_mgr(values, index, columns, dtype, copy, typ)\r\n    346 # _prep_ndarray ensures that values.ndim == 2 at this point\r\n    347 index, columns = _get_axes(\r\n    348     values.shape[0], values.shape[1], index=index, columns=columns\r\n    349 )\r\n--> 351 _check_values_indices_shape_match(values, index, columns)\r\n    353 if typ == \"array\":\r\n    355     if issubclass(values.dtype.type, str):\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:422, in _check_values_indices_shape_match(values, index, columns)\r\n    420 passed = values.shape\r\n    421 implied = (len(index), len(columns))\r\n--> 422 raise ValueError(f\"Shape of passed values is {passed}, indices imply {implied}\")\r\n\r\nValueError: Shape of passed values is (2, 2), indices imply (2, 3)\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\npython3, sklearn = 1.2.1\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-29294", "file_changes": [{"file": "sklearn/utils/parallel.py", "changes": {"edited_modules": ["sklearn/utils/parallel.py:_FuncWrapper", "sklearn/utils/parallel.py:_with_config", "sklearn/utils/parallel.py:Parallel"], "edited_entities": ["sklearn/utils/parallel.py:_FuncWrapper.with_config", "sklearn/utils/parallel.py:_with_config", "sklearn/utils/parallel.py:Parallel.__call__", "sklearn/utils/parallel.py:_FuncWrapper", "sklearn/utils/parallel.py:_FuncWrapper.__call__"]}}, {"file": "sklearn/utils/tests/test_parallel.py", "changes": {"edited_modules": ["sklearn/utils/tests/test_parallel.py:test_dispatch_config_parallel"], "edited_entities": ["sklearn/utils/tests/test_parallel.py:test_dispatch_config_parallel"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "2707099b23a0a8580731553629566c1182d26f48", "problem_statement": "ConvergenceWarnings cannot be turned off\n\nHi, I'm unable to turn off convergence warnings from `GraphicalLassoCV`.\r\n\r\nI've tried most of the solutions from, and none of them worked (see below for actual implementations):\r\nhttps://stackoverflow.com/questions/879173/how-to-ignore-deprecation-warnings-in-python\r\nhttps://stackoverflow.com/questions/32612180/eliminating-warnings-from-scikit-learn/33812427#33812427\r\nhttps://stackoverflow.com/questions/53968004/how-to-silence-all-sklearn-warning\r\nhttps://stackoverflow.com/questions/14463277/how-to-disable-python-warnings\r\n\r\nContrary to what the designers of the sklearn's exceptions must have thought when it was implemented, some of us actually use stdout to log important information of the host program for diagnostics purposes.  Flooding it with garbage that cannot be turned off, as is in the case with cross-validation, is not ok. \r\n\r\nTo briefly speak to the severity of the issue, the above sklearn-specific questions relating to suppressing warnings have been viewed ~500K times with combined ~400 upvotes, and dates back 7 years. \r\n\r\nI've tried the following (`n_jobs` parameter does not appear to affect the result):\r\n\r\n```py\r\nfrom sklearn.covariance import GraphicalLassoCV\r\nimport warnings\r\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\r\n\r\nmodel = GraphicalLassoCV(n_jobs=4)\r\nmodel = model.fit(data)\r\n```\r\n\r\n```py\r\nfrom sklearn.covariance import GraphicalLassoCV\r\nimport warnings\r\nwarnings.filterwarnings(action='ignore')\r\n\r\nmodel = GraphicalLassoCV(n_jobs=4)\r\nmodel = model.fit(data)\r\n```\r\n\r\n```py\r\nimport warnings\r\nwith warnings.catch_warnings():\r\n    warnings.simplefilter(\"ignore\", ConvergenceWarning)\r\n\r\n    model = GraphicalLassoCV(n_jobs=4)\r\n    model = model.fit(data)\r\n```\r\n\r\n```py\r\nfrom sklearn.covariance import GraphicalLassoCV\r\ndef warn(*args, **kwargs):\r\n    pass\r\nimport warnings\r\nwarnings.warn = warn\r\n\r\nmodel = GraphicalLassoCV(n_jobs=4)\r\nmodel = model.fit(data)\r\n```\r\n\r\n```py\r\nimport contextlib\r\nimport os, sys\r\n\r\n@contextlib.contextmanager\r\ndef suppress_stdout():\r\n    with open(os.devnull, 'w') as fnull:\r\n        old_stdout = sys.stdout\r\n        sys.stdout = fnull\r\n        try:\r\n            yield\r\n        finally:\r\n            sys.stdout = old_stdout\r\n\r\nwith suppress_stdout():\r\n    model = GraphicalLassoCV(n_jobs=4)\r\n    model = model.fit(data)\r\n```\r\n\r\n```py\r\nimport logging\r\nlogging.captureWarnings(True)\r\n\r\nlogging.getLogger(\"py.warnings\").setLevel(logging.ERROR)\r\n\r\nmodel = GraphicalLassoCV(n_jobs=4)\r\nmodel = model.fit(data)\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-19248", "file_changes": [{"file": "doc/modules/clustering.rst", "changes": {}}, {"file": "examples/cluster/plot_birch_vs_minibatchkmeans.py", "changes": {}}, {"file": "examples/cluster/plot_cluster_comparison.py", "changes": {}}, {"file": "sklearn/cluster/_birch.py", "changes": {"edited_modules": ["sklearn/cluster/_birch.py:Birch"], "edited_entities": ["sklearn/cluster/_birch.py:Birch", "sklearn/cluster/_birch.py:Birch._global_clustering"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "23d8761615d0417eef5f52cc796518e44d41ca2a", "problem_statement": "Birch should be called BIRCH\n\nC.f. the original paper.\r\nZhang, T.; Ramakrishnan, R.; Livny, M. (1996). \"BIRCH: an efficient data clustering method for very large databases\". Proceedings of the 1996 ACM SIGMOD international conference on Management of data - SIGMOD '96. pp. 103\u2013114. doi:10.1145/233269.233324", "patch": ""}
{"instance_id": "pallets__flask-602", "file_changes": [{"file": "flask/app.py", "changes": {"edited_modules": ["flask/app.py:Flask"], "edited_entities": ["flask/app.py:Flask.handle_exception"]}}], "repo": "pallets/flask", "base_commit": "ee76129812419d473eb62434051e81d5855255b6", "problem_statement": "Misspelling in docs @ flask.Flask.handle_exception\n\n`Default exception handling that kicks in when an exception occours that is not caught. In debug mode the exception will be re-raised immediately, otherwise it is logged and the handler for a 500 internal server error is used. If no such handler exists, a default 500 internal server error message is displayed.`\n\nOccours should be occurs.\n\nI looked around in the project code to see if i could update this, but it looks like the docs subdir is no longer used? I could be wrong, if you let me know where this is at I'll update it and send a PR :)", "patch": ""}
{"instance_id": "pandas-dev__pandas-37494", "file_changes": [{"file": "pandas/core/dtypes/cast.py", "changes": {"edited_modules": ["pandas/core/dtypes/cast.py:maybe_cast_result_dtype"], "edited_entities": ["pandas/core/dtypes/cast.py:maybe_cast_result_dtype"]}}, {"file": "pandas/core/groupby/ops.py", "changes": {"edited_modules": ["pandas/core/groupby/ops.py:BaseGrouper"], "edited_entities": ["pandas/core/groupby/ops.py:BaseGrouper._ea_wrap_cython_operation"]}}, {"file": "pandas/tests/arrays/integer/test_arithmetic.py", "changes": {"edited_modules": ["pandas/tests/arrays/integer/test_arithmetic.py:test_reduce_to_float"], "edited_entities": ["pandas/tests/arrays/integer/test_arithmetic.py:test_reduce_to_float"]}}, {"file": "pandas/tests/groupby/aggregate/test_cython.py", "changes": {"edited_modules": ["pandas/tests/groupby/aggregate/test_cython.py:test_cython_agg_nullable_int"], "edited_entities": ["pandas/tests/groupby/aggregate/test_cython.py:test_cython_agg_nullable_int"]}}, {"file": "pandas/tests/groupby/test_function.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_function.py:test_apply_to_nullable_integer_returns_float"], "edited_entities": ["pandas/tests/groupby/test_function.py:test_apply_to_nullable_integer_returns_float"]}}, {"file": "pandas/tests/resample/test_datetime_index.py", "changes": {"edited_modules": ["pandas/tests/resample/test_datetime_index.py:test_resample_integerarray"], "edited_entities": ["pandas/tests/resample/test_datetime_index.py:test_resample_integerarray"]}}], "repo": "pandas-dev/pandas", "base_commit": "862cd05df4452592a99dd1a4fa10ce8cfb3766f7", "problem_statement": "ENH: improve the resulting dtype for groupby operations on nullable dtypes\n\nFollow-up on https://github.com/pandas-dev/pandas/pull/37433, and partly related to https://github.com/pandas-dev/pandas/issues/37493\r\n\r\nCurrently, after groupby operations we try to cast back to the original dtype when possible (at least in case of extension arrays). But this is not always correct, and also not done consistently. Some examples using the test case from the mentioned PR using a nullable Int64 column as input:\r\n\r\n```\r\nIn [1]: df = DataFrame(\r\n   ...:     {\r\n   ...:         \"A\": [\"A\", \"B\"] * 5,\r\n   ...:         \"B\": pd.array([1, 2, 3, 4, 5, 6, 7, 8, 9, pd.NA], dtype=\"Int64\"),\r\n   ...:     }\r\n   ...: )\r\n\r\nIn [2]: df.groupby(\"A\")[\"B\"].sum()\r\nOut[2]: \r\nA\r\nA    25\r\nB    20\r\nName: B, dtype: Int64\r\n\r\nIn [3]: df.groupby(\"A\")[\"B\"].std()\r\nOut[3]: \r\nA\r\nA    3.162278\r\nB    2.581989\r\nName: B, dtype: float64\r\n\r\nIn [4]: df.groupby(\"A\")[\"B\"].mean()\r\nOut[4]: \r\nA\r\nA    5\r\nB    5\r\nName: B, dtype: Int64\r\n\r\nIn [5]: df.groupby(\"A\")[\"B\"].count()\r\nOut[5]: \r\nA\r\nA    5\r\nB    4\r\nName: B, dtype: int64\r\n```\r\n\r\nSo some observations:\r\n\r\n* For `sum()`, we correctly have Int64 for the result\r\n* For `std()`, we could use the nullable Float64 instead of float64 dtype\r\n* For `mean()`, we incorrectly cast back to Int64 dtype, as the result of mean should always be floating (in this case the casting just happened to work because the means were rounded numbers)\r\n* For `count()`, we did not create a nullable Int64 dtype for the result, while this could be done in the input is nullable", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-16730", "file_changes": [{"file": "doc/whats_new/v0.23.rst", "changes": {}}, {"file": "sklearn/decomposition/_pca.py", "changes": {"edited_modules": ["sklearn/decomposition/_pca.py:_assess_dimension", "sklearn/decomposition/_pca.py:_infer_dimension", "sklearn/decomposition/_pca.py:PCA"], "edited_entities": ["sklearn/decomposition/_pca.py:_assess_dimension", "sklearn/decomposition/_pca.py:_infer_dimension", "sklearn/decomposition/_pca.py:PCA._fit_full"]}}, {"file": "sklearn/decomposition/tests/test_pca.py", "changes": {"edited_modules": ["sklearn/decomposition/tests/test_pca.py:test_fit_mle_too_few_samples", "sklearn/decomposition/tests/test_pca.py:test_n_components_mle", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_1", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_2", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_3", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_bad_spec", "sklearn/decomposition/tests/test_pca.py:test_assess_dimension_error_rank_greater_than_features", "sklearn/decomposition/tests/test_pca.py:test_assess_dimension_small_eigenvalues", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_mle"], "edited_entities": ["sklearn/decomposition/tests/test_pca.py:test_fit_mle_too_few_samples", "sklearn/decomposition/tests/test_pca.py:test_n_components_mle", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_1", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_2", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_3", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_bad_spec", "sklearn/decomposition/tests/test_pca.py:test_assess_dimension_error_rank_greater_than_features", "sklearn/decomposition/tests/test_pca.py:test_assess_dimension_small_eigenvalues", "sklearn/decomposition/tests/test_pca.py:test_infer_dim_mle"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "eaf0a044fdc084ebeeb9bbfbcf42e6df2b1491bb", "problem_statement": "BUG: MLE for PCA mis-estimates rank\n\nAfter #16224 it looks like this code no longer produces the correct result:\r\n```\r\nimport numpy as np\r\nfrom sklearn.decomposition import PCA\r\nn_samples, n_dim = 1000, 10\r\nX = np.random.RandomState(0).randn(n_samples, n_dim)\r\nX[:, -1] = np.mean(X[:, :-1], axis=-1)  # true X dim is ndim - 1\r\npca_skl = PCA('mle', svd_solver='full')\r\npca_skl.fit(X)\r\nassert pca_skl.n_components_ == n_dim - 1\r\n```\r\nBefore #16224 this passed (`n_components_ == 9`) but after #16224 it gives 8. Not sure why this would happen given the singular value spectrum looks good:\r\n```\r\nimport matplotlib.pyplot as plt\r\ns = np.linalg.svdvals(X)\r\nplt.stem(s)\r\n```\r\n![Figure_1](https://user-images.githubusercontent.com/2365790/77180767-c4f62a00-6aa0-11ea-8dc8-99c6dc137a71.png)\r\n\r\nMaybe an off-by-one error somewhere?\r\n\r\ncc'ing @lschwetlick since it was your PR", "patch": ""}
{"instance_id": "pallets__flask-2813", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "docs/config.rst", "changes": {}}, {"file": "src/flask/app.py", "changes": {"edited_modules": ["src/flask/app.py:Flask"], "edited_entities": ["src/flask/app.py:Flask.create_url_adapter"]}}, {"file": "tests/test_basic.py", "changes": {}}, {"file": "tests/test_blueprints.py", "changes": {"edited_modules": ["tests/test_blueprints.py:test_nesting_subdomains", "tests/test_blueprints.py:test_child_and_parent_subdomain"], "edited_entities": ["tests/test_blueprints.py:test_nesting_subdomains", "tests/test_blueprints.py:test_child_and_parent_subdomain"]}}], "repo": "pallets/flask", "base_commit": "07c7d5730a2685ef2281cc635e289685e5c3d478", "problem_statement": "Allow flexible routing with SERVER_NAME config\n\n### Expected Behavior\r\n\r\nDeployed a flask application which is reachable over multiple domains and ports:\r\n- external via load balancer: `client - Host: example.org -> LB -> flask app`\r\n- internal via DNS service discovery without load balancer: `client - Host: instance-1231.example.org -> flask app` \r\n\r\nIf the client connects directly (`Host: instance-1231.example.org`) the app should be able to return absolute and stable URLs like `http://example.org/path/to/my/view` as the URL (`http://instance-1231.example.org/path/to/my/view`) with the internal DNS name is ephemeral.\r\nTherefore I configured the `SERVER_NAME` config key and `url_for` generates the intended absolute URL by using `_external=True` within and without request context. But the app should be still able to route requests coming with `Host: instance-1231.example.org`.\r\n\r\n### Actual Behavior\r\n\r\nFlasks creates the `werkzeug.routing.MapAdapter` with `server_name=app.config['SERVER_NAME']` and therefore no view method will match to incoming requests with `Host: instance-1231.example.org`.\r\n\r\n### Environment\r\n\r\n* Python version: 2.7.13 (I'm sorry)\r\n* Flask version: 1.0.2\r\n* Werkzeug version: 0.14.1\r\n\r\n### Applied workaround:\r\n\r\nOverwrite `Flask.create_url_adapter` and create `MapAdapter` for request context without `server_name` parameter. Routing and URL generation works fine.", "patch": ""}
{"instance_id": "pandas-dev__pandas-46804", "file_changes": [{"file": ".github/workflows/code-checks.yml", "changes": {}}, {"file": ".github/workflows/docbuild-and-upload.yml", "changes": {}}, {"file": "ci/code_checks.sh", "changes": {}}, {"file": "doc/source/index.rst.template", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "a8968bfa696d51f73769c54f2630a9530488236a", "problem_statement": "DOC: building page for nested methods doesn't work\n\nThe following\r\n```\r\npython make.py --single pandas.Series.str.rsplit\r\n```\r\nfails to produce the docs:\r\n```\r\n(pandas-dev) marcogorelli@OVMG025 doc % python make.py clean && python make.py --single pandas.Series.str.rsplit\r\nRunning Sphinx v4.4.0\r\nloading translations [en]... done\r\nmaking output directory... done\r\n[autosummary] generating autosummary for: index.rst\r\n[autosummary] generating autosummary for: /Users/marcogorelli/pandas-dev/doc/source/reference/api/pandas.Series.str.rsplit.rst\r\nbuilding [mo]: targets for 0 po files that are out of date\r\nbuilding [html]: targets for 1 source files that are out of date\r\nupdating environment: [new config] 2 added, 0 changed, 0 removed\r\nreading sources... [100%] reference/api/pandas.Series.str.rsplit                                                                        \r\nWARNING: autodoc: failed to import method 'str.rsplit' from module 'Series'; the following exception was raised:\r\nNo module named 'Series'\r\nlooking for now-outdated files... none found\r\npickling environment... done\r\nchecking consistency... done\r\npreparing documents... done\r\n/Users/marcogorelli/pandas-dev/doc/source/index.rst:44: WARNING: 'any' reference target not found: getting_started\r\n/Users/marcogorelli/pandas-dev/doc/source/index.rst:60: WARNING: 'any' reference target not found: user_guide\r\n/Users/marcogorelli/pandas-dev/doc/source/index.rst:77: WARNING: 'any' reference target not found: api\r\n/Users/marcogorelli/pandas-dev/doc/source/index.rst:94: WARNING: 'any' reference target not found: development\r\nwriting output... [100%] reference/api/pandas.Series.str.rsplit                                                                         \r\nwaiting for workers...\r\ngenerating indices... genindex py-modindex done\r\nwriting additional pages... search done\r\ncopying images... [100%] _static/index_contribute.svg                                                                                   \r\ncopying static files... done\r\ncopying extra files... done\r\ndumping search index in English (code: en)... done\r\ndumping object inventory... done\r\nbuild succeeded, 5 warnings.\r\n```\r\n\r\nHowever, it works just fine to do\r\n```\r\npython make.py --single pandas.Series.value_counts\r\n```\r\n\r\nI haven't figured out how to address this, so opening an issue for now", "patch": ""}
{"instance_id": "pandas-dev__pandas-33428", "file_changes": [{"file": "pandas/plotting/_misc.py", "changes": {"edited_modules": ["pandas/plotting/_misc.py:parallel_coordinates"], "edited_entities": ["pandas/plotting/_misc.py:parallel_coordinates"]}}], "repo": "pandas-dev/pandas", "base_commit": "e88c39225ef545123860c679822f1b567fe65c27", "problem_statement": "DOC: Data links in Pandas API Reference are broken 404\n\n#### Location of the documentation\r\n\r\nhttps://pandas.pydata.org/docs/reference/api/pandas.plotting.parallel_coordinates.html\r\n...probably many examples in other sections\r\n\r\n#### Documentation problem\r\n\r\nResults in 404 not found error\r\ndf = pd.read_csv('https://raw.github.com/pandas-dev/pandas/master'\r\n                    '/pandas/tests/data/csv/iris.csv')\r\n\r\n#### Suggested fix for documentation\r\n\r\nThe GitHub site should be \"raw.githubusercontent.com\"", "patch": ""}
{"instance_id": "pandas-dev__pandas-17200", "file_changes": [{"file": "doc/source/whatsnew/v0.21.1.txt", "changes": {}}, {"file": "pandas/io/json/json.py", "changes": {"edited_modules": ["pandas/io/json/json.py:JsonReader", "pandas/io/json/json.py:Parser"], "edited_entities": ["pandas/io/json/json.py:JsonReader.read", "pandas/io/json/json.py:Parser._try_convert_data", "pandas/io/json/json.py:Parser._try_convert_to_date"]}}, {"file": "pandas/tests/io/json/test_pandas.py", "changes": {"edited_modules": ["pandas/tests/io/json/test_pandas.py:TestPandasContainer"], "edited_entities": ["pandas/tests/io/json/test_pandas.py:TestPandasContainer"]}}, {"file": "pandas/tests/io/parser/test_network.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "674fb96b33c07c680844f674fcdf0767b6e3c2f9", "problem_statement": "read_json(lines=True) broken for s3 urls in Python 3 (v0.20.3)\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\nUsing Python\r\n```python\r\nimport pandas as pd\r\ninputdf = pd.read_json(path_or_buf=\"s3://path/to/python-lines/file.json\", lines=True)\r\n```\r\n\r\nThe file is similar to:\r\n```\r\n{\"url\": \"blah\", \"other\": \"blah\"}\r\n{\"url\": \"blah\", \"other\": \"blah\"}\r\n{\"url\": \"blah\", \"other\": \"blah\"}\r\n```\r\n\r\n#### Problem description\r\n\r\nWhen attempting to read a python lines file into a DataFrame using the s3 protocol, the above code will error with:\r\n\r\n```\r\n2017-08-08 11:06:14,225 - image_rank_csv - ERROR - initial_value must be str or None, not bytes\r\nTraceback (most recent call last):\r\n  File \"image_rank_csv.py\", line 62, in run\r\n    inputdf = pd.read_json(path_or_buf=\"s3://path/to/python-lines/file.json\", lines=True)\r\n  File \"...env/lib/python3.6/site-packages/pandas/io/json/json.py\", line 347, in read_json\r\n    lines = list(StringIO(json.strip()))\r\nTypeError: initial_value must be str or None, not bytes\r\n```\r\n\r\nThis works fine if the file is local, e.g.:\r\n```python\r\nimport pandas as pd\r\ninputdf = pd.read_json(path_or_buf=\"/local/path/to/python-lines/file.json\", lines=True)\r\n```\r\n\r\n#### Expected Output\r\n\r\nExpect to successfully read the file and error above not to occur.\r\n\r\nMy current thinking is that when we get the file handle: https://github.com/pandas-dev/pandas/blob/v0.20.3/pandas/io/json/json.py#L333 , you delegate to `s3fs`, which documents that [it only operates in Binary mode](http://s3fs.readthedocs.io/en/latest/#limitations). Therefore when you `read()`: https://github.com/pandas-dev/pandas/blob/v0.20.3/pandas/io/json/json.py#L335, Therefore passing to `StringIO` will fail here: https://github.com/pandas-dev/pandas/blob/v0.20.3/pandas/io/json/json.py#L347 . Maybe it needs a different handler for `BytesIO`?\r\n\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n[paste the output of ``pd.show_versions()`` here below this line]\r\n```\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.1.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.6.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.20.3\r\npytest: None\r\npip: 9.0.1\r\nsetuptools: 36.2.7\r\nCython: None\r\nnumpy: 1.12.0\r\nscipy: 0.19.1\r\nxarray: None\r\nIPython: None\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: None\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: 2.6.2 (dt dec pq3 ext lo64)\r\njinja2: None\r\ns3fs: 0.1.2\r\npandas_gbq: None\r\npandas_datareader: None\r\n```\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-39636", "file_changes": [{"file": "doc/source/whatsnew/v1.2.2.rst", "changes": {}}, {"file": "pandas/core/aggregation.py", "changes": {"edited_modules": ["pandas/core/aggregation.py:transform"], "edited_entities": ["pandas/core/aggregation.py:transform"]}}, {"file": "pandas/tests/apply/test_frame_transform.py", "changes": {"edited_modules": ["pandas/tests/apply/test_frame_transform.py:test_transform_mixed_column_name_dtypes"], "edited_entities": ["pandas/tests/apply/test_frame_transform.py:test_transform_mixed_column_name_dtypes"]}}], "repo": "pandas-dev/pandas", "base_commit": "d558bce8e9d5d4adfb0ab587be20b8a231dd1eea", "problem_statement": "BUG: ValueError on \".transform\" method applied to an empty DataFrame\n\n- [X] I have checked that this issue has not already been reported.\r\n\r\n- [X] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\nOutput on version 1.1.5:\r\n```python\r\nIn [5]: import pandas as pd\r\n   ...: df = pd.DataFrame([], columns=[\"id\", \"field\"])\r\n   ...: df[\"id\"].transform(lambda x: x + 10)\r\nOut[5]: Series([], Name: id, dtype: object)\r\n```\r\n\r\nOutput on version 1.2.x:\r\n```python\r\nIn [4]: import pandas as pd\r\n   ...: df = pd.DataFrame([], columns=[\"id\", \"field\"])\r\n   ...: df[\"id\"].transform(lambda x: x + 10)\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-d1e6cad57091> in <module>\r\n----> 1 df[\"id\"].transform(lambda x: x + 10)\r\n\r\n~/.pyenv/versions/3.9.1/envs/odds-data-3.9.1/lib/python3.9/site-packages/pandas/core/series.py in transform(self, func, axis, *args, **kwargs)\r\n   3975         self, func: AggFuncType, axis: Axis = 0, *args, **kwargs\r\n   3976     ) -> FrameOrSeriesUnion:\r\n-> 3977         return transform(self, func, axis, *args, **kwargs)\r\n   3978 \r\n   3979     def apply(self, func, convert_dtype=True, args=(), **kwds):\r\n\r\n~/.pyenv/versions/3.9.1/envs/odds-data-3.9.1/lib/python3.9/site-packages/pandas/core/aggregation.py in transform(obj, func, axis, *args, **kwargs)\r\n    458     # when the dtype is not appropriate\r\n    459     if isinstance(result, (ABCSeries, ABCDataFrame)) and result.empty:\r\n--> 460         raise ValueError(\"Transform function failed\")\r\n    461     if not isinstance(result, (ABCSeries, ABCDataFrame)) or not result.index.equals(\r\n    462         obj.index\r\n\r\nValueError: Transform function failed\r\n```\r\n\r\n#### Problem description\r\n\r\nApplying `.transform` on an empty DataFrame raises a `ValueError` on version 1.2.x. This is a change on the behavior of 1.1.5 version that returns the same empty DataFrame (as `.apply` is still doing).\r\n\r\nThe change that added this error apparently is related to this commit https://github.com/pandas-dev/pandas/pull/35964/commits/7b6ab94720024d6696b19867f5f8f59f79587ff0 \r\n\r\n#### Expected Output\r\n\r\n```python\r\nIn [5]: import pandas as pd\r\n   ...: df = pd.DataFrame([], columns=[\"id\", \"field\"])\r\n   ...: df[\"id\"].transform(lambda x: x + 10)\r\nOut[5]: Series([], Name: id, dtype: object)\r\n```\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 9d598a5e1eee26df95b3910e3f2934890d062caa\r\npython           : 3.9.1.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 5.4.0-65-generic\r\nVersion          : #73-Ubuntu SMP Mon Jan 18 17:25:17 UTC 2021\r\nmachine          : x86_64\r\nprocessor        : x86_64\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 1.2.1\r\nnumpy            : 1.20.0\r\npytz             : 2021.1\r\ndateutil         : 2.8.1\r\npip              : 20.2.3\r\nsetuptools       : 49.2.1\r\nCython           : None\r\npytest           : 6.2.2\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : 4.6.2\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : None\r\nIPython          : 7.20.0\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.6.0\r\nsqlalchemy       : 1.3.23\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-33238", "file_changes": [{"file": "pandas/_libs/writers.pyx", "changes": {}}, {"file": "pandas/io/sas/sas.pyx", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "9572a2e00ddadb9fc7e2125c3e723b8a3b54be05", "problem_statement": "CI/COMPAT: Linux py37_np_dev pipeline timeouts\n\n#### Problem description\r\n\r\nLinux py37_np_dev pipeline appears to timeout for everyone after 60 minutes.\r\nThere are a couple hundred thousand errors like this:\r\n```\r\nException ignored in: 'pandas.io.sas._sas.Parser.process_byte_array_with_data'\r\nDeprecationWarning: tostring() is deprecated. Use tobytes() instead.\r\nDeprecationWarning: tostring() is deprecated. Use tobytes() instead.\r\n```\r\nHere is a [link](https://dev.azure.com/pandas-dev/pandas/_build/results?buildId=32212&view=logs&j=3a03f79d-0b41-5610-1aa4-b4a014d0bc70&t=4d05ed0e-1ed3-5bff-dd63-1e957f2766a9&l=792078) to it failing for me.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-10251", "file_changes": [{"file": "sklearn/tree/_criterion.pxd", "changes": {}}, {"file": "sklearn/tree/_criterion.pyx", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "61e722aa126207efcdbc1ddcd4453854ad44ea09", "problem_statement": "Extending Criterion\n\nUnless I'm missing something, it's not completely trivial how one can use a custom `sklearn.tree._criterion.Criterion` for a decision tree. See my use case [here](https://stats.stackexchange.com/q/316954/98500).\r\n\r\nThings I have tried include:\r\n\r\n- Import the `ClassificationCriterion` in Python and subclass it. It seems that `node_impurity` and `children_impurity` do not get called, the impurity is always 0 (perhaps because they are `cdef` and not `cpdef`?). I'm also unsure what the parameters to `__new__` / `__cinit__` should be (e.g. `1` and `np.array([2], dtype='intp')` for a binary classification problem?), or how to pass them properly: I have to create the `Criterion` object from outside the tree to circumvent [the check on the `criterion` argument](https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/tree/tree.py#L324).\r\n\r\n- Extend `ClassificationCriterion` in a Cython file. This seems to work, but (a) it requires exporting `ClassificationCriterion` from `_criterion.pxd` and (b) it would be nice if it would be documented more extensively what should be done in `node_impurity` and `children_impurity`. I will post my code below once it seems to work correctly.\r\n\r\nMay I propose one of the following to make this easier?\r\n\r\n- Document what should be done to extend the class in Cython or Python - if Python should be allowed: I am aware of the performance issue with that, but in some cases it may be OK to do this in Python - I don't know.\r\n- Make it possible to pass a function or other object not extending `Criterion` to the tree, similar to how it is very easy to implement a custom scorer for validation functions. That would require changing the checks [here](https://github.com/scikit-learn/scikit-learn/blob/a24c8b464d094d2c468a16ea9f8bf8d42d949f84/sklearn/tree/tree.py#L324).", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-27682", "file_changes": [{"file": "sklearn/metrics/_pairwise_distances_reduction/_middle_term_computer.pyx.tp", "changes": {}}, {"file": "sklearn/metrics/_pairwise_distances_reduction/_radius_neighbors.pyx.tp", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "3d19272be75fe32edd4cf01cb2eeac2281305e42", "problem_statement": "MAINT Directly `cimport` interfaces from `std::algorithm`\n\nSome Cython implementations use interfaces from the standard library of C++, namely `std::algorithm::move` and `std::algorithm::fill` from [`std::algorithm`](https://en.cppreference.com/w/cpp/algorithm/).\r\n\r\nBefore Cython 3, those interfaces had to be imported directly using the verbose syntax from Cython:\r\n - https://github.com/scikit-learn/scikit-learn/blob/5fc67aeb092d636895b599921283221a68c7a2ad/sklearn/metrics/_pairwise_distances_reduction/_radius_neighbors.pyx.tp#L22-L26\r\n - https://github.com/scikit-learn/scikit-learn/blob/5fc67aeb092d636895b599921283221a68c7a2ad/sklearn/metrics/_pairwise_distances_reduction/_middle_term_computer.pyx.tp#L28-L33\r\n\r\nCython 3 introduced the following line natively, for those interfaces. Those interfaces should now be `cimported` directly. That is one can replace the line shown above respectively with:\r\n\r\n```cython\r\nfrom libcpp.algorithm cimport move\r\nfrom libcpp.algorithm cimport fill\r\n```\r\n\r\nI believe this is a good first Cython issue.\r\n\r\nAny reader should feel free to pick it up. It might be possible that there is some context missing.\r\n\r\nPlease let me know if you need help. :slightly_smiling_face:", "patch": ""}
{"instance_id": "huggingface__transformers-9954", "file_changes": [{"file": "tests/test_modeling_tf_lxmert.py", "changes": {"edited_modules": ["tests/test_modeling_tf_lxmert.py:TFLxmertModelTest"], "edited_entities": ["tests/test_modeling_tf_lxmert.py:TFLxmertModelTest.test_saved_model_creation_extended", "tests/test_modeling_tf_lxmert.py:TFLxmertModelTest.test_pt_tf_model_equivalence"]}}], "repo": "huggingface/transformers", "base_commit": "626a0a01471accc32ded29ccca3ed93c4995fcd6", "problem_statement": "[Good first issue] LXMERT TensorFlow Integration tests\n\nThe TensorFlow implementation of the LXMERT model currently has no integration tests. This is problematic as the behavior can diverge without being noticed.\r\n\r\nThe [test_modeling_tf_lxmert.py](https://github.com/huggingface/transformers/blob/master/tests/test_modeling_tf_lxmert.py) file should be updated to include integration testing.\r\n\r\nAn example of a good modeling integration test is visible in the [test_modeling_tf_bert.py#L365-L387](https://github.com/huggingface/transformers/blob/1809de5165804666ba6c6a02a9d177f6683869cc/tests/test_modeling_tf_bert.py#L365-L387) file:\r\n\r\nhttps://github.com/huggingface/transformers/blob/1809de5165804666ba6c6a02a9d177f6683869cc/tests/test_modeling_tf_bert.py#L365-L387\r\n\r\nSome additional tips:\r\n- The test must be marked as slow using the `@slow` decorator, so as to be run *daily*, and not on every commit of every branch/pull request of this repository.\r\n- The test must be decorated with the `@require_tf` decorator so as to only be run in environments using PyTorch.\r\n- A single test is necessary. If you feel like implementing multiple of these, then sharing the same checkpoint would be ideal so as to reduce download time.", "patch": ""}
{"instance_id": "pandas-dev__pandas-24115", "file_changes": [{"file": "doc/source/whatsnew/v1.0.0.rst", "changes": {}}, {"file": "pandas/core/arrays/datetimelike.py", "changes": {"edited_modules": ["pandas/core/arrays/datetimelike.py:DatetimeLikeArrayMixin"], "edited_entities": ["pandas/core/arrays/datetimelike.py:DatetimeLikeArrayMixin", "pandas/core/arrays/datetimelike.py:DatetimeLikeArrayMixin.__iadd__", "pandas/core/arrays/datetimelike.py:DatetimeLikeArrayMixin.__isub__"]}}, {"file": "pandas/tests/arrays/test_datetimelike.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "710df2140555030e4d86e669d6df2deb852bcaf5", "problem_statement": "DTA/TDA/PA inplace methods should actually be inplace\n\nAt the moment we are using the implementations designed for Index subclasses, which return new objects.", "patch": ""}
{"instance_id": "huggingface__transformers-26809", "file_changes": [{"file": "docs/source/en/index.md", "changes": {}}, {"file": "docs/source/en/model_doc/llama.md", "changes": {}}, {"file": "src/transformers/__init__.py", "changes": {}}, {"file": "src/transformers/modeling_flax_utils.py", "changes": {"edited_modules": ["src/transformers/modeling_flax_utils.py:append_call_sample_docstring"], "edited_entities": ["src/transformers/modeling_flax_utils.py:append_call_sample_docstring"]}}, {"file": "src/transformers/models/auto/modeling_flax_auto.py", "changes": {}}, {"file": "src/transformers/models/bloom/modeling_bloom.py", "changes": {"edited_modules": ["src/transformers/models/bloom/modeling_bloom.py:BloomPreTrainedModel"], "edited_entities": ["src/transformers/models/bloom/modeling_bloom.py:BloomPreTrainedModel._convert_to_bloom_cache"]}}, {"file": "src/transformers/models/fuyu/image_processing_fuyu.py", "changes": {"edited_modules": ["src/transformers/models/fuyu/image_processing_fuyu.py:make_list_of_list_of_images"], "edited_entities": ["src/transformers/models/fuyu/image_processing_fuyu.py:make_list_of_list_of_images"]}}, {"file": "src/transformers/models/llama/__init__.py", "changes": {}}, {"file": "src/transformers/models/mpt/modeling_mpt.py", "changes": {"edited_modules": ["src/transformers/models/mpt/modeling_mpt.py:MptPreTrainedModel"], "edited_entities": ["src/transformers/models/mpt/modeling_mpt.py:MptPreTrainedModel._convert_to_mpt_cache"]}}, {"file": "src/transformers/utils/dummy_flax_objects.py", "changes": {}}, {"file": "tests/models/llama/test_modeling_llama.py", "changes": {"edited_modules": ["tests/models/llama/test_modeling_llama.py:LlamaModelTester"], "edited_entities": ["tests/models/llama/test_modeling_llama.py:LlamaModelTester.prepare_config_and_inputs"]}}, {"file": "tests/models/mistral/test_modeling_mistral.py", "changes": {"edited_modules": ["tests/models/mistral/test_modeling_mistral.py:MistralModelTester"], "edited_entities": ["tests/models/mistral/test_modeling_mistral.py:MistralModelTester.prepare_config_and_inputs"]}}, {"file": "tests/models/persimmon/test_modeling_persimmon.py", "changes": {"edited_modules": ["tests/models/persimmon/test_modeling_persimmon.py:PersimmonModelTester"], "edited_entities": ["tests/models/persimmon/test_modeling_persimmon.py:PersimmonModelTester.prepare_config_and_inputs"]}}, {"file": "tests/models/phi/test_modeling_phi.py", "changes": {}}, {"file": "utils/check_docstrings.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "da1d0d404f05523d37b37207a4c1ff419cc1f47f", "problem_statement": "Add Mistral Models to Flax\n\n### Feature request\r\n\r\nI would like to implement the ~~Llama~~ Mistral model in flax\r\n\r\n### Motivation\r\n\r\nI've been trying to get familiar with jax and as such I started migrating the llama model, and I think I am at a point where both models are quite comparable in outcome\r\n\r\n### Your contribution\r\n\r\nYes I could submit a PR with the model implementation", "patch": ""}
{"instance_id": "pandas-dev__pandas-6403", "file_changes": [{"file": "ci/requirements-3.4.txt", "changes": {}}, {"file": "ci/requirements-3.4_SLOW.txt", "changes": {}}, {"file": "doc/source/install.rst", "changes": {}}, {"file": "doc/source/io.rst", "changes": {}}, {"file": "doc/source/whatsnew/v0.17.0.txt", "changes": {}}, {"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame.to_excel"]}}, {"file": "pandas/io/excel.py", "changes": {"edited_modules": ["pandas/io/excel.py:ExcelFile", "pandas/io/excel.py:_conv_value", "pandas/io/excel.py:ExcelWriter", "pandas/io/excel.py:_XlwtWriter", "pandas/io/excel.py:_XlsxWriter"], "edited_entities": ["pandas/io/excel.py:ExcelFile._parse_excel", "pandas/io/excel.py:_conv_value", "pandas/io/excel.py:ExcelWriter", "pandas/io/excel.py:_XlwtWriter.__init__", "pandas/io/excel.py:_XlsxWriter.write_cells", "pandas/io/excel.py:ExcelWriter.__new__", "pandas/io/excel.py:ExcelWriter.__init__"]}}, {"file": "pandas/io/tests/test_excel.py", "changes": {"edited_modules": ["pandas/io/tests/test_excel.py:ExcelReaderTests"], "edited_entities": ["pandas/io/tests/test_excel.py:ExcelReaderTests.test_creating_and_reading_multiple_sheets"]}}, {"file": "vb_suite/packers.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "0b74c72e1c7fe320440fa97a3d256107ea329307", "problem_statement": "ExcelFile parse of empty sheet fails with \"IndexError: list index out of range\"\n\nUsing pandas 0.13.1 on OS X Mavericks to parse a blank Excel spreadsheet causes \"IndexError: list index out of range\". Apparently the default header=0 in `_parse_excel` causes the execution of `_trim_excel_header(data[header])`. Perhaps when nrows==0 this should not be executed.\n\n``` python\nimport pandas as pd\nxl_file = pd.ExcelFile('blank.xlsx')\nxl_file.parse('Sheet1') #Sheet1 has no data\n```\n\nSTDERR:\n\n```\nTraceback (most recent call last):\n  File \"/Users/myourshaw/lab/pypeline/python2/excel_example.py\", line 10, in <module>\n    xl_file.parse('Sheet1')\n  File \"/usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/excel.py\", line 208, in parse\n    **kwds)\n  File \"/usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/excel.py\", line 291, in _parse_excel\n    data[header] = _trim_excel_header(data[header])\nIndexError: list index out of range\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-23814", "file_changes": [{"file": "asv_bench/benchmarks/categoricals.py", "changes": {"edited_modules": ["asv_bench/benchmarks/categoricals.py:Constructor"], "edited_entities": ["asv_bench/benchmarks/categoricals.py:Constructor.setup"]}}, {"file": "doc/source/whatsnew/v0.24.0.rst", "changes": {}}, {"file": "pandas/core/arrays/categorical.py", "changes": {"edited_modules": ["pandas/core/arrays/categorical.py:Categorical"], "edited_entities": ["pandas/core/arrays/categorical.py:Categorical.__init__"]}}], "repo": "pandas-dev/pandas", "base_commit": "d865e5213515cef6344f16f4c77386be9ce8f223", "problem_statement": "equality comparison with a scalar is slow for category (performance regression)\n\nAre the following 2 ways to compare a series to a scalar equivalent (ignore missing values)? I have to write the hard way in order to take advantage of the category properties.\r\n\r\n    ```python\r\n    x = pd.Series(list('abcd') * 1000000).astype('category')\r\n    %timeit x == 'a'\r\n    # 10 loops, best of 3: 25.2 ms per loop\r\n    %timeit x.cat.codes == x.cat.categories.get_loc('a')\r\n    # 1000 loops, best of 3: 750 \u00b5s per loop\r\n    ```", "patch": ""}
{"instance_id": "psf__requests-3659", "file_changes": [{"file": "requests/adapters.py", "changes": {"edited_modules": ["requests/adapters.py:HTTPAdapter"], "edited_entities": ["requests/adapters.py:HTTPAdapter.proxy_headers"]}}, {"file": "tests/test_requests.py", "changes": {"edited_modules": ["tests/test_requests.py:TestRequests"], "edited_entities": ["tests/test_requests.py:TestRequests"]}}], "repo": "psf/requests", "base_commit": "7eaa5ee37f2ef0fb37dc6e9efbead726665810b4", "problem_statement": "URL proxy auth with empty passwords doesn't emit auth header.\n\nI'm using a proxy that requires authentication to send request that receives 302 response with Location header. I would like python.requests to follow this redirect and make request via proxy with specified credentials. But it seems like this doesn't happen, if I provide credentials in HTTPProxyAuth they will work ok for 200 responses but will fail for 302. See below code sample:\r\n\r\n```python\r\n\r\nimport requests\r\nfrom requests.auth import HTTPProxyAuth\r\n\r\nsess = requests.Session()\r\nurl1 = 'http://httpbin.org/'\r\nurl2 = 'http://httpbin.org/redirect/2'\r\nauth = HTTPProxyAuth('frank', 'hunter2')\r\nproxies = {\r\n    \"http\": \"http://localhost:9000\"\r\n}\r\nresponse1 = sess.get(url1, proxies=proxies, auth=auth)\r\nresponse1.raise_for_status()\r\nresponse2 = sess.get(url2, proxies=proxies, auth=auth)\r\nresponse2.raise_for_status()\r\n```\r\nNow launch MITM proxy on localhost\r\n\r\n```\r\n> mitmproxy -p 9000 --singleuser=frank:hunter2\r\n```\r\n\r\nThis fails with 407 for me, and proxy logs only two requests\r\n\r\n```\r\n    response2.raise_for_status()\r\n  File \"----------\", line 862, in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nrequests.exceptions.HTTPError: 407 Client Error: Proxy Authentication Required for url: http://httpbin.org/relative-redirect/1\r\n```\r\n\r\n```\r\n>> GET http://httpbin.org/\r\n       \u2190 200 text/html 11.87kB 3.57MB/s\r\n   GET http://httpbin.org/redirect/2\r\n       \u2190 302 text/html 247B 76.59kB/s\r\n\r\n```\r\nit does not log request to `Location`. \r\n\r\nI see that putting credentials in proxies dictionary somehow fixes this issue when I use MITM proxy but it doesn't fix it for my production proxy (can't share code or proxy details here, need to check closer why it doesn't work for my proxy). I guess some details in setup of proxies might vary.\r\n\r\nIs this a bug? I see some issues for proxy auth but they are mostly about HTTPS, not sure if someone reported this thing I describe here. Should this be fixed?\r\n\r\nEDIT:\r\n\r\nIt looks like this always fails if proxy password is empty string.\r\n\r\nchange auth to \r\n\r\n```python\r\nauth = HTTPProxyAuth('frank', '')\r\n\r\nproxies = {\r\n    \"http\": \"http://frank:@localhost:9000\"\r\n}\r\n```\r\n\r\nwill now always fail on redirect.\r\n\r\n```python\r\nauth = HTTPProxyAuth('frank', 'hunter2')\r\nproxies = {\r\n    \"http\": \"http://frank:hunter2@localhost:9000\"\r\n}\r\n```\r\nworks fine on redirects, but seems somewhat duplicated.\r\n\r\nI noticed this on Ubuntu 14.04, requests 2.11.1, python 2.7.6, mitmproxy 0.10.1", "patch": ""}
{"instance_id": "pandas-dev__pandas-25828", "file_changes": [{"file": "pandas/tseries/offsets.py", "changes": {"edited_modules": ["pandas/tseries/offsets.py:_CustomBusinessMonth", "pandas/tseries/offsets.py:CustomBusinessMonthEnd", "pandas/tseries/offsets.py:CustomBusinessMonthBegin"], "edited_entities": ["pandas/tseries/offsets.py:_CustomBusinessMonth", "pandas/tseries/offsets.py:CustomBusinessMonthEnd", "pandas/tseries/offsets.py:CustomBusinessMonthBegin"]}}], "repo": "pandas-dev/pandas", "base_commit": "923ac2bdee409e4fa8c47414b07f52e036bb21bc", "problem_statement": "Use Substitution Decorator for CustomBusinessMonthEnd\n\nThis is a follow up to https://github.com/pandas-dev/pandas/pull/21093/files#r188805397 which wasn't working with Py27. Now that that is a thing of the past we should be able to use the more idiomatic Substitution approach to generating this docstring", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-4744", "file_changes": [{"file": "doc/whats_new.rst", "changes": {}}, {"file": "sklearn/ensemble/forest.py", "changes": {"edited_modules": ["sklearn/ensemble/forest.py:ForestClassifier", "sklearn/ensemble/forest.py:ForestRegressor"], "edited_entities": ["sklearn/ensemble/forest.py:ForestClassifier._set_oob_score", "sklearn/ensemble/forest.py:ForestRegressor._set_oob_score"]}}, {"file": "sklearn/ensemble/tests/test_forest.py", "changes": {"edited_modules": ["sklearn/ensemble/tests/test_forest.py:test_oob_score"], "edited_entities": ["sklearn/ensemble/tests/test_forest.py:test_oob_score"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "abb31d0a7ca769a1e6406553a58a7fb0bd3b259a", "problem_statement": "Bug with using TreeClassifier with OOB score and sparse matrices\n\nWhen using the ExtraTreesClassifier (and likely other classes that are derived from BaseTreeClassifier), there is a problem when using sparsematrices: `ValueError: X should be in csr_matrix format, got <class 'scipy.sparse.csc.csc_matrix'>`.\n\nI tracked the issue down to the following lines:\n\nOn line 195 of forest.py the sparse matrix is changed to a csc matrix:\n`X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")`\n\nHowever on line 369 of forest.py, the following is call is made with `check_input=false`:\n`p_estimator = estimator.predict_proba(X[mask_indices, :], check_input=False)`\n\nThis leads to a ValueError in predict `ValueError: X should be in csr_matrix format, got <class 'scipy.sparse.csc.csc_matrix'>`.\n\nChanging check_input to True seems to fix the issue. It's probably best to also include a test case for this problem, I just made a quick PR with only the False -> True fix.", "patch": ""}
{"instance_id": "pandas-dev__pandas-22046", "file_changes": [{"file": "doc/source/whatsnew/v1.2.0.rst", "changes": {}}, {"file": "pandas/core/indexing.py", "changes": {"edited_modules": ["pandas/core/indexing.py:_LocationIndexer", "pandas/core/indexing.py:_iLocIndexer"], "edited_entities": ["pandas/core/indexing.py:_LocationIndexer.__setitem__", "pandas/core/indexing.py:_iLocIndexer", "pandas/core/indexing.py:_iLocIndexer._setitem_with_indexer", "pandas/core/indexing.py:_iLocIndexer._setitem_with_indexer_split_path", "pandas/core/indexing.py:_iLocIndexer._setitem_with_indexer_frame_value", "pandas/core/indexing.py:_iLocIndexer._setitem_single_block", "pandas/core/indexing.py:_iLocIndexer._setitem_with_indexer_missing"]}}, {"file": "pandas/tests/frame/indexing/test_setitem.py", "changes": {"edited_modules": ["pandas/tests/frame/indexing/test_setitem.py:TestDataFrameSetItem"], "edited_entities": ["pandas/tests/frame/indexing/test_setitem.py:TestDataFrameSetItem"]}}, {"file": "pandas/tests/indexing/test_iloc.py", "changes": {"edited_modules": ["pandas/tests/indexing/test_iloc.py:TestILocSeries"], "edited_entities": ["pandas/tests/indexing/test_iloc.py:TestILocSeries.test_iloc_getitem_nonunique"]}}, {"file": "pandas/tests/indexing/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/indexing/test_indexing.py:TestMisc"], "edited_entities": ["pandas/tests/indexing/test_indexing.py:TestMisc.test_rhs_alignment", "pandas/tests/indexing/test_indexing.py:TestMisc.run_tests"]}}], "repo": "pandas-dev/pandas", "base_commit": "9b4dfa195e3f23d81389745c26bff8e0087e74b0", "problem_statement": "Replacing multiple columns (or just one) with iloc does not work\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nimport pandas\r\n\r\ncolumns = pandas.DataFrame({'a2': [11, 12, 13], 'b2': [14, 15, 16]})\r\ninputs = pandas.DataFrame({'a1': [1, 2, 3], 'b1': [4, 5, 6], 'c1': [7, 8, 9]})\r\n\r\ninputs.iloc[:, [1]] = columns.iloc[:, [0]]\r\n\r\nprint(inputs)\r\n```\r\n\r\n#### Problem description\r\n\r\nI have a code which is replacing a set of columns with another set of columns, based on column indices. To make things done without a special case, I assumes I could just use `iloc` to both select and set columns in a DataFrame. But it seems that this not work and fails in strange ways.\r\n\r\n#### Expected Output\r\n\r\n```\r\n   a1  b1  c1\r\n0   1  11   7\r\n1   2  12   8\r\n2   3  13   9\r\n```\r\n\r\nBut in reality, you get:\r\n\r\n```\r\n    a1  b1   c1\r\n0  1.0 NaN  7.0\r\n1  2.0 NaN  8.0\r\n2  3.0 NaN  9.0\r\n```\r\n\r\nSee how values converted to float and how column is `NaN`s?\r\n\r\nBut, if I do the following I get expected results:\r\n\r\n```\r\ninputs.iloc[:, [1]] = [[11], [12], [13]]\r\n```\r\n\r\nThis also works:\r\n\r\n```\r\ninputs.iloc[:, [1]] = columns.iloc[:, [0]].values\r\n```\r\n\r\nSo if it works with lists and ndarrays, one would assume it would also work with DataFrames themselves. But it does not.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.13.0-46-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.23.3\r\npytest: None\r\npip: 18.0\r\nsetuptools: 40.0.0\r\nCython: None\r\nnumpy: 1.15.0\r\nscipy: None\r\npyarrow: None\r\nxarray: None\r\nIPython: None\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.7.3\r\npytz: 2018.5\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: None\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: None\r\ns3fs: None\r\nfastparquet: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-41423", "file_changes": [{"file": "pandas/core/series.py", "changes": {"edited_modules": ["pandas/core/series.py:Series"], "edited_entities": ["pandas/core/series.py:Series"]}}], "repo": "pandas-dev/pandas", "base_commit": "896256ee02273bebf723428ee41cab31930a69f4", "problem_statement": "DOC: pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n\nNo proper information on \"copy\" is present under [Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)", "patch": ""}
{"instance_id": "pandas-dev__pandas-49647", "file_changes": [{"file": "pandas/tests/apply/test_series_apply.py", "changes": {"edited_modules": ["pandas/tests/apply/test_series_apply.py:test_apply", "pandas/tests/apply/test_series_apply.py:test_map_decimal"], "edited_entities": ["pandas/tests/apply/test_series_apply.py:test_apply", "pandas/tests/apply/test_series_apply.py:test_map_decimal"]}}, {"file": "pandas/tests/arrays/test_datetimelike.py", "changes": {"edited_modules": ["pandas/tests/arrays/test_datetimelike.py:array_likes"], "edited_entities": ["pandas/tests/arrays/test_datetimelike.py:array_likes"]}}, {"file": "pandas/tests/frame/indexing/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/frame/indexing/test_indexing.py:TestDataFrameIndexing"], "edited_entities": ["pandas/tests/frame/indexing/test_indexing.py:TestDataFrameIndexing.test_setitem_ambig"]}}, {"file": "pandas/tests/frame/methods/test_to_records.py", "changes": {"edited_modules": ["pandas/tests/frame/methods/test_to_records.py:TestDataFrameToRecords"], "edited_entities": ["pandas/tests/frame/methods/test_to_records.py:TestDataFrameToRecords.test_to_records_with_Mapping_type"]}}, {"file": "pandas/tests/frame/test_constructors.py", "changes": {"edited_modules": ["pandas/tests/frame/test_constructors.py:TestDataFrameConstructors"], "edited_entities": ["pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_ordereddict", "pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_defaultdict", "pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_stdlib_array", "pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_list_of_namedtuples", "pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_list_of_dataclasses", "pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_list_of_dataclasses_with_varying_types", "pandas/tests/frame/test_constructors.py:TestDataFrameConstructors.test_constructor_list_of_dataclasses_error_thrown"]}}, {"file": "pandas/tests/groupby/test_filters.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_filters.py:test_filter_against_workaround"], "edited_entities": ["pandas/tests/groupby/test_filters.py:test_filter_against_workaround"]}}, {"file": "pandas/tests/groupby/test_grouping.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_grouping.py:TestGrouping"], "edited_entities": ["pandas/tests/groupby/test_grouping.py:TestGrouping.test_grouper_multilevel_freq"]}}, {"file": "pandas/tests/groupby/test_timegrouper.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_timegrouper.py:TestGroupBy"], "edited_entities": ["pandas/tests/groupby/test_timegrouper.py:TestGroupBy.test_first_last_max_min_on_time_data"]}}, {"file": "pandas/tests/indexes/test_common.py", "changes": {"edited_modules": ["pandas/tests/indexes/test_common.py:TestCommon"], "edited_entities": ["pandas/tests/indexes/test_common.py:TestCommon.test_copy_and_deepcopy"]}}, {"file": "pandas/tests/indexing/multiindex/test_slice.py", "changes": {"edited_modules": ["pandas/tests/indexing/multiindex/test_slice.py:TestMultiIndexSlicers"], "edited_entities": ["pandas/tests/indexing/multiindex/test_slice.py:TestMultiIndexSlicers.test_multiindex_slicers_datetimelike"]}}, {"file": "pandas/tests/io/excel/test_readers.py", "changes": {"edited_modules": ["pandas/tests/io/excel/test_readers.py:TestReaders"], "edited_entities": ["pandas/tests/io/excel/test_readers.py:TestReaders.test_read_from_file_url"]}}, {"file": "pandas/tests/io/formats/test_printing.py", "changes": {"edited_modules": ["pandas/tests/io/formats/test_printing.py:test_repr_binary_type"], "edited_entities": ["pandas/tests/io/formats/test_printing.py:test_repr_binary_type"]}}, {"file": "pandas/tests/io/formats/test_to_csv.py", "changes": {"edited_modules": ["pandas/tests/io/formats/test_to_csv.py:TestToCSV"], "edited_entities": ["pandas/tests/io/formats/test_to_csv.py:TestToCSV.test_to_csv_doublequote"]}}, {"file": "pandas/tests/io/json/test_pandas.py", "changes": {"edited_modules": ["pandas/tests/io/json/test_pandas.py:TestPandasContainer"], "edited_entities": ["pandas/tests/io/json/test_pandas.py:TestPandasContainer.test_to_s3"]}}, {"file": "pandas/tests/io/parser/test_c_parser_only.py", "changes": {"edited_modules": ["pandas/tests/io/parser/test_c_parser_only.py:test_precise_conversion"], "edited_entities": ["pandas/tests/io/parser/test_c_parser_only.py:test_precise_conversion"]}}, {"file": "pandas/tests/io/parser/test_encoding.py", "changes": {"edited_modules": ["pandas/tests/io/parser/test_encoding.py:test_utf16_bom_skiprows"], "edited_entities": ["pandas/tests/io/parser/test_encoding.py:test_utf16_bom_skiprows"]}}, {"file": "pandas/tests/io/parser/test_python_parser_only.py", "changes": {"edited_modules": ["pandas/tests/io/parser/test_python_parser_only.py:test_sniff_delimiter_encoding"], "edited_entities": ["pandas/tests/io/parser/test_python_parser_only.py:test_sniff_delimiter_encoding"]}}, {"file": "pandas/tests/io/pytables/test_store.py", "changes": {"edited_modules": ["pandas/tests/io/pytables/test_store.py:test_repr", "pandas/tests/io/pytables/test_store.py:test_table_mixed_dtypes", "pandas/tests/io/pytables/test_store.py:test_calendar_roundtrip_issue", "pandas/tests/io/pytables/test_store.py:test_same_name_scoping", "pandas/tests/io/pytables/test_store.py:test_store_index_name_numpy_str", "pandas/tests/io/pytables/test_store.py:do_copy"], "edited_entities": ["pandas/tests/io/pytables/test_store.py:test_repr", "pandas/tests/io/pytables/test_store.py:test_table_mixed_dtypes", "pandas/tests/io/pytables/test_store.py:test_calendar_roundtrip_issue", "pandas/tests/io/pytables/test_store.py:test_same_name_scoping", "pandas/tests/io/pytables/test_store.py:test_store_index_name_numpy_str", "pandas/tests/io/pytables/test_store.py:do_copy"]}}, {"file": "pandas/tests/io/test_orc.py", "changes": {"edited_modules": ["pandas/tests/io/test_orc.py:test_orc_reader_decimal"], "edited_entities": ["pandas/tests/io/test_orc.py:test_orc_reader_decimal"]}}, {"file": "pandas/tests/io/xml/test_xml.py", "changes": {"edited_modules": ["pandas/tests/io/xml/test_xml.py:test_empty_string_etree", "pandas/tests/io/xml/test_xml.py:test_wrong_file_path_etree"], "edited_entities": ["pandas/tests/io/xml/test_xml.py:test_empty_string_etree", "pandas/tests/io/xml/test_xml.py:test_wrong_file_path_etree"]}}, {"file": "pandas/tests/plotting/frame/test_frame.py", "changes": {"edited_modules": ["pandas/tests/plotting/frame/test_frame.py:TestDataFramePlots"], "edited_entities": ["pandas/tests/plotting/frame/test_frame.py:TestDataFramePlots.test_memory_leak"]}}, {"file": "pandas/tests/reshape/concat/test_concat.py", "changes": {"edited_modules": ["pandas/tests/reshape/concat/test_concat.py:TestConcatenate"], "edited_entities": ["pandas/tests/reshape/concat/test_concat.py:TestConcatenate.test_dtype_coerceion"]}}, {"file": "pandas/tests/reshape/concat/test_index.py", "changes": {"edited_modules": ["pandas/tests/reshape/concat/test_index.py:TestMultiIndexConcat"], "edited_entities": ["pandas/tests/reshape/concat/test_index.py:TestMultiIndexConcat.test_concat_multiindex_dfs_with_deepcopy"]}}, {"file": "pandas/tests/reshape/test_get_dummies.py", "changes": {"edited_modules": ["pandas/tests/reshape/test_get_dummies.py:TestGetDummies"], "edited_entities": ["pandas/tests/reshape/test_get_dummies.py:TestGetDummies.test_get_dummies_unicode"]}}, {"file": "pandas/tests/series/test_arithmetic.py", "changes": {"edited_modules": ["pandas/tests/series/test_arithmetic.py:TestSeriesArithmetic"], "edited_entities": ["pandas/tests/series/test_arithmetic.py:TestSeriesArithmetic.test_add_na_handling"]}}], "repo": "pandas-dev/pandas", "base_commit": "fa78ea801392f4f0d37ea7ddbbfe44e9c8c102bd", "problem_statement": "STYLE place standard library imports at top of file\n\nImports should typically be placed at the top of files. Sometimes, imports are placed inside functions to:\r\n- avoid circular imports\r\n- avoid `ImportError` if it's an optional dependency\r\n\r\nStandard library imports should really always be at the top of files.\r\n\r\nNoticed in https://github.com/pandas-dev/pandas/pull/49645 that this is often not the case\r\n\r\nI've made a script to automate detecting when this is the case. So the task is:\r\n```\r\ngit checkout -b standard-library-imports main\r\ngit pull git@github.com:MarcoGorelli/pandas.git standard-library-imports\r\ngit reset --hard FETCH_HEAD\r\npre-commit run stdlib-imports --all-files\r\n```\r\nThen, fixup any errors that are reported. Finally, stage your changes, commit them, push them to your fork, and open a pull request\r\n\r\nFeel free to reach out if you into any issues along the way\r\n\r\nIf any wants to take this, it would be a nice and welcome clean up!\r\n\r\n---\r\n\r\nEDIT: after going through a PR, I'm not sure it's worth introducing a check for this - but we can still take some of the cleanups it found", "patch": ""}
{"instance_id": "pallets__flask-3555", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "docs/api.rst", "changes": {}}, {"file": "docs/installation.rst", "changes": {}}, {"file": "src/flask/json/__init__.py", "changes": {"edited_modules": ["src/flask/json/__init__.py:dumps", "src/flask/json/__init__.py:loads", "src/flask/json/__init__.py:jsonify", "src/flask/json/__init__.py:JSONEncoder", "src/flask/json/__init__.py:JSONDecoder", "src/flask/json/__init__.py:_dump_arg_defaults", "src/flask/json/__init__.py:_load_arg_defaults", "src/flask/json/__init__.py:detect_encoding", "src/flask/json/__init__.py:dump", "src/flask/json/__init__.py:load", "src/flask/json/__init__.py:htmlsafe_dumps", "src/flask/json/__init__.py:htmlsafe_dump"], "edited_entities": ["src/flask/json/__init__.py:dumps", "src/flask/json/__init__.py:loads", "src/flask/json/__init__.py:jsonify", "src/flask/json/__init__.py:JSONEncoder", "src/flask/json/__init__.py:JSONEncoder.default", "src/flask/json/__init__.py:JSONDecoder", "src/flask/json/__init__.py:_dump_arg_defaults", "src/flask/json/__init__.py:_load_arg_defaults", "src/flask/json/__init__.py:detect_encoding", "src/flask/json/__init__.py:dump", "src/flask/json/__init__.py:load", "src/flask/json/__init__.py:htmlsafe_dumps", "src/flask/json/__init__.py:htmlsafe_dump"]}}, {"file": "src/flask/json/tag.py", "changes": {"edited_modules": ["src/flask/json/tag.py:TagMarkup", "src/flask/json/tag.py:TaggedJSONSerializer"], "edited_entities": ["src/flask/json/tag.py:TagMarkup", "src/flask/json/tag.py:TaggedJSONSerializer"]}}, {"file": "tests/test_helpers.py", "changes": {"edited_modules": ["tests/test_helpers.py:TestJSON"], "edited_entities": ["tests/test_helpers.py:TestJSON", "tests/test_helpers.py:TestJSON.test_template_escaping"]}}, {"file": "tox.ini", "changes": {}}], "repo": "pallets/flask", "base_commit": "024f0d384cf5bb65c76ac59f8ddce464b2dc2ca1", "problem_statement": "Remove simplejson\n\nIn modern Python it's unlikely to be significantly better than the built-in `json`. The module used by `JSONMixin` is overridable, so users can plug it in again if they want.\r\n\r\nSee pallets/itsdangerous#146 and pallets/werkzeug#1766.", "patch": ""}
{"instance_id": "pandas-dev__pandas-5420", "file_changes": [{"file": "doc/source/v0.14.1.txt", "changes": {}}, {"file": "pandas/core/index.py", "changes": {"edited_modules": ["pandas/core/index.py:Index"], "edited_entities": ["pandas/core/index.py:Index._convert_list_indexer_for_mixed"]}}, {"file": "pandas/tests/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/test_indexing.py:TestIndexing"], "edited_entities": ["pandas/tests/test_indexing.py:TestIndexing"]}}], "repo": "pandas-dev/pandas", "base_commit": "324208eaa66a528f1e88f938c71c2d8efb8304f3", "problem_statement": "BUG: loc should not fallback for integer indexing for multi-index\n\nhttps://groups.google.com/forum/m/#!topic/pydata/W0e3l0UvNwI", "patch": ""}
{"instance_id": "pandas-dev__pandas-3561", "file_changes": [{"file": "RELEASE.rst", "changes": {}}, {"file": "doc/source/indexing.rst", "changes": {}}, {"file": "pandas/core/index.py", "changes": {"edited_modules": ["pandas/core/index.py:Index"], "edited_entities": ["pandas/core/index.py:Index"]}}, {"file": "pandas/core/indexing.py", "changes": {"edited_modules": ["pandas/core/indexing.py:_NDFrameIndexer"], "edited_entities": ["pandas/core/indexing.py:_NDFrameIndexer._getitem_iterable", "pandas/core/indexing.py:_NDFrameIndexer._convert_to_indexer"]}}, {"file": "pandas/index.pyx", "changes": {}}, {"file": "pandas/lib.pyx", "changes": {}}, {"file": "pandas/tests/test_frame.py", "changes": {"edited_modules": ["pandas/tests/test_frame.py:TestDataFrame"], "edited_entities": ["pandas/tests/test_frame.py:TestDataFrame._check_df"]}}, {"file": "pandas/tests/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/test_indexing.py:TestIndexing"], "edited_entities": ["pandas/tests/test_indexing.py:TestIndexing"]}}], "repo": "pandas-dev/pandas", "base_commit": "6d2c57fa010c12f21f700034b5651519670b9b9d", "problem_statement": "DataFrame.ix losing row ordering when index has duplicates\n\n``` python\nimport pandas as pd\n\nind = ['A', 'A', 'B', 'C']i\ndf = pd.DataFrame({'test':range(len(ind))}, index=ind)\n\nrows = ['C', 'B']\nres = df.ix[rows]\nassert rows == list(res.index) # fails\n```\n\nThe problem is that the resulting DataFrame keeps the ordering of the `df.index` and not the `rows` key. You'll notice that the `rows` key doesn't reference a duplicate value.", "patch": ""}
{"instance_id": "pandas-dev__pandas-18734", "file_changes": [{"file": "pandas/tests/apply/test_frame_apply.py", "changes": {"edited_modules": ["pandas/tests/apply/test_frame_apply.py:test_agg_list_like_func_with_args"], "edited_entities": ["pandas/tests/apply/test_frame_apply.py:test_agg_list_like_func_with_args"]}}], "repo": "pandas-dev/pandas", "base_commit": "bcc5160b3a5b0fc9c531da194c6bb83619045434", "problem_statement": "ddof for np.std in df.agg changes depending on how given & lambda expression does not work correctly in a list of functions\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [31]: import numpy as np\r\n\r\nIn [32]: import pandas as pd\r\n\r\nIn [33]: df = pd.DataFrame(np.arange(6).reshape(3, 2), columns=['A', 'B'])\r\n\r\nIn [34]: df\r\nOut[34]:\r\n   A  B\r\n0  0  1\r\n1  2  3\r\n2  4  5\r\n\r\nIn [35]: df.agg(np.std)  # Behavior of ddof=0\r\nOut[35]:\r\nA    1.632993\r\nB    1.632993\r\ndtype: float64\r\n\r\nIn [36]: df.agg([np.std])  # Behavior of ddof=1\r\nOut[36]:\r\n       A    B\r\nstd  2.0  2.0\r\n\r\nIn [37]: # So how to get the ddof=0 behavior when giving a list of functions?\r\n\r\nIn [39]: df.agg([lambda x: np.std(x)])  # This gives a numerically unexpected result.\r\nOut[39]:\r\n         A        B\r\n  <lambda> <lambda>\r\n0      0.0      0.0\r\n1      0.0      0.0\r\n2      0.0      0.0\r\n\r\nIn [40]: df.agg([np.mean, lambda x: np.std(x)])  # This gives an error.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-40-52f4ec4195b5> in <module>()\r\n----> 1 df.agg([np.mean, lambda x: np.std(x)])\r\n\r\n/Users/ikeda/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/pandas/core/frame.py in aggregate(self, func, axis, *args, **kwargs)\r\n   4740         if axis == 0:\r\n   4741             try:\r\n-> 4742                 result, how = self._aggregate(func, axis=0, *args, **kwargs)\r\n   4743             except TypeError:\r\n   4744                 pass\r\n\r\n/Users/ikeda/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/pandas/core/base.py in _aggregate(self, arg, *args, **kwargs)\r\n    537             return self._aggregate_multiple_funcs(arg,\r\n    538                                                   _level=_level,\r\n--> 539                                                   _axis=_axis), None\r\n    540         else:\r\n    541             result = None\r\n\r\n/Users/ikeda/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/pandas/core/base.py in _aggregate_multiple_funcs(self, arg, _level, _axis)\r\n    594         # if we are empty\r\n    595         if not len(results):\r\n--> 596             raise ValueError(\"no results\")\r\n    597\r\n    598         try:\r\n\r\nValueError: no results\r\n\r\n```\r\n#### Problem description\r\n\r\nWhen using, e.g., `df.agg`, the `ddof` (degrees of freedom) value for the function `np.std` changes depending on how the function is given (single function or a list of functions), which may be so confusing for many people. I believe the behavior should be unified in some way.\r\n\r\nFurthermore, I could not find the way to obtain to the `np.std` result with `ddof=0` by supplying it as one of the members of a list of functions. The `lambda` expression does not work well in a list of functions (this gives numerically unexpected results or even gives errors). This prohibits us to use many useful methods like `df.agg`, `df.apply`, and `df.describe` when we hope the `ddof=0` behavior. \r\n\r\nFrom https://github.com/pandas-dev/pandas/issues/13344, I guess Developers prefer the `ddof=1` behavior in pandas. So the expected behavior should be as below.\r\n\r\n#### Expected Output\r\n```\r\nIn [35]: df.agg(np.std)  # Behavior of ddof=1\r\nOut[35]:\r\nA    2.0\r\nB    2.0\r\ndtype: float64\r\n\r\nIn [38]: df.agg([lambda x: np.std(x)])  # To obtain the ddof=0 results\r\nOut[38]:\r\n                     A             B\r\n<lambda>      1.632993      1.632993\r\n\r\nIn [41]: df.agg([np.mean, lambda x: np.std(x)])\r\n                     A             B\r\nmean          2.0           3.0\r\n<lambda>      1.632993      1.632993\r\n```\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\n\r\npandas: 0.21.0\r\npytest: 3.0.7\r\npip: 9.0.1\r\nsetuptools: 27.2.0\r\nCython: 0.25.2\r\nnumpy: 1.13.3\r\nscipy: 0.19.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 5.3.0\r\nsphinx: 1.5.6\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.3.0\r\nnumexpr: 2.6.2\r\nfeather: None\r\nmatplotlib: 2.0.2\r\nopenpyxl: 2.4.7\r\nxlrd: 1.0.0\r\nxlwt: 1.2.0\r\nxlsxwriter: 0.9.6\r\nlxml: 3.7.3\r\nbs4: 4.6.0\r\nhtml5lib: 0.999\r\nsqlalchemy: 1.1.9\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\nfastparquet: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n\r\n</details>", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-29742", "file_changes": [{"file": "doc/Makefile", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "c13703c8dfb7324a05a82e8befe9b203a6590257", "problem_statement": "spin docs --no-plot runs the examples\n\nSeen at the EuroScipy sprint\r\n\r\nCommands run by spin:\r\n```\r\n$ export SPHINXOPTS=-W -D plot_gallery=0 -j auto\r\n$ cd doc\r\n$ make html\r\n```\r\n\r\nLooks like our Makefile does not use SPHINXOPTS the same way as expected:\r\nProbably we have a slightly different way of building the doc\r\n\r\n```\r\n\u276f make html-noplot -n\r\nsphinx-build -D plot_gallery=0 -b html -d _build/doctrees  -T  . -jauto \\\r\n    _build/html/stable\r\necho\r\necho \"Build finished. The HTML pages are in _build/html/stable.\"\r\n```", "patch": ""}
{"instance_id": "huggingface__transformers-15640", "file_changes": [{"file": "src/transformers/models/gptj/modeling_gptj.py", "changes": {"edited_modules": ["src/transformers/models/gptj/modeling_gptj.py:apply_rotary_pos_emb"], "edited_entities": ["src/transformers/models/gptj/modeling_gptj.py:apply_rotary_pos_emb"]}}], "repo": "huggingface/transformers", "base_commit": "147c8166852db64de12b851b8307f44c9e8fe0dd", "problem_statement": "Add support for ONNX-TensorRT conversion for GPT-J6B (and possible bug in rotary embedding)\n\n### Who can help\r\n@patil-suraj \r\n\r\n## Information\r\n\r\nModel I am using: GPT-J\r\n\r\nThe problem arises when using:\r\n* [x] the official example scripts: (give details below)\r\n* [x] my own modified scripts: (give details below)\r\n\r\n## Description\r\nI opened this issue for two reasons:\r\n1. This is not strictly a bug report, rather a change that enables converting this model to ONNX and then parsing it using the current TensorRT ONNX parser.\r\n2. Possible implementation bug in GPT-J.\r\n\r\n## Details\r\n1. When exporting GPT-J to ONNX using the latest version (v4.16.2), one of the ops that is exported is [SplitToSequence](https://github.com/onnx/onnx/blob/main/docs/Operators.md#SplitToSequence) (along with more Sequence* ops) that is currently not supported in the [TensorRT ONNX parser](https://github.com/onnx/onnx-tensorrt/blob/master/docs/operators.md).\r\nThis is entirely due to just 1 line of code that uses `torch.repeat_interleave`. ([relevant line](https://github.com/huggingface/transformers/blob/52d2e6f6e904ef9b75c78716ce77b98196ed837a/src/transformers/models/gptj/modeling_gptj.py#L67))\r\n```\r\nsin, cos = map(lambda t: t[None, offset : x.shape[1] + offset, None, :].repeat_interleave(2, 3), sincos)\r\n```\r\nBy replacing `lambda t` with this:\r\n```\r\nlambda t: t.view(-1, 1).repeat(1, 2).view(seq_len, -1)[None, offset : x.shape[1] + offset, None, :]\r\n```\r\nwe get the exact same output tensors but now exporting to ONNX doesn't include any Sequence* ops, and TensorRT can parse it successfully.\r\nThe suggested function is even faster, although probably not critical in this huge model (benched only on CPU):\r\n```\r\noriginal: 106 \u00b5s \u00b1 20.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\nsuggested: 32.4 \u00b5s \u00b1 6.55 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n```\r\n\r\n2. I was following the implementation in EleutherAI for rotary positional embeddings and I'm trying to understand if this is a bug or I'm simply missing something (would love an explanation if you can spare the time) but there (EleutherAI) they implement this function (rotary positional embedding) using `torch.cat` instead of `torch.repeat_interleave`, as can be seen [here](https://github.com/EleutherAI/gpt-neox/blob/b30afd1d0a1d06220be9b5f2c9c9c1523defba96/megatron/model/positional_embeddings.py#L41).\r\n\r\nIf I'm not missing something, the EleutherAI version transforms a tensor from\r\n```\r\n[[1,2,3],\r\n [4,5,6]]\r\n```\r\nto \r\n```\r\n[[1,2,3,1,2,3],\r\n [4,5,6,4,5,6]]\r\n```\r\nand HF version (using repeat_interleave):\r\n```\r\n[[1,2,3],\r\n [4,5,6]]\r\n```\r\nto \r\n```\r\n[[1,1,2,2,3,3],\r\n [4,4,5,5,6,6]]\r\n```\r\nCan anyone confirm the current implementation is indeed correct? Because otherwise `cat` and `repeat_interleave` are very different, and the rest of the implementation doesn't take it into account.", "patch": ""}
{"instance_id": "psf__requests-1995", "file_changes": [{"file": "setup.py", "changes": {}}], "repo": "psf/requests", "base_commit": "95161ed313db11296c3bd473336340dbb19bb347", "problem_statement": "Create an Extra for Better SSL Support\n\nSo right now the SSL connections when you use pyOpenSSL, ndg-httspclient, and pyasn1 are more secure than if you just use the stdlib options. However it's hard to actually remember those three things. It would be cool if requests would add an extra to it's setup.py so that people can install requests with betterssl, something like:\n\n``` python\nsetup(\n    extras_require={\n        \"betterssl\": [\"pyOpenSSL\", \"ndg-httpsclient\", \"pyasn1\"],\n    },\n)\n```\n\nWould make it so people can install requests like `pip install requests[betterssl]` and get all of those dependencies without having to manually track those down. It also means people could depend on `requests[betterssl]` instead of just `requests` in their own setup.py's.\n\nExtra name can of course be bikeshed here :)", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-2185", "file_changes": [{"file": "sklearn/cluster/k_means_.py", "changes": {"edited_modules": ["sklearn/cluster/k_means_.py:_labels_inertia_precompute_dense", "sklearn/cluster/k_means_.py:_labels_inertia", "sklearn/cluster/k_means_.py:_mini_batch_step", "sklearn/cluster/k_means_.py:KMeans", "sklearn/cluster/k_means_.py:MiniBatchKMeans"], "edited_entities": ["sklearn/cluster/k_means_.py:_labels_inertia_precompute_dense", "sklearn/cluster/k_means_.py:_labels_inertia", "sklearn/cluster/k_means_.py:_mini_batch_step", "sklearn/cluster/k_means_.py:KMeans", "sklearn/cluster/k_means_.py:KMeans.transform", "sklearn/cluster/k_means_.py:MiniBatchKMeans", "sklearn/cluster/k_means_.py:MiniBatchKMeans.fit", "sklearn/cluster/k_means_.py:MiniBatchKMeans.partial_fit"]}}, {"file": "sklearn/cluster/tests/test_k_means.py", "changes": {"edited_modules": ["sklearn/cluster/tests/test_k_means.py:test_minibatch_reassign"], "edited_entities": ["sklearn/cluster/tests/test_k_means.py:test_minibatch_reassign"]}}, {"file": "sklearn/utils/setup.py", "changes": {"edited_modules": ["sklearn/utils/setup.py:configuration"], "edited_entities": ["sklearn/utils/setup.py:configuration"]}}, {"file": "sklearn/utils/tests/test_extmath.py", "changes": {"edited_modules": ["sklearn/utils/tests/test_extmath.py:test_random_weights"], "edited_entities": ["sklearn/utils/tests/test_extmath.py:test_random_weights"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "14d03f60ed366df942be09ee4bc394a69958e09c", "problem_statement": "MinibatchKMeans bad center reallocation causes duplicate centers\n\nFor instance have a look at:\n\n  http://scikit-learn.org/dev/auto_examples/cluster/plot_dict_face_patches.html\n\nsome of the centroids are duplicated, presumably because of a bug in the bad cluster reallocation heuristic.", "patch": ""}
{"instance_id": "psf__requests-1650", "file_changes": [{"file": "requests/adapters.py", "changes": {"edited_modules": ["requests/adapters.py:HTTPAdapter"], "edited_entities": ["requests/adapters.py:HTTPAdapter.send"]}}, {"file": "requests/exceptions.py", "changes": {}}], "repo": "psf/requests", "base_commit": "9968a10fcfad7268b552808c4f8946eecafc956a", "problem_statement": "Requests doesn't catch requests.packages.urllib3.exceptions.ProxyError\n\nRequests doesn't catch requests.packages.urllib3.exceptions.ProxyError and translate it into a requests module specific exception which derives from RequestException as it does for other errors originating from urllib3. This means if trying to catch any exception derived from RequestException so as to treat it specially, the urllib3 ProxyError will be missed.", "patch": ""}
{"instance_id": "huggingface__transformers-8171", "file_changes": [{"file": "docs/source/model_doc/dpr.rst", "changes": {}}, {"file": "src/transformers/__init__.py", "changes": {}}, {"file": "src/transformers/convert_pytorch_checkpoint_to_tf2.py", "changes": {}}, {"file": "src/transformers/modeling_tf_auto.py", "changes": {}}, {"file": "src/transformers/utils/dummy_pt_objects.py", "changes": {}}, {"file": "src/transformers/utils/dummy_tf_objects.py", "changes": {}}, {"file": "tests/test_modeling_dpr.py", "changes": {"edited_modules": ["tests/test_modeling_dpr.py:DPRModelTest"], "edited_entities": ["tests/test_modeling_dpr.py:DPRModelTest.test_model_from_pretrained"]}}, {"file": "utils/check_repo.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "eb3bd73ce35bfef56eeb722d697f2d39a06a8f8d", "problem_statement": "Need suggestion on contributing TFDPR\n\n# \ud83c\udf1f New model addition\r\n\r\n## Model description\r\nHi, I would love to try contributing TFDPR . This is the first time to me, so I need some suggestions.\r\nI have followed @sshleifer 's [great PR on TFBart model](https://github.com/huggingface/transformers/commit/829842159efeb1f920cbbb1daf5ad67e0114d0b9) on 4 files :` __init__.py , convert_pytorch_checkpoint_to_tf2.py , utils/dummy_tf_objects.py` and (newly created) `modeling_tf_dpr.py `\r\n\r\nNow the TF model works properly and can load Pytorch's weights successfully the same output as Pytorch's counterparts **except** small random noise (1e-5) which I suspect of some dtypes different , but I could not find the cause. \r\n\r\nI guess I need to add document on  docs/source/model_doc/dpr.rst , and that's all ? \r\n**My question is do I need to change / fix any other files ? and/or do I need to do some other thing before making PR ?**\r\n\r\n<!-- Important information -->\r\nTo resolve TF vs. Pytorch naming issues, there's one change regarding `TFBertModel` vs. `TFBertMainLayer` as [discussed here](https://discuss.huggingface.co/t/solved-issue-on-translating-dpr-to-tfdpr-on-loading-pytorch-weights-to-tf-model/1764) .\r\nThanks to @sshleifer for his help to solve the issue.\r\n\r\n## Open source status\r\n\r\n* [X] the model implementation is available: (give details)\r\nYou can see all the modified codes with test run at : \r\nhttps://colab.research.google.com/drive/1lU4fx7zkr-Y3CXa3wmHIY8yJhKdiN3DI?usp=sharing\r\n(to easily navigate the changes, please \u201cfind on page\u201d for e.g. `TFDPRContextEncoder` )\r\n\r\n* [X] the model weights are available: (give details)\r\nAt the moment, I use existing Pytorch weights, but will upload TF weights too.\r\n\r\n* [X] who are the authors: (mention them, if possible by @gh-username)\r\n@ratthachat", "patch": ""}
{"instance_id": "huggingface__transformers-34390", "file_changes": [{"file": "src/transformers/models/mask2former/modeling_mask2former.py", "changes": {"edited_modules": ["src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoder", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderMultiscaleDeformableAttention", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderLayer", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderOnly", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerMaskedAttentionDecoder"], "edited_entities": ["src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoder.forward", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderMultiscaleDeformableAttention.forward", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderLayer.forward", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderOnly", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderOnly.get_reference_points", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerPixelDecoderEncoderOnly.forward", "src/transformers/models/mask2former/modeling_mask2former.py:Mask2FormerMaskedAttentionDecoder.forward"]}}, {"file": "tests/models/mask2former/test_modeling_mask2former.py", "changes": {"edited_modules": ["tests/models/mask2former/test_modeling_mask2former.py:Mask2FormerModelIntegrationTest"], "edited_entities": ["tests/models/mask2former/test_modeling_mask2former.py:Mask2FormerModelIntegrationTest.test_with_segmentation_maps_and_loss"]}}], "repo": "huggingface/transformers", "base_commit": "9bee9ff5db6e68fb31065898d7e924d07c1eb9c1", "problem_statement": "[mask2former] torch.export error for Mask2Former\n\n### System Info\r\n\r\n- `transformers` version: 4.46.0.dev0\r\n- Platform: Linux-6.8.0-47-generic-x86_64-with-glibc2.35\r\n- Python version: 3.11.9\r\n- Huggingface_hub version: 0.25.2\r\n- Safetensors version: 0.4.5\r\n- Accelerate version: not installed\r\n- Accelerate config: not found\r\n- PyTorch version (GPU?): 2.4.1+cu121 (True)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Flax version (CPU?/GPU?/TPU?): not installed (NA)\r\n- Jax version: not installed\r\n- JaxLib version: not installed\r\n- Using distributed or parallel set-up in script?: <fill in>\r\n- Using GPU in script?: <fill in>\r\n- GPU type: NVIDIA GeForce RTX 4090\r\n\r\n### Who can help?\r\n\r\n@amyeroberts, @qubvel, @ylacombe\r\n\r\n### Information\r\n\r\n- [ ] The official example scripts\r\n- [X] My own modified scripts\r\n\r\n### Tasks\r\n\r\n- [X] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\r\n- [ ] My own task or dataset (give details below)\r\n\r\n### Reproduction\r\n\r\n```python\r\nimport torch\r\nfrom transformers import Mask2FormerForUniversalSegmentation\r\n\r\nmodel = Mask2FormerForUniversalSegmentation.from_pretrained(\r\n    \"facebook/mask2former-swin-base-coco-panoptic\", torchscript=True\r\n)\r\n\r\nscripted_model = torch.export.export(model, args=(torch.randn(1, 3, 800, 1280),))\r\n```\r\nwhich causes\r\n```\r\nUserError: Could not extract specialized integer from data-dependent expression u0 (unhinted: u0).  (Size-like symbols: none)\r\n\r\nPotential framework code culprit (scroll up for full backtrace):\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 2132, in run_node\r\n    return node.target(*args, **kwargs)\r\n\r\nFor more information, run with TORCH_LOGS=\"dynamic\"\r\nFor extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\"\r\nIf you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\r\nFor more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing\r\n\r\nUser Stack (most recent call last):\r\n  (snipped, see stack below for prefix)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 2499, in forward\r\n    outputs = self.model(\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 2270, in forward\r\n    pixel_level_module_output = self.pixel_level_module(\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1395, in forward\r\n    decoder_output = self.decoder(backbone_features, output_hidden_states=output_hidden_states)\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1319, in forward\r\n    encoder_outputs = self.encoder(\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1165, in forward\r\n    reference_points = self.get_reference_points(spatial_shapes, valid_ratios, device=inputs_embeds.device)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1106, in get_reference_points\r\n    torch.linspace(0.5, height - 0.5, height, dtype=valid_ratios.dtype, device=device),\r\n\r\nFor C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1\r\nFor more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#constrain-as-size-example\r\n\r\nfrom user code:\r\n   File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 2499, in forward\r\n    outputs = self.model(\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 2270, in forward\r\n    pixel_level_module_output = self.pixel_level_module(\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1395, in forward\r\n    decoder_output = self.decoder(backbone_features, output_hidden_states=output_hidden_states)\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1319, in forward\r\n    encoder_outputs = self.encoder(\r\n  File \"/home/philkuz/.pyenv/versions/3.11.9/envs/gml311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1165, in forward\r\n    reference_points = self.get_reference_points(spatial_shapes, valid_ratios, device=inputs_embeds.device)\r\n  File \"/home/philkuz/dev/transformers/src/transformers/models/mask2former/modeling_mask2former.py\", line 1106, in get_reference_points\r\n    torch.linspace(0.5, height - 0.5, height, dtype=valid_ratios.dtype, device=device),\r\n ```\r\n\r\n### Expected behavior\r\n\r\ntorch.export works for this model.", "patch": ""}
{"instance_id": "pandas-dev__pandas-22471", "file_changes": [{"file": "pandas/tests/frame/common.py", "changes": {}}, {"file": "pandas/tests/frame/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/frame/test_indexing.py:TestDataFrameIndexing", "pandas/tests/frame/test_indexing.py:TestDataFrameIndexingDatetimeWithTZ", "pandas/tests/frame/test_indexing.py:TestDataFrameIndexingUInt64"], "edited_entities": ["pandas/tests/frame/test_indexing.py:TestDataFrameIndexing", "pandas/tests/frame/test_indexing.py:TestDataFrameIndexing.test_setitem_fancy_mixed_2d", "pandas/tests/frame/test_indexing.py:TestDataFrameIndexingDatetimeWithTZ", "pandas/tests/frame/test_indexing.py:TestDataFrameIndexingUInt64"]}}, {"file": "pandas/tests/frame/test_query_eval.py", "changes": {"edited_modules": ["pandas/tests/frame/test_query_eval.py:TestDataFrameQueryNumExprPython", "pandas/tests/frame/test_query_eval.py:TestDataFrameQueryPythonPandas", "pandas/tests/frame/test_query_eval.py:TestDataFrameQueryPythonPython"], "edited_entities": ["pandas/tests/frame/test_query_eval.py:TestDataFrameQueryNumExprPython.setup_class", "pandas/tests/frame/test_query_eval.py:TestDataFrameQueryPythonPandas.setup_class", "pandas/tests/frame/test_query_eval.py:TestDataFrameQueryPythonPython.setup_class"]}}], "repo": "pandas-dev/pandas", "base_commit": "953757a3e37ffb80570a20a8eca52dae35fc27bb", "problem_statement": "TST/CLN: remove TestData from frame-tests; replace with fixtures\n\nFollowing review in #22236: \r\n> ok, pls open a new issue that refs this, to remove use of `TestData` in favor of fixtures\r\n\r\nStarted the process in that PR by creating a `conftest.py` that translates all the current attributes of `TestData` to fixtures, with the following \"translation guide\":\r\n\r\n* `frame` -> `float_frame`\r\n* `frame2` -> `float_frame2`\r\n* `intframe` -> `int_frame`\r\n* `tsframe` -> `datetime_frame`\r\n* `mixed_frame` -> `float_string_frame`\r\n* `mixed_float` -> `mixed_float_frame`\r\n* `mixed_float2` -> `mixed_float_frame2`\r\n* `mixed_int` -> `mixed_int_frame`\r\n* `all_mixed` -> `mixed_type_frame`\r\n* `tzframe` -> `timezone_frame`\r\n* `empty` -> `empty_frame`\r\n* `ts1` -> `datetime_series`\r\n* `ts2` -> `datetime_series_short`\r\n* `simple` -> `simple_frame`\r\n\r\nNeed to incrementally replace their usages in `pandas/tests/frame/` (example below).\r\n\r\n- [x] Create `conftest.py` and translate `TestData`-attributes into fixtures (#22236)\r\n- [x] `test_alter_axes.py` (#22236)\r\n- [x] `test_analytics.py` (#22733)\r\n- [x] `test_api.py` (#22738)\r\n- [x] `test_apply.py` (#22735)\r\n- [x] `test_arithmetic.py` (#22736)\r\n- [x] `test_asof.py` (#25628)\r\n- [x] `test_axis_select_reindex.py` (#25627)\r\n- [x] `test_block_internals.py` (#22926)\r\n- [x] `test_combine_concat.py` (#25634)\r\n- [ ] `test_constructors.py` (#25635)\r\n- [ ] `test_convert_to.py`\r\n- [ ] `test_dtypes.py` (#25636)\r\n- [x] `test_duplicates.py`\r\n- [x] `test_indexing.py` (#25633)\r\n- [x] `test_join.py` (#25639)\r\n- [x] `test_missing.py` (#25640)\r\n- [x] `test_mutate_columns.py` (#25642)\r\n- [ ] `test_nonunique_indexes.py`\r\n- [x] `test_operators.py` (#25641)\r\n- [ ] `test_period.py`\r\n- [ ] `test_quantile.py`\r\n- [ ] `test_query_eval.py`\r\n- [ ] `test_rank.py`\r\n- [ ] `test_replace.py`\r\n- [ ] `test_repr_info.py`\r\n- [ ] `test_reshape.py`\r\n- [ ] `test_sort_values_level_as_str.py`\r\n- [ ] `test_sorting.py`\r\n- [ ] `test_subclass.py`\r\n- [ ] `test_timeseries.py`\r\n- [ ] `test_timezones.py`\r\n- [ ] `test_to_csv.py`\r\n- [ ] `test_validate.py`\r\n\r\nThings for follow-ups:\r\n- Remove other class-based test-methods\r\n- Turn tests from class- to function-based\r\n\r\nAn example from #22236 - before:\r\n```\r\ndef test_set_columns(self):\r\n    cols = Index(np.arange(len(self.mixed_frame.columns)))\r\n    self.mixed_frame.columns = cols\r\n    with tm.assert_raises_regex(ValueError, 'Length mismatch'):\r\n        self.mixed_frame.columns = cols[::2]\r\n```\r\nAfter:\r\n```\r\ndef test_set_columns(self, float_string_frame):\r\n    cols = Index(np.arange(len(float_string_frame.columns)))\r\n    float_string_frame.columns = cols\r\n    with tm.assert_raises_regex(ValueError, 'Length mismatch'):\r\n        float_string_frame.columns = cols[::2]\r\n```\r\n\r\nBasically, it comes down to replacing all the occurrences of `self.<name>` with `translation_guide[<name>]` (and specifying`<name>` as a parameter to the function).\r\n\r\nPS. Note that some fixtures added by #22236 have now been removed by #24885. Please check #24885 which code was removed, in case you should need it for the fixturisation. Alternatively, you can ping me, @jbrockmendel or @jreback.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-2372", "file_changes": [{"file": "doc/modules/cross_validation.rst", "changes": {}}, {"file": "doc/tutorial/statistical_inference/model_selection.rst", "changes": {}}, {"file": "doc/whats_new.rst", "changes": {}}, {"file": "sklearn/cross_validation.py", "changes": {"edited_modules": ["sklearn/cross_validation.py:StratifiedKFold"], "edited_entities": ["sklearn/cross_validation.py:StratifiedKFold.__init__", "sklearn/cross_validation.py:StratifiedKFold"]}}, {"file": "sklearn/feature_selection/tests/test_rfe.py", "changes": {"edited_modules": ["sklearn/feature_selection/tests/test_rfe.py:test_rfecv"], "edited_entities": ["sklearn/feature_selection/tests/test_rfe.py:test_rfecv"]}}, {"file": "sklearn/tests/test_cross_validation.py", "changes": {"edited_modules": ["sklearn/tests/test_cross_validation.py:test_kfold_valueerrors", "sklearn/tests/test_cross_validation.py:test_kfold_indices", "sklearn/tests/test_cross_validation.py:test_shuffle_kfold", "sklearn/tests/test_cross_validation.py:test_cross_val_score_with_score_func_classification", "sklearn/tests/test_cross_validation.py:test_permutation_score"], "edited_entities": ["sklearn/tests/test_cross_validation.py:test_kfold_valueerrors", "sklearn/tests/test_cross_validation.py:test_kfold_indices", "sklearn/tests/test_cross_validation.py:test_shuffle_kfold", "sklearn/tests/test_cross_validation.py:test_cross_val_score_with_score_func_classification", "sklearn/tests/test_cross_validation.py:test_permutation_score"]}}, {"file": "sklearn/tests/test_naive_bayes.py", "changes": {"edited_modules": ["sklearn/tests/test_naive_bayes.py:test_check_accuracy_on_digits"], "edited_entities": ["sklearn/tests/test_naive_bayes.py:test_check_accuracy_on_digits"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "130601e076ec5ca8298b95c3d02122ac5d8cf8eb", "problem_statement": "StratifiedKFold should do its best to preserve the dataset dependency structure\n\nAs highlighted in this [notebook](http://nbviewer.ipython.org/urls/raw.github.com/ogrisel/notebooks/master/Non%2520IID%2520cross-validation.ipynb) the current implementation of `StratifiedKFold` (which is used by default by `cross_val_score` and `GridSearchCV` for classification problems) breaks the dependency structure of the dataset by computing the folds based on the sorted labels.\n\nInstead one should probably do an implementation that performs individual dependency preserving KFold on for each possible label value and aggregate the folds to get the `StratifiedKFold` final folds.\n\nThis might incur a refactoring to get rid of the `_BaseKFold` base class. It might also make it easier to implement a `shuffle=True` option for `StratifiedKFold`.", "patch": ""}
{"instance_id": "pandas-dev__pandas-26139", "file_changes": [{"file": "pandas/io/pytables.py", "changes": {"edited_modules": ["pandas/io/pytables.py:HDFStore"], "edited_entities": ["pandas/io/pytables.py:HDFStore"]}}], "repo": "pandas-dev/pandas", "base_commit": "dc86509b44b3fb0cd9a1a6d6ed564b082dc50848", "problem_statement": "Doc for HDFStore compression unclear on what the default value of None does\n\nThe doc for the `HDFStore` class mentions:\r\n\r\n```    \r\ncomplevel : int, 0-9, default None\r\n            Specifies a compression level for data.\r\n            A value of 0 disables compression.\r\n```\r\n\r\nThat doesn't actually answer the question of what compression level is used when the default (None) is used, though. Is None translated further down to 0? it turns out yes, but you have to dig in the code to actually figure that out. And it could as well have been translated eventually to any other value.\r\n\r\nTwo options:\r\n1. Actually change the default in the `complevel` argument to be \"0\". (It's an immutable object, so it's fine as a default value for a function argument.)\r\n2. Just adjust the doc in some way.\r\n\r\nWhen the right solution is decided, I can do a pull request with it. Thanks!", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-3689", "file_changes": [{"file": "sklearn/cross_validation.py", "changes": {"edited_modules": ["sklearn/cross_validation.py:_fit_and_predict", "sklearn/cross_validation.py:_fit_and_score"], "edited_entities": ["sklearn/cross_validation.py:_fit_and_predict", "sklearn/cross_validation.py:_fit_and_score"]}}, {"file": "sklearn/tests/test_cross_validation.py", "changes": {"edited_modules": ["sklearn/tests/test_cross_validation.py:assert_fit_params"], "edited_entities": ["sklearn/tests/test_cross_validation.py:assert_fit_params"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "439c19596a248a31cd1aa8220f54a622a0322160", "problem_statement": "using sparse matrix in fit_params\n\nWhen the value of a fit_params is sparse matrix, it will raise error from the following code.\nsklearn/cross_validation.py\n\n```\n1224                       if hasattr(v, '__len__') and len(v) == n_samples else v)\n1225                       for k, v in fit_params.items()])\n```\n\nIt is because the `__len__` of sparse matrix is defined as\nscipy/sparse/base.py\n\n```\n190    def __len__(self):\n191        # return self.getnnz()\n192        raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n193                         \" or shape[0]\")\n```\n\nIs there anyway to circumpass this issue. I do not want to convert the sparse matrix into a dense one, since it will consume a big memory.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-9174", "file_changes": [{"file": "doc/modules/multiclass.rst", "changes": {}}, {"file": "doc/modules/svm.rst", "changes": {}}, {"file": "doc/whats_new/v0.21.rst", "changes": {}}, {"file": "sklearn/svm/base.py", "changes": {"edited_modules": ["sklearn/svm/base.py:BaseSVC"], "edited_entities": ["sklearn/svm/base.py:BaseSVC.decision_function"]}}, {"file": "sklearn/utils/estimator_checks.py", "changes": {"edited_modules": ["sklearn/utils/estimator_checks.py:check_methods_subset_invariance"], "edited_entities": ["sklearn/utils/estimator_checks.py:check_methods_subset_invariance"]}}, {"file": "sklearn/utils/multiclass.py", "changes": {"edited_modules": ["sklearn/utils/multiclass.py:_ovr_decision_function"], "edited_entities": ["sklearn/utils/multiclass.py:_ovr_decision_function"]}}, {"file": "sklearn/utils/tests/test_multiclass.py", "changes": {"edited_modules": ["sklearn/utils/tests/test_multiclass.py:test_safe_split_with_precomputed_kernel"], "edited_entities": ["sklearn/utils/tests/test_multiclass.py:test_safe_split_with_precomputed_kernel"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "adc1e590d4dc1e230b49a4c10b4cd7b672bb3d69", "problem_statement": "SVC and OneVsOneClassifier decision_function inconsistent on sub-sample\n\nHi,\r\n\r\nI'm seeing inconsistent numerical results with SVC's decision_function.\r\nWhen estimated over an entire batch of samples ( (n_samples, n_features) matrix ) compared to analyzing sample-by-sample, the results are not the same.\r\nThis is true for both the individual numerical values per sample and the overall distribution of the results.\r\n\r\n**The model is SVC with RBF kernel, for a 3-class classification:**\r\n```\r\nSVC(C=1.0, gamma=0.007, class_weight = new_class_weight, probability = True, random_state = 30, \r\ndecision_function_shape = 'ovr')\r\n```\r\n\r\n**The models are loaded from file:**\r\n\r\n`ML = joblib.load(\"model.pkl\")`\r\n\r\n**Option A, analyze a matrix:**\r\n\r\n`distances = ML.decision_function(X)`\r\n\r\n**Option B, analyze individual samples:**    \r\n```\r\ndistances = numpy.zeros([X.shape[0], 3])\r\nfor i in range(X.shape[0]):     \r\n    distances[i,:]` = ML.decision_function(X[i,:].reshape(1,-1))\r\n```\r\n\r\n**Output for first two samples:**\r\n**Option A:**\r\nsample 1: [ 0.90835588, -0.17305875,  2.26470288]\r\nsample 2: [ 1.10437313, -0.2371539 ,  2.13278077]\r\n\r\n**Option B:**\r\nsample 1: [ 0.82689247, -0.32689247,  2.5       ]\r\nsample 2: [ 1.22005359, -0.5       ,  2.27994641]\r\n\r\nI couldn't find any indication for this behavior in the documentation.\r\n\r\nWindows-10-10.0.15063-SP0\r\nPython 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\r\nNumPy 1.12.1\r\nSciPy 0.18.1\r\nScikit-Learn 0.18.1\r\n\r\nThanks!", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-10059", "file_changes": [{"file": "doc/whats_new/v0.20.rst", "changes": {}}, {"file": "sklearn/cluster/k_means_.py", "changes": {"edited_modules": ["sklearn/cluster/k_means_.py:k_means"], "edited_entities": ["sklearn/cluster/k_means_.py:k_means"]}}, {"file": "sklearn/cluster/tests/test_k_means.py", "changes": {"edited_modules": ["sklearn/cluster/tests/test_k_means.py:test_sparse_validate_centers"], "edited_entities": ["sklearn/cluster/tests/test_k_means.py:test_sparse_validate_centers"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "effd75dda5f4afa61f988035ff8fe4b3a447464e", "problem_statement": "Duplicated input points silently create duplicated clusters in KMeans\n\n#### Description\r\nWhen there are duplicated input points to Kmeans resulting to number of unique points < number of requested clusters, there is no error thrown. Instead, clustering continues to (seemingly) produce the number of clusters requested, but some of them are exactly the same, so the cluster labels produced for the input points do not go all the way to number of requested clusters.\r\n\r\n#### Steps/Code to Reproduce\r\n```python\r\nfrom sklearn.cluster import KMeans\r\nimport numpy as np\r\n\r\n# some input points here are identical, so that n_total=17, n_unique=9\r\nx2d = np.array([(1086, 348), (1087, 347), (1190, 244), (1190, 244), (1086, 348), (1185, 249), (1193, 241), (1185, 249), (1087, 347), (1188, 247), (1187, 233), (26, 111), (26, 111), (26, 110), (26, 110), (26, 110), (26, 110)])\r\nkmeans = KMeans(n_clusters=10) # n_clusters > n_unique\r\nc_labels = kmeans.fit_predict(x2d)\r\nc_centers = kmeans.cluster_centers_\r\n```\r\n#### Expected Results\r\nEither an error thrown, or the cluster labels produced should match the unique clusters only (i.e. no identical cluster centres)\r\n\r\n#### Actual Results\r\n```python\r\n>>> c_labels  # note there's no entry for cluster 9\r\narray([7, 2, 6, 6, 7, 5, 4, 5, 2, 1, 3, 8, 8, 0, 0, 0, 0], dtype=int32)\r\n>>> c_centers # two of these 10 clusters have identical centers, so only 9 of them are unique\r\narray([[   26.,   110.],\r\n       [ 1188.,   247.],\r\n       [ 1087.,   347.],\r\n       [ 1187.,   233.],\r\n       [ 1193.,   241.],\r\n       [ 1185.,   249.],\r\n       [ 1190.,   244.],\r\n       [ 1086.,   348.],\r\n       [   26.,   111.],\r\n       [   26.,   110.]]) \r\n```\r\n\r\n#### Versions\r\n```python\r\nDarwin-16.7.0-x86_64-i386-64bit\r\nPython 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:04:09)\r\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\r\nNumPy 1.13.1\r\nSciPy 0.19.1\r\nScikit-Learn 0.18.2\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-18146", "file_changes": [{"file": "doc/whats_new/v0.24.rst", "changes": {}}, {"file": "sklearn/decomposition/tests/test_kernel_pca.py", "changes": {"edited_modules": ["sklearn/decomposition/tests/test_kernel_pca.py:test_kernel_pca_inverse_transform"], "edited_entities": ["sklearn/decomposition/tests/test_kernel_pca.py:test_kernel_pca_inverse_transform"]}}, {"file": "sklearn/utils/validation.py", "changes": {"edited_modules": ["sklearn/utils/validation.py:_check_psd_eigenvalues"], "edited_entities": ["sklearn/utils/validation.py:_check_psd_eigenvalues"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "e217b68fd00bb7c54b81a492ee6f9db6498517fa", "problem_statement": "Something goes wrong with KernelPCA with 32 bits input data\n\nWhen given 32 bits input, KernelPCA succeed to transform the data into a 17-dimensional feature space while the original space was 3 features. I did not debug yet but this seems really unlikely.\r\n\r\n```python\r\n# %%\r\nfrom sklearn.datasets import make_blobs\r\nfrom sklearn.preprocessing import StandardScaler\r\n\r\nX, y = make_blobs(\r\n    n_samples=30,\r\n    centers=[[0, 0, 0], [1, 1, 1]],\r\n    random_state=0,\r\n    cluster_std=0.1\r\n)\r\nX = StandardScaler().fit_transform(X)\r\nX -= X.min()\r\n\r\n# %%\r\nimport numpy as np\r\nfrom sklearn.decomposition import KernelPCA\r\n\r\nkpca = KernelPCA()\r\nprint(kpca.fit_transform(X).shape)\r\nprint(kpca.fit_transform(X.astype(np.float32)).shape)\r\n```", "patch": ""}
{"instance_id": "huggingface__transformers-12990", "file_changes": [{"file": "README.md", "changes": {}}, {"file": "docs/source/index.rst", "changes": {}}, {"file": "docs/source/model_doc/byt5.rst", "changes": {}}, {"file": "docs/source/model_doc/mt5.rst", "changes": {}}, {"file": "docs/source/model_doc/t5.rst", "changes": {}}, {"file": "src/transformers/models/t5/modeling_flax_t5.py", "changes": {"edited_modules": ["src/transformers/models/t5/modeling_flax_t5.py:FlaxT5PreTrainedModel", "src/transformers/models/t5/modeling_flax_t5.py:FlaxT5ForConditionalGeneration"], "edited_entities": ["src/transformers/models/t5/modeling_flax_t5.py:FlaxT5PreTrainedModel.encode", "src/transformers/models/t5/modeling_flax_t5.py:FlaxT5PreTrainedModel.decode", "src/transformers/models/t5/modeling_flax_t5.py:FlaxT5ForConditionalGeneration.decode"]}}, {"file": "src/transformers/models/t5/modeling_t5.py", "changes": {"edited_modules": ["src/transformers/models/t5/modeling_t5.py:T5Model", "src/transformers/models/t5/modeling_t5.py:T5ForConditionalGeneration"], "edited_entities": ["src/transformers/models/t5/modeling_t5.py:T5Model.forward", "src/transformers/models/t5/modeling_t5.py:T5ForConditionalGeneration.forward"]}}, {"file": "src/transformers/models/t5/modeling_tf_t5.py", "changes": {"edited_modules": ["src/transformers/models/t5/modeling_tf_t5.py:TFT5Model", "src/transformers/models/t5/modeling_tf_t5.py:TFT5ForConditionalGeneration", "src/transformers/models/t5/modeling_tf_t5.py:TFT5EncoderModel"], "edited_entities": ["src/transformers/models/t5/modeling_tf_t5.py:TFT5Model.call", "src/transformers/models/t5/modeling_tf_t5.py:TFT5ForConditionalGeneration.call", "src/transformers/models/t5/modeling_tf_t5.py:TFT5EncoderModel.call"]}}], "repo": "huggingface/transformers", "base_commit": "ba1b3db70907b975b5ca52b9957c5ed7a186a0fa", "problem_statement": "kindly adding some documentations on t5-v1_1-base\"\"\n\n## Environment info\r\n<!-- You can run the command `transformers-cli env` and copy-and-paste its output below.\r\n     Don't forget to fill out the missing fields in that output! -->\r\n\r\n- `transformers` version:\r\n- Platform:\r\n- Python version:\r\n- PyTorch version (GPU?):\r\n- Tensorflow version (GPU?):\r\n- Using GPU in script?:\r\n- Using distributed or parallel set-up in script?:\r\n\r\n### Who can help\r\n<!-- Your issue will be replied to more quickly if you can figure out the right person to tag with @\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @Rocketknight1\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nModel hub:\r\n\r\n- for issues with a model report at https://discuss.huggingface.co/ and tag the model's creator.\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n\r\nDocumentation: @sgugger\r\nHi\r\nCould you kindly add some documentations on \"t5-v1_1-base\"? I tested one code with t5-base and t5-v1 version, for t5-v1 I got memory issue, this seems to me the model size is different and larger, also fast tokenizer for this model does not work, could you kindly add a documentation on these differences?\r\n\r\nthanks a lot.", "patch": ""}
{"instance_id": "pandas-dev__pandas-16668", "file_changes": [{"file": "pandas/compat/__init__.py", "changes": {"edited_modules": ["pandas/compat/__init__.py:OrderedDefaultdict"], "edited_entities": ["pandas/compat/__init__.py:OrderedDefaultdict"]}}, {"file": "pandas/core/panel.py", "changes": {"edited_modules": ["pandas/core/panel.py:Panel"], "edited_entities": ["pandas/core/panel.py:Panel.from_dict"]}}], "repo": "pandas-dev/pandas", "base_commit": "ad24759871ea43131711cfce1e5fc69c06d82956", "problem_statement": "CLN: private impl of OrderedDefaultDict can be removed\n\nhttps://github.com/pandas-dev/pandas/blob/master/pandas/compat/__init__.py#L376\r\n\r\nI think this was leftover from 2.6 compat.", "patch": ""}
{"instance_id": "huggingface__transformers-3785", "file_changes": [{"file": "docs/source/index.rst", "changes": {}}, {"file": "src/transformers/__init__.py", "changes": {}}, {"file": "src/transformers/configuration_auto.py", "changes": {}}, {"file": "src/transformers/modeling_auto.py", "changes": {}}, {"file": "src/transformers/modeling_bert.py", "changes": {}}, {"file": "src/transformers/modeling_encoder_decoder.py", "changes": {"edited_modules": ["src/transformers/modeling_encoder_decoder.py:PreTrainedEncoderDecoder"], "edited_entities": ["src/transformers/modeling_encoder_decoder.py:PreTrainedEncoderDecoder", "src/transformers/modeling_encoder_decoder.py:PreTrainedEncoderDecoder.__init__", "src/transformers/modeling_encoder_decoder.py:PreTrainedEncoderDecoder.from_pretrained", "src/transformers/modeling_encoder_decoder.py:PreTrainedEncoderDecoder.save_pretrained", "src/transformers/modeling_encoder_decoder.py:PreTrainedEncoderDecoder.forward"]}}, {"file": "src/transformers/modeling_utils.py", "changes": {"edited_modules": ["src/transformers/modeling_utils.py:PreTrainedModel"], "edited_entities": ["src/transformers/modeling_utils.py:PreTrainedModel.generate"]}}, {"file": "src/transformers/utils_encoder_decoder.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "41750a6cff55e401364568868d619747de3db037", "problem_statement": "How to fine tune EncoderDecoder model for training a new corpus of data ?\n\nis there any documentation available for the same?", "patch": ""}
{"instance_id": "pandas-dev__pandas-29916", "file_changes": [{"file": "doc/source/whatsnew/v1.1.0.rst", "changes": {}}, {"file": "pandas/io/pytables.py", "changes": {"edited_modules": ["pandas/io/pytables.py:HDFStore"], "edited_entities": ["pandas/io/pytables.py:HDFStore.keys", "pandas/io/pytables.py:HDFStore"]}}, {"file": "pandas/tests/io/pytables/test_store.py", "changes": {"edited_modules": ["pandas/tests/io/pytables/test_store.py:TestHDFStore"], "edited_entities": ["pandas/tests/io/pytables/test_store.py:TestHDFStore"]}}], "repo": "pandas-dev/pandas", "base_commit": "c482b5727e3bd98b6f9780e51615791e413d542d", "problem_statement": "HDF5: empty groups and keys\n\nHi,\r\n\r\nWith some of the hdf5 files I have, `pandas.HDFStore.groups()` returns an empty list. (as does `.keys()` which iterates over the groups). However, the data are accessible via `.get()` or `.get_node()`.\r\n\r\nThis is related to #21543 and #21372 where the `.groups()` logic was changed, in particular using `self._handle.walk_groups()` instead of `self._handle.walk_nodes()`, now to be found here:\r\nhttps://github.com/pandas-dev/pandas/blob/ea2e26ae7d700d7fd363ea5bfc05d2fe3fb8a5ee/pandas/io/pytables.py#L1212\r\n\r\n\r\n#### Current Output\r\n\r\n```python\r\n>>> hdf.groups()\r\n[]\r\n```\r\n```python\r\n>>> hdf.keys()\r\n[]\r\n```\r\n\r\n#### Expected Ouptut\r\n\r\nList of groups and keys as visible with e.g. `h5dump`.\r\n**Note:** Changing the aforementioned line back to use `.walk_nodes()` fixes the issue and lists the groups and keys properly:\r\n\r\n```python\r\n>>> hdf.groups()\r\n[/Data/Table Layout (Table(69462,), zlib(4)) ''\r\n   description := {\r\n...\r\n/Data/Array Layout/2D Parameters/Data Parameters (Table(15,)) ''\r\n   description := {\r\n   \"mnemonic\": StringCol(itemsize=8, shape=(), dflt=b'', pos=0),\r\n   \"description\": StringCol(itemsize=48, shape=(), dflt=b'', pos=1),\r\n   \"isError\": Int64Col(shape=(), dflt=0, pos=2),\r\n   \"units\": StringCol(itemsize=7, shape=(), dflt=b'', pos=3),\r\n   \"category\": StringCol(itemsize=31, shape=(), dflt=b'', pos=4)}\r\n   byteorder := 'little'\r\n   chunkshape := (642,)]]\r\n```\r\n```python\r\n>>> hdf.keys()\r\n['/Data/Table Layout',\r\n '/Metadata/Data Parameters',\r\n '/Metadata/Experiment Notes',\r\n '/Metadata/Experiment Parameters',\r\n '/Metadata/Independent Spatial Parameters',\r\n '/Metadata/_record_layout',\r\n '/Data/Array Layout/Layout Description',\r\n '/Data/Array Layout/1D Parameters/Data Parameters',\r\n '/Data/Array Layout/2D Parameters/Data Parameters']\r\n```\r\n\r\n#### Fix\r\n\r\nOne solution would be (I guess) to revert #21543, another to fix at least `.keys()` to use `._handle.walk_nodes()` instead of `.groups()` in\r\nhttps://github.com/pandas-dev/pandas/blob/ea2e26ae7d700d7fd363ea5bfc05d2fe3fb8a5ee/pandas/io/pytables.py#L562\r\n\r\nCould also be that it is a bug in `pytables`.\r\n\r\n#### Problem background\r\n\r\nI was trying to figure out why some hdf5 files open fine with `pandas` but fail with `dask`.\r\nThe reason is that `dask` allows wildcards and iterates over the keys to find valid ones. If `.keys()` is empty, reading the files with `dask` fails.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : None\r\npython           : 3.7.3.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 3.10.0-957.27.2.el7.x86_64\r\nmachine          : x86_64\r\nprocessor        : x86_64\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : C\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 0.25.3\r\nnumpy            : 1.17.3\r\npytz             : 2019.3\r\ndateutil         : 2.8.1\r\npip              : 19.3.1\r\nsetuptools       : 42.0.1.post20191125\r\nCython           : None\r\npytest           : 5.0.1\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : 4.4.2\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.10.3\r\nIPython          : 7.10.0\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nlxml.etree       : 4.4.2\r\nmatplotlib       : 3.1.2\r\nnumexpr          : 2.7.0\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npytables         : None\r\ns3fs             : None\r\nscipy            : 1.3.2\r\nsqlalchemy       : None\r\ntables           : 3.6.1\r\nxarray           : 0.14.1\r\nxlrd             : None\r\nxlwt             : None\r\nxlsxwriter       : None\r\n\r\n</details>", "patch": ""}
{"instance_id": "huggingface__transformers-20058", "file_changes": [{"file": "src/transformers/models/clip/processing_clip.py", "changes": {"edited_modules": ["src/transformers/models/clip/processing_clip.py:CLIPProcessor"], "edited_entities": ["src/transformers/models/clip/processing_clip.py:CLIPProcessor.decode"]}}, {"file": "src/transformers/models/flava/processing_flava.py", "changes": {"edited_modules": ["src/transformers/models/flava/processing_flava.py:FlavaProcessor"], "edited_entities": ["src/transformers/models/flava/processing_flava.py:FlavaProcessor.decode"]}}, {"file": "src/transformers/models/layoutlmv2/processing_layoutlmv2.py", "changes": {"edited_modules": ["src/transformers/models/layoutlmv2/processing_layoutlmv2.py:LayoutLMv2Processor"], "edited_entities": ["src/transformers/models/layoutlmv2/processing_layoutlmv2.py:LayoutLMv2Processor.decode"]}}, {"file": "src/transformers/models/layoutlmv3/processing_layoutlmv3.py", "changes": {"edited_modules": ["src/transformers/models/layoutlmv3/processing_layoutlmv3.py:LayoutLMv3Processor"], "edited_entities": ["src/transformers/models/layoutlmv3/processing_layoutlmv3.py:LayoutLMv3Processor.decode"]}}, {"file": "src/transformers/models/layoutxlm/processing_layoutxlm.py", "changes": {"edited_modules": ["src/transformers/models/layoutxlm/processing_layoutxlm.py:LayoutXLMProcessor"], "edited_entities": ["src/transformers/models/layoutxlm/processing_layoutxlm.py:LayoutXLMProcessor.decode"]}}, {"file": "src/transformers/models/markuplm/processing_markuplm.py", "changes": {"edited_modules": ["src/transformers/models/markuplm/processing_markuplm.py:MarkupLMProcessor"], "edited_entities": ["src/transformers/models/markuplm/processing_markuplm.py:MarkupLMProcessor.decode"]}}, {"file": "src/transformers/models/owlvit/processing_owlvit.py", "changes": {"edited_modules": ["src/transformers/models/owlvit/processing_owlvit.py:OwlViTProcessor"], "edited_entities": ["src/transformers/models/owlvit/processing_owlvit.py:OwlViTProcessor.decode"]}}, {"file": "src/transformers/models/vilt/processing_vilt.py", "changes": {"edited_modules": ["src/transformers/models/vilt/processing_vilt.py:ViltProcessor"], "edited_entities": ["src/transformers/models/vilt/processing_vilt.py:ViltProcessor.decode"]}}, {"file": "src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py", "changes": {"edited_modules": ["src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py:VisionTextDualEncoderProcessor"], "edited_entities": ["src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py:VisionTextDualEncoderProcessor"]}}, {"file": "src/transformers/models/x_clip/processing_x_clip.py", "changes": {"edited_modules": ["src/transformers/models/x_clip/processing_x_clip.py:XCLIPProcessor"], "edited_entities": ["src/transformers/models/x_clip/processing_x_clip.py:XCLIPProcessor.decode"]}}, {"file": "src/transformers/processing_utils.py", "changes": {}}, {"file": "tests/models/clip/test_processor_clip.py", "changes": {"edited_modules": ["tests/models/clip/test_processor_clip.py:CLIPProcessorTest"], "edited_entities": ["tests/models/clip/test_processor_clip.py:CLIPProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/flava/test_processor_flava.py", "changes": {"edited_modules": ["tests/models/flava/test_processor_flava.py:FlavaProcessorTest"], "edited_entities": ["tests/models/flava/test_processor_flava.py:FlavaProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/layoutlmv2/test_processor_layoutlmv2.py", "changes": {"edited_modules": ["tests/models/layoutlmv2/test_processor_layoutlmv2.py:LayoutLMv2ProcessorTest"], "edited_entities": ["tests/models/layoutlmv2/test_processor_layoutlmv2.py:LayoutLMv2ProcessorTest"]}}, {"file": "tests/models/layoutlmv3/test_processor_layoutlmv3.py", "changes": {"edited_modules": ["tests/models/layoutlmv3/test_processor_layoutlmv3.py:LayoutLMv3ProcessorTest"], "edited_entities": ["tests/models/layoutlmv3/test_processor_layoutlmv3.py:LayoutLMv3ProcessorTest"]}}, {"file": "tests/models/layoutxlm/test_processor_layoutxlm.py", "changes": {"edited_modules": ["tests/models/layoutxlm/test_processor_layoutxlm.py:LayoutXLMProcessorTest"], "edited_entities": ["tests/models/layoutxlm/test_processor_layoutxlm.py:LayoutXLMProcessorTest"]}}, {"file": "tests/models/markuplm/test_processor_markuplm.py", "changes": {}}, {"file": "tests/models/mctct/test_processor_mctct.py", "changes": {"edited_modules": ["tests/models/mctct/test_processor_mctct.py:MCTCTProcessorTest"], "edited_entities": ["tests/models/mctct/test_processor_mctct.py:MCTCTProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/owlvit/test_processor_owlvit.py", "changes": {"edited_modules": ["tests/models/owlvit/test_processor_owlvit.py:OwlViTProcessorTest"], "edited_entities": ["tests/models/owlvit/test_processor_owlvit.py:OwlViTProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/speech_to_text/test_processor_speech_to_text.py", "changes": {"edited_modules": ["tests/models/speech_to_text/test_processor_speech_to_text.py:Speech2TextProcessorTest"], "edited_entities": ["tests/models/speech_to_text/test_processor_speech_to_text.py:Speech2TextProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/vision_text_dual_encoder/test_processor_vision_text_dual_encoder.py", "changes": {"edited_modules": ["tests/models/vision_text_dual_encoder/test_processor_vision_text_dual_encoder.py:VisionTextDualEncoderProcessorTest"], "edited_entities": ["tests/models/vision_text_dual_encoder/test_processor_vision_text_dual_encoder.py:VisionTextDualEncoderProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/wav2vec2/test_processor_wav2vec2.py", "changes": {"edited_modules": ["tests/models/wav2vec2/test_processor_wav2vec2.py:Wav2Vec2ProcessorTest"], "edited_entities": ["tests/models/wav2vec2/test_processor_wav2vec2.py:Wav2Vec2ProcessorTest.test_tokenizer_decode"]}}, {"file": "tests/models/wav2vec2_with_lm/test_processor_wav2vec2_with_lm.py", "changes": {"edited_modules": ["tests/models/wav2vec2_with_lm/test_processor_wav2vec2_with_lm.py:Wav2Vec2ProcessorWithLMTest"], "edited_entities": ["tests/models/wav2vec2_with_lm/test_processor_wav2vec2_with_lm.py:Wav2Vec2ProcessorWithLMTest"]}}, {"file": "tests/models/whisper/test_processor_whisper.py", "changes": {"edited_modules": ["tests/models/whisper/test_processor_whisper.py:WhisperProcessorTest"], "edited_entities": ["tests/models/whisper/test_processor_whisper.py:WhisperProcessorTest.test_tokenizer_decode"]}}], "repo": "huggingface/transformers", "base_commit": "6dda14dc47d82f0e32df05fea8ba6444ba52b90a", "problem_statement": "Push to Hub fails with `model_name`\n\n### System Info\r\n\r\n- `transformers` version: 4.25.0.dev0\r\n- Platform: Linux-5.15.0-48-generic-x86_64-with-glibc2.31\r\n- Python version: 3.9.13\r\n- Huggingface_hub version: 0.10.1\r\n- PyTorch version (GPU?): 1.13.0+cu117 (True)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Flax version (CPU?/GPU?/TPU?): not installed (NA)\r\n- Jax version: not installed\r\n- JaxLib version: not installed\r\n- Using GPU in script?: yes\r\n- Using distributed or parallel set-up in script?: no\r\n\r\n\r\n### Who can help?\r\n\r\n@sanchit-gandhi \r\n\r\n### Information\r\n\r\n- [ ] The official example scripts\r\n- [X] My own modified scripts\r\n\r\n### Tasks\r\n\r\n- [X] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\r\n- [ ] My own task or dataset (give details below)\r\n\r\n### Reproduction\r\n\r\n```python\r\nfrom datasets import load_dataset, DatasetDict\r\n\r\ncommon_voice = DatasetDict()\r\n\r\n#common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"train+validation\", use_auth_token=True)\r\n#common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"test\", use_auth_token=True)\r\n\r\ncommon_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"train[:1%]+validation[:1%]\", use_auth_token=True)\r\ncommon_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sv-SE\", split=\"test[:1%]\", use_auth_token=True)\r\n\r\nprint(common_voice)\r\n\r\ncommon_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\r\n\r\nprint(common_voice)\r\n\r\nfrom transformers import WhisperFeatureExtractor\r\n\r\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\r\n\r\nfrom transformers import WhisperTokenizer\r\n\r\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"swedish\", task=\"transcribe\")\r\n\r\nfrom transformers import WhisperProcessor\r\n\r\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"swedish\", task=\"transcribe\")\r\n\r\nprint(common_voice[\"train\"][0])\r\n\r\nfrom datasets import Audio\r\n\r\ncommon_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\r\n\r\n\r\nprint(common_voice[\"train\"][0])\r\n\r\ndef prepare_dataset(batch):\r\n    # load and resample audio data from 48 to 16kHz\r\n    audio = batch[\"audio\"]\r\n\r\n    # compute log-Mel input features from input audio array \r\n    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\r\n\r\n    # encode target text to label ids \r\n    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\r\n    return batch\r\n\r\ncommon_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1)\r\n\r\nimport torch\r\n\r\nfrom dataclasses import dataclass\r\nfrom typing import Any, Dict, List, Union\r\n\r\n@dataclass\r\nclass DataCollatorSpeechSeq2SeqWithPadding:\r\n    processor: Any\r\n\r\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\r\n        # split inputs and labels since they have to be of different lengths and need different padding methods\r\n        # first treat the audio inputs by simply returning torch tensors\r\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\r\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\r\n\r\n        # get the tokenized label sequences\r\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\r\n        # pad the labels to max length\r\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\r\n\r\n        # replace padding with -100 to ignore loss correctly\r\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\r\n\r\n        # if bos token is appended in previous tokenization step,\r\n        # cut bos token here as it's append later anyways\r\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\r\n            labels = labels[:, 1:]\r\n\r\n        batch[\"labels\"] = labels\r\n\r\n        return batch\r\n\r\n\"\"\"Let's initialise the data collator we've just defined:\"\"\"\r\n\r\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\r\n\r\nimport evaluate\r\n\r\nmetric = evaluate.load(\"wer\")\r\n\r\ndef compute_metrics(pred):\r\n    pred_ids = pred.predictions\r\n    label_ids = pred.label_ids\r\n\r\n    # replace -100 with the pad_token_id\r\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\r\n\r\n    # we do not want to group tokens when computing the metrics\r\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\r\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\r\n\r\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\r\n\r\n    return {\"wer\": wer}\r\n\r\nfrom transformers import WhisperForConditionalGeneration\r\n\r\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\r\n\r\nmodel.config.forced_decoder_ids = None\r\nmodel.config.suppress_tokens = []\r\n\r\nfrom transformers import Seq2SeqTrainingArguments\r\n\r\ntraining_args = Seq2SeqTrainingArguments(\r\n    output_dir=\"./whisper-small-sv-test2\",  # change to a repo name of your choice\r\n    per_device_train_batch_size=16,\r\n    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\r\n    learning_rate=1e-5,\r\n    warmup_steps=500,\r\n    max_steps=10,\r\n    gradient_checkpointing=True,\r\n    fp16=True,\r\n    group_by_length=True,\r\n    evaluation_strategy=\"steps\",\r\n    per_device_eval_batch_size=8,\r\n    predict_with_generate=True,\r\n    generation_max_length=225,\r\n    save_steps=1000,\r\n    eval_steps=1000,\r\n    logging_steps=25,\r\n    report_to=[\"tensorboard\"],\r\n    load_best_model_at_end=True,\r\n    metric_for_best_model=\"wer\",\r\n    greater_is_better=False,\r\n    push_to_hub=True,\r\n)\r\n\r\nfrom transformers import Seq2SeqTrainer\r\n\r\ntrainer = Seq2SeqTrainer(\r\n    args=training_args,\r\n    model=model,\r\n    train_dataset=common_voice[\"train\"],\r\n    eval_dataset=common_voice[\"test\"],\r\n    data_collator=data_collator,\r\n    compute_metrics=compute_metrics,\r\n    tokenizer=processor.feature_extractor,\r\n)\r\n\r\ntrainer.train()\r\n\r\n\"\"\"Our best WER is 32.0% - not bad for 8h of training data! We can submit our checkpoint to the [`hf-speech-bench`](https://huggingface.co/spaces/huggingface/hf-speech-bench) on push by setting the appropriate key-word arguments (kwargs):\"\"\"\r\n\r\nkwargs = {\r\n    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\r\n    \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\r\n    \"language\": \"sv\",\r\n    #\"model_name\": \"WhisperSmallSwedishBirgerMoell\",  # a 'pretty' name for our model\r\n    \"finetuned_from\": \"openai/whisper-small\",\r\n    \"tasks\": \"automatic-speech-recognition\",\r\n    \"tags\": \"hf-asr-leaderboard\",\r\n}\r\n\r\ntrainer.push_to_hub(**kwargs)\r\n\r\nfrom transformers import pipeline\r\nimport gradio as gr\r\n\r\npipe = pipeline(model=\"birgermoell/whisper-small-sv-test2\")  # change to \"your-username/the-name-you-picked\"\r\n\r\ndef transcribe(audio):\r\n    text = pipe(audio)[\"text\"]\r\n    return text\r\n\r\niface = gr.Interface(\r\n    fn=transcribe, \r\n    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"), \r\n    outputs=\"text\",\r\n    title=\"Whisper Small SV\",\r\n    description=\"Realtime demo for Swedish speech recognition using a fine-tuned Whisper small model.\",\r\n)\r\n\r\niface.launch()\r\n\r\n```\r\n\r\n\r\n### Expected behavior\r\n\r\nThe following script is a downloaded version of the colab notebook that follows the whisper fine-tuning tutorial.\r\nhttps://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb\r\n\r\nOne edit was that I removed the model name since I had an issue that it was complaining about two model names that made it impossible to upload. The script just runs on 1% of the dataset on 10 epochs.\r\n\r\nkwargs = {\r\n    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\r\n    \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\r\n    \"language\": \"sv\",\r\n    #\"model_name\": \"WhisperSmallSwedishBirgerMoell\",  # a 'pretty' name for our model\r\n    \"finetuned_from\": \"openai/whisper-small\",\r\n    \"tasks\": \"automatic-speech-recognition\",\r\n    \"tags\": \"hf-asr-leaderboard\",\r\n}\r\n\r\nhttps://huggingface.co/birgermoell/whisper-small-sv-test2\r\n\r\nI also ran into similar issues when I trained a model on the whole dataset.\r\n\r\nhttps://huggingface.co/birgermoell/whisper-small-sv", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-7435", "file_changes": [{"file": "doc/modules/classes.rst", "changes": {}}, {"file": "doc/modules/cross_validation.rst", "changes": {}}, {"file": "doc/modules/grid_search.rst", "changes": {}}, {"file": "doc/modules/model_evaluation.rst", "changes": {}}, {"file": "doc/whats_new.rst", "changes": {}}, {"file": "sklearn/metrics/scorer.py", "changes": {"edited_modules": ["sklearn/metrics/scorer.py:get_scorer", "sklearn/metrics/scorer.py:check_scoring"], "edited_entities": ["sklearn/metrics/scorer.py:get_scorer", "sklearn/metrics/scorer.py:check_scoring"]}}, {"file": "sklearn/metrics/tests/test_score_objects.py", "changes": {"edited_modules": ["sklearn/metrics/tests/test_score_objects.py:EstimatorWithoutFit", "sklearn/metrics/tests/test_score_objects.py:EstimatorWithFit", "sklearn/metrics/tests/test_score_objects.py:EstimatorWithFitAndScore", "sklearn/metrics/tests/test_score_objects.py:EstimatorWithFitAndPredict", "sklearn/metrics/tests/test_score_objects.py:test_check_scoring"], "edited_entities": ["sklearn/metrics/tests/test_score_objects.py:EstimatorWithoutFit", "sklearn/metrics/tests/test_score_objects.py:EstimatorWithFit", "sklearn/metrics/tests/test_score_objects.py:EstimatorWithFitAndScore", "sklearn/metrics/tests/test_score_objects.py:EstimatorWithFitAndPredict", "sklearn/metrics/tests/test_score_objects.py:test_check_scoring"]}}, {"file": "sklearn/model_selection/__init__.py", "changes": {}}, {"file": "sklearn/model_selection/_search.py", "changes": {"edited_modules": ["sklearn/model_selection/_search.py:fit_grid_point", "sklearn/model_selection/_search.py:BaseSearchCV", "sklearn/model_selection/_search.py:GridSearchCV", "sklearn/model_selection/_search.py:RandomizedSearchCV"], "edited_entities": ["sklearn/model_selection/_search.py:fit_grid_point", "sklearn/model_selection/_search.py:BaseSearchCV.score", "sklearn/model_selection/_search.py:BaseSearchCV._store", "sklearn/model_selection/_search.py:BaseSearchCV", "sklearn/model_selection/_search.py:GridSearchCV", "sklearn/model_selection/_search.py:RandomizedSearchCV", "sklearn/model_selection/_search.py:BaseSearchCV._check_is_fitted", "sklearn/model_selection/_search.py:BaseSearchCV.fit", "sklearn/model_selection/_search.py:BaseSearchCV.grid_scores_"]}}, {"file": "sklearn/model_selection/_validation.py", "changes": {"edited_modules": ["sklearn/model_selection/_validation.py:cross_val_score", "sklearn/model_selection/_validation.py:_fit_and_score", "sklearn/model_selection/_validation.py:validation_curve", "sklearn/model_selection/_validation.py:_score", "sklearn/model_selection/_validation.py:permutation_test_score"], "edited_entities": ["sklearn/model_selection/_validation.py:cross_val_score", "sklearn/model_selection/_validation.py:_fit_and_score", "sklearn/model_selection/_validation.py:validation_curve", "sklearn/model_selection/_validation.py:_score", "sklearn/model_selection/_validation.py:permutation_test_score"]}}, {"file": "sklearn/model_selection/tests/test_search.py", "changes": {"edited_modules": ["sklearn/model_selection/tests/test_search.py:test_unsupervised_grid_search", "sklearn/model_selection/tests/test_search.py:check_cv_results_array_types", "sklearn/model_selection/tests/test_search.py:test_random_search_cv_results", "sklearn/model_selection/tests/test_search.py:test_no_refit", "sklearn/model_selection/tests/test_search.py:test_pandas_input", "sklearn/model_selection/tests/test_search.py:check_cv_results_grid_scores_consistency", "sklearn/model_selection/tests/test_search.py:test_grid_search_cv_results", "sklearn/model_selection/tests/test_search.py:test_grid_search_cv_splits_consistency"], "edited_entities": ["sklearn/model_selection/tests/test_search.py:test_unsupervised_grid_search", "sklearn/model_selection/tests/test_search.py:check_cv_results_array_types", "sklearn/model_selection/tests/test_search.py:test_random_search_cv_results", "sklearn/model_selection/tests/test_search.py:test_no_refit", "sklearn/model_selection/tests/test_search.py:test_pandas_input", "sklearn/model_selection/tests/test_search.py:check_cv_results_grid_scores_consistency", "sklearn/model_selection/tests/test_search.py:test_grid_search_cv_results", "sklearn/model_selection/tests/test_search.py:test_grid_search_cv_splits_consistency"]}}, {"file": "sklearn/model_selection/tests/test_validation.py", "changes": {"edited_modules": ["sklearn/model_selection/tests/test_validation.py:test_cross_val_score_score_func"], "edited_entities": ["sklearn/model_selection/tests/test_validation.py:test_cross_val_score_score_func"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "e8a15d544490b3fe80ef77dd995d12de84194d00", "problem_statement": "[RFC?] Make cross_val_score output a dict/named tuple.\n\nTwo major things here -\n- Often I see that only a partial output of `_fit_and_score` is taken for use. It is wasteful to generate and discard arrays. It would rather be much better to generate only the stuff that is required.\n- Now that we have more options, like @jnothman says [here](https://github.com/scikit-learn/scikit-learn/pull/7325#issuecomment-246529168) and [here](https://github.com/scikit-learn/scikit-learn/pull/7388#issuecomment-246233650) should we modify the output of `cross_val_score` (and also `_fit_and_score` to be a dict or a named tuple similar to the structure of `cv_results_`? (I think named-tuple is a better choice atleast for `_fit_and_score` as we stack the result of multiple `_fit_and_score` operations via `Parallel` mostly)\n\nIf we are changing the output of `cross_val_score`, this would be an ideal time to do it as we don't have to deprecate anything...\n\n@jnothman @amueller @vene @GaelVaroquaux @agramfort", "patch": ""}
{"instance_id": "huggingface__transformers-24100", "file_changes": [{"file": "src/transformers/trainer_callback.py", "changes": {"edited_modules": ["src/transformers/trainer_callback.py:ProgressCallback"], "edited_entities": ["src/transformers/trainer_callback.py:ProgressCallback.on_train_begin", "src/transformers/trainer_callback.py:ProgressCallback.on_prediction_step"]}}], "repo": "huggingface/transformers", "base_commit": "a73883ae9ec66cb35a8222f204a5f2fafc326d3f", "problem_statement": "[Trainer] Why not use `tqdm`'s `dynamic_ncols=True` option?\n\n### Feature request\r\n\r\n# Problem\r\n\r\nTqdm progress bar is getting ugly when the width of the terminal is shrunk!\r\n\r\n![image](https://github.com/huggingface/transformers/assets/4879345/b60f232f-41a5-40de-b759-8bb2710d3b5f)\r\n\r\nIt progress bar makes the new line on every update! It is very ugly...\r\n\r\n# Solution\r\n\r\nSimply add the `dynamic_ncols=True` option to `tqdm`. It is located in `trainer_callbacks.ProgressCallback`.\r\n\r\n![image](https://github.com/huggingface/transformers/assets/4879345/6741eb00-7430-48db-acc8-4c3a0eb00217)\r\n\r\nYou can check the progress bar is now dynamically resized when the terminal size is updated.\r\n\r\n### Motivation\r\n\r\nWhen I connect `tmux` session with different widths of the terminal, then the `tqdm` printing is getting ugly.\r\n\r\n### Your contribution\r\n\r\nPlease check the PR #24101", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-11194", "file_changes": [{"file": "sklearn/ensemble/tests/test_iforest.py", "changes": {"edited_modules": ["sklearn/ensemble/tests/test_iforest.py:test_iforest_error"], "edited_entities": ["sklearn/ensemble/tests/test_iforest.py:test_iforest_error"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "bb385394b87e382a34db829bc7ed60d347af73c9", "problem_statement": "NumPy dev causes test errors due to use of np.matrix\n\nWe are getting many warnings like `PendingDeprecationWarning('the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.` using numpy master (see logs at https://travis-ci.org/scikit-learn/scikit-learn/builds/387352026)\r\n\r\nApart from a very long log, this causes test failures where we have used `assert_no_warnings` (which we could now be importing from numpy instead of having our own implementation).\r\n\r\nIt might be a good idea to remove all uses of np.matrix that raise warnings. On the other hand, we might also consider that `assert_no_warnings` shouldn't be bothered by `PendingDeprecationWarning`s.", "patch": ""}
{"instance_id": "huggingface__transformers-9326", "file_changes": [{"file": "docs/source/custom_datasets.rst", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "5f7a07c0c867abedbb3ebf135915eeee56add24b", "problem_statement": "Issue with 'char_to_token()' function of DistilBertTokenizerFast\n\n## Environment info\r\n<!-- You can run the command `transformers-cli env` and copy-and-paste its output below.\r\n     Don't forget to fill out the missing fields in that output! -->\r\n     \r\n- `transformers` version: 4.0.1\r\n- Platform: Google Colab\r\n- Python version: 3.8\r\n- PyTorch version (GPU?):\r\n- Tensorflow version (GPU?): 2.4.0\r\n- Using GPU in script?: No\r\n- Using distributed or parallel set-up in script?: NA\r\n\r\n### Who can help:   **tokenizers: @mfuntowicz**\r\n\r\n## Information\r\n\r\nModel I am using DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased') to tokenize Squad 2.0 train and validate dataset. \r\n\r\nThe problem arises when using below code snippet to add_token_positions (start and end position) as below from https://huggingface.co/transformers/custom_datasets.html:\r\n\r\n_def add_token_positions(encodings, answers):\r\n    start_positions = []\r\n    end_positions = []\r\n    for i in range(len(answers)):\r\n        start_positions.append(**encodings.char_to_token(i, answers[i]['answer_start'])**)\r\n        end_positions.append(**encodings.char_to_token(i, answers[i]['answer_end'] - 1**))\r\n        # if None, the answer passage has been truncated\r\n        if start_positions[-1] is None:\r\n            start_positions[-1] = tokenizer.model_max_length\r\n        if end_positions[-1] is None:\r\n            end_positions[-1] = tokenizer.model_max_length\r\n    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\r\n\r\nadd_token_positions(train_encodings, train_answers)\r\nadd_token_positions(val_encodings, val_answers)_\r\n\r\n\r\n\r\n\r\nThe tasks I am working on is:\r\n*Training model on SQUaD 2.0 using code given on https://huggingface.co/transformers/custom_datasets.html#question-answering-with-squad-2-0\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Follow the steps given on https://huggingface.co/transformers/custom_datasets.html#question-answering-with-squad-2-0 and then verify start and end position outcome using below code snippet in Expected behavior\r\n\r\n\r\n<!-- If you have code snippets, error messages, stack traces please provide them here as well.\r\n     Important! Use code tags to correctly format your code. See https://help.github.com/en/github/writing-on-github/creating-and-highlighting-code-blocks#syntax-highlighting\r\n     Do not use screenshots, as they are hard to read and (more importantly) don't allow others to copy-and-paste your code.-->\r\n\r\n## Expected behavior:\r\n- Start and End position are being defined using above code snippet which will be provided as training/validation data to model but end position is not derived as correct value due to some issue with char_to_token() function which is used to find out end position.\r\n- Please find below snippet for verification that answer using start and end position after tokenization is not matching with actual answer.\r\n- So the training data which is being fed to model after tokenization is incorrect\r\n\r\nidx=8\r\nprint(f'Actual context: {train_contexts[idx]}')\r\nprint(f'Actual question: {train_questions[idx]}')\r\nprint(f\"Actual answer: {train_answers[idx]['text']}\")\r\n\r\nstart_position=train_encodings.char_to_token(idx,train_answers[idx]['answer_start'])\r\nend_position =train_encodings.char_to_token(idx,train_answers[idx]['answer_end'])\r\nprint(f\"Answer after tokenization: {tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][idx][start_position:end_position])}\") \r\n\r\nOUTPUT:\r\n**Actual context:** Beyonc\u00e9 Giselle Knowles-Carter (/bi\u02d0\u02c8j\u0252nse\u026a/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc\u00e9's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\r\n**Actual question:** When did Beyonc\u00e9 rise to fame?\r\n**Actual answer:** late 1990s\r\n**Answer after tokenization:** ['late', '1990s', 'as', 'lead', 'singer', 'of', 'r', '&', 'b', 'girl', '-', 'group', 'destiny', \"'\", 's', 'child', '.', 'managed', 'by', 'her', 'father', ',', 'mathew', 'knowles', ',', 'the', 'group', 'became', 'one', 'of', 'the', 'world', \"'\", 's', 'best', '-', 'selling', 'girl', 'groups', 'of', 'all', 'time', '.', 'their', 'hiatus', 'saw', 'the', 'release', 'of', 'beyonce', \"'\", 's', 'debut', 'album', ',', 'dangerously', 'in', 'love', '(', '2003', ')', ',', 'which', 'established', 'her', 'as', 'a', 'solo', 'artist', 'worldwide', ',', 'earned', 'five', 'grammy', 'awards', 'and', 'featured', 'the', 'billboard', 'hot', '100', 'number', '-', 'one', 'singles', '\"', 'crazy', 'in', 'love', '\"', 'and', '\"', 'baby', 'boy', '\"', '.', '[SEP]', 'when', 'did', 'beyonce', 'rise', 'to', 'fame', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-10463", "file_changes": [{"file": "doc/glossary.rst", "changes": {}}, {"file": "doc/modules/classes.rst", "changes": {}}, {"file": "doc/modules/neighbors.rst", "changes": {}}, {"file": "doc/whats_new/v0.22.rst", "changes": {}}, {"file": "sklearn/cluster/dbscan_.py", "changes": {"edited_modules": ["sklearn/cluster/dbscan_.py:dbscan", "sklearn/cluster/dbscan_.py:DBSCAN"], "edited_entities": ["sklearn/cluster/dbscan_.py:dbscan", "sklearn/cluster/dbscan_.py:DBSCAN", "sklearn/cluster/dbscan_.py:DBSCAN.fit"]}}, {"file": "sklearn/cluster/spectral.py", "changes": {"edited_modules": ["sklearn/cluster/spectral.py:SpectralClustering"], "edited_entities": ["sklearn/cluster/spectral.py:SpectralClustering.fit", "sklearn/cluster/spectral.py:SpectralClustering", "sklearn/cluster/spectral.py:SpectralClustering._pairwise"]}}, {"file": "sklearn/cluster/tests/test_dbscan.py", "changes": {}}, {"file": "sklearn/cluster/tests/test_spectral.py", "changes": {}}, {"file": "sklearn/manifold/_utils.pyx", "changes": {}}, {"file": "sklearn/manifold/isomap.py", "changes": {"edited_modules": ["sklearn/manifold/isomap.py:Isomap"], "edited_entities": ["sklearn/manifold/isomap.py:Isomap", "sklearn/manifold/isomap.py:Isomap.__init__", "sklearn/manifold/isomap.py:Isomap._fit_transform", "sklearn/manifold/isomap.py:Isomap.fit", "sklearn/manifold/isomap.py:Isomap.fit_transform", "sklearn/manifold/isomap.py:Isomap.transform"]}}, {"file": "sklearn/manifold/locally_linear.py", "changes": {"edited_modules": ["sklearn/manifold/locally_linear.py:barycenter_kneighbors_graph"], "edited_entities": ["sklearn/manifold/locally_linear.py:barycenter_kneighbors_graph"]}}, {"file": "sklearn/manifold/spectral_embedding_.py", "changes": {"edited_modules": ["sklearn/manifold/spectral_embedding_.py:SpectralEmbedding", "sklearn/manifold/spectral_embedding_.py:spectral_embedding"], "edited_entities": ["sklearn/manifold/spectral_embedding_.py:SpectralEmbedding._get_affinity_matrix", "sklearn/manifold/spectral_embedding_.py:spectral_embedding", "sklearn/manifold/spectral_embedding_.py:SpectralEmbedding", "sklearn/manifold/spectral_embedding_.py:SpectralEmbedding._pairwise", "sklearn/manifold/spectral_embedding_.py:SpectralEmbedding.fit", "sklearn/manifold/spectral_embedding_.py:SpectralEmbedding.fit_transform"]}}, {"file": "sklearn/manifold/t_sne.py", "changes": {"edited_modules": ["sklearn/manifold/t_sne.py:TSNE", "sklearn/manifold/t_sne.py:_joint_probabilities", "sklearn/manifold/t_sne.py:_joint_probabilities_nn"], "edited_entities": ["sklearn/manifold/t_sne.py:TSNE._fit", "sklearn/manifold/t_sne.py:_joint_probabilities", "sklearn/manifold/t_sne.py:_joint_probabilities_nn", "sklearn/manifold/t_sne.py:TSNE.fit_transform", "sklearn/manifold/t_sne.py:TSNE.fit"]}}, {"file": "sklearn/manifold/tests/test_isomap.py", "changes": {}}, {"file": "sklearn/manifold/tests/test_spectral_embedding.py", "changes": {"edited_modules": ["sklearn/manifold/tests/test_spectral_embedding.py:test_spectral_embedding_precomputed_affinity", "sklearn/manifold/tests/test_spectral_embedding.py:test_spectral_embedding_callable_affinity"], "edited_entities": ["sklearn/manifold/tests/test_spectral_embedding.py:test_spectral_embedding_precomputed_affinity", "sklearn/manifold/tests/test_spectral_embedding.py:test_spectral_embedding_callable_affinity"]}}, {"file": "sklearn/manifold/tests/test_t_sne.py", "changes": {"edited_modules": ["sklearn/manifold/tests/test_t_sne.py:test_binary_search", "sklearn/manifold/tests/test_t_sne.py:test_binary_search_neighbors", "sklearn/manifold/tests/test_t_sne.py:test_binary_perplexity_stability", "sklearn/manifold/tests/test_t_sne.py:test_fit_csr_matrix", "sklearn/manifold/tests/test_t_sne.py:test_non_square_precomputed_distances", "sklearn/manifold/tests/test_t_sne.py:test_non_positive_precomputed_distances", "sklearn/manifold/tests/test_t_sne.py:test_no_sparse_on_barnes_hut", "sklearn/manifold/tests/test_t_sne.py:test_barnes_hut_angle"], "edited_entities": ["sklearn/manifold/tests/test_t_sne.py:test_binary_search", "sklearn/manifold/tests/test_t_sne.py:test_binary_search_neighbors", "sklearn/manifold/tests/test_t_sne.py:test_binary_perplexity_stability", "sklearn/manifold/tests/test_t_sne.py:test_fit_csr_matrix", "sklearn/manifold/tests/test_t_sne.py:test_non_square_precomputed_distances", "sklearn/manifold/tests/test_t_sne.py:test_non_positive_precomputed_distances", "sklearn/manifold/tests/test_t_sne.py:test_no_sparse_on_barnes_hut", "sklearn/manifold/tests/test_t_sne.py:test_barnes_hut_angle"]}}, {"file": "sklearn/neighbors/__init__.py", "changes": {}}, {"file": "sklearn/neighbors/base.py", "changes": {"edited_modules": ["sklearn/neighbors/base.py:NeighborsBase", "sklearn/neighbors/base.py:KNeighborsMixin", "sklearn/neighbors/base.py:RadiusNeighborsMixin", "sklearn/neighbors/base.py:_tree_query_parallel_helper", "sklearn/neighbors/base.py:_tree_query_radius_parallel_helper"], "edited_entities": ["sklearn/neighbors/base.py:NeighborsBase._fit", "sklearn/neighbors/base.py:KNeighborsMixin.kneighbors", "sklearn/neighbors/base.py:KNeighborsMixin.kneighbors_graph", "sklearn/neighbors/base.py:RadiusNeighborsMixin.radius_neighbors_graph", "sklearn/neighbors/base.py:_tree_query_parallel_helper", "sklearn/neighbors/base.py:_tree_query_radius_parallel_helper", "sklearn/neighbors/base.py:RadiusNeighborsMixin", "sklearn/neighbors/base.py:RadiusNeighborsMixin.radius_neighbors"]}}, {"file": "sklearn/neighbors/classification.py", "changes": {"edited_modules": ["sklearn/neighbors/classification.py:KNeighborsClassifier", "sklearn/neighbors/classification.py:RadiusNeighborsClassifier"], "edited_entities": ["sklearn/neighbors/classification.py:KNeighborsClassifier", "sklearn/neighbors/classification.py:RadiusNeighborsClassifier", "sklearn/neighbors/classification.py:KNeighborsClassifier.predict", "sklearn/neighbors/classification.py:KNeighborsClassifier.predict_proba", "sklearn/neighbors/classification.py:RadiusNeighborsClassifier.predict", "sklearn/neighbors/classification.py:RadiusNeighborsClassifier.predict_proba"]}}, {"file": "sklearn/neighbors/graph.py", "changes": {"edited_modules": ["sklearn/neighbors/graph.py:radius_neighbors_graph", "sklearn/neighbors/graph.py:_query_include_self", "sklearn/neighbors/graph.py:kneighbors_graph"], "edited_entities": ["sklearn/neighbors/graph.py:radius_neighbors_graph", "sklearn/neighbors/graph.py:_query_include_self", "sklearn/neighbors/graph.py:kneighbors_graph"]}}, {"file": "sklearn/neighbors/lof.py", "changes": {"edited_modules": ["sklearn/neighbors/lof.py:LocalOutlierFactor"], "edited_entities": ["sklearn/neighbors/lof.py:LocalOutlierFactor", "sklearn/neighbors/lof.py:LocalOutlierFactor.fit", "sklearn/neighbors/lof.py:LocalOutlierFactor._predict", "sklearn/neighbors/lof.py:LocalOutlierFactor._local_reachability_density"]}}, {"file": "sklearn/neighbors/regression.py", "changes": {"edited_modules": ["sklearn/neighbors/regression.py:KNeighborsRegressor", "sklearn/neighbors/regression.py:RadiusNeighborsRegressor"], "edited_entities": ["sklearn/neighbors/regression.py:KNeighborsRegressor", "sklearn/neighbors/regression.py:RadiusNeighborsRegressor", "sklearn/neighbors/regression.py:KNeighborsRegressor.predict", "sklearn/neighbors/regression.py:RadiusNeighborsRegressor.predict"]}}, {"file": "sklearn/neighbors/tests/test_neighbors.py", "changes": {"edited_modules": ["sklearn/neighbors/tests/test_neighbors.py:test_k_and_radius_neighbors_duplicates", "sklearn/neighbors/tests/test_neighbors.py:test_radius_neighbors_predict_proba", "sklearn/neighbors/tests/test_neighbors.py:test_precomputed", "sklearn/neighbors/tests/test_neighbors.py:test_kneighbors_regressor_sparse"], "edited_entities": ["sklearn/neighbors/tests/test_neighbors.py:test_k_and_radius_neighbors_duplicates", "sklearn/neighbors/tests/test_neighbors.py:test_radius_neighbors_predict_proba", "sklearn/neighbors/tests/test_neighbors.py:test_precomputed", "sklearn/neighbors/tests/test_neighbors.py:test_kneighbors_regressor_sparse"]}}, {"file": "sklearn/neighbors/unsupervised.py", "changes": {"edited_modules": ["sklearn/neighbors/unsupervised.py:NearestNeighbors"], "edited_entities": ["sklearn/neighbors/unsupervised.py:NearestNeighbors"]}}, {"file": "sklearn/utils/estimator_checks.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "c56bce482db698c7c7e7b583b8b2e08a211eb48b", "problem_statement": "Toward a consistent API for NearestNeighbors & co\n\n### Estimators relying on `NearestNeighbors` (NN), and their related params:\r\n`params = (algorithm, leaf_size, metric, p, metric_params, n_jobs)`\r\n\r\n**sklearn.neighbors:**\r\n- `NearestNeighbors(n_neighbors, radius, *params)`\r\n- `KNeighborsClassifier(n_neighbors, *params)`\r\n- `KNeighborsRegressor(n_neighbors, *params)`\r\n- `RadiusNeighborsClassifier(radius, *params)`\r\n- `RadiusNeighborsRegressor(radius, *params)`\r\n- `LocalOutlierFactor(n_neighbors, *params)`\r\n- ~`KernelDensity(algorithm, metric, leaf_size, metric_params)`\r\n\r\n**sklearn.manifold:**\r\n- `TSNE(method=\"barnes_hut\", metric)`\r\n- `Isomap(n_neighbors, neighbors_algorithm, n_jobs)`\r\n- `LocallyLinearEmbedding(n_neighbors, neighbors_algorithm, n_jobs)`\r\n- `SpectralEmbedding(affinity='nearest_neighbors', n_neighbors, n_jobs)`\r\n\r\n**sklearn.cluster:**\r\n- `SpectralClustering(affinity='nearest_neighbors', n_neighbors, n_jobs)`\r\n- `DBSCAN(eps, *params)`\r\n\r\n### How do they call `NearestNeighbors` ?\r\n- Inherit from `NeighborsBase._fit`: NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor, RadiusNeighborsClassifier, RadiusNeighborsRegressor, LocalOutlierFactor\r\n- Call `BallTree/KDTree(X)`: KernelDensity\r\n- Call `kneighbors_graph(X)`: SpectralClustering, SpectralEmbedding\r\n- Call `NearestNeighbors().fit(X)`: TSNE, DBSCAN, Isomap, kneighbors_graph\r\n\r\n### Do they handle other form of input X?\r\n- Handle precomputed distances matrix, with (metric/affinity='precomputed'): TSNE, DBSCAN, SpectralEmbedding, SpectralClustering\r\n- Handle `KNeighborsMixin` object: kneighbors_graph\r\n- Handle `NeighborsBase` object: all estimators inheriting NeighborsBase + UnsupervisedMixin\r\n- Handle `BallTree/KDTree` object: all estimators inheriting NeighborsBase + SupervisedFloatMixin/SupervisedIntegerMixin\r\n___\r\n### Issues:\r\n1. We don't have all NN parameters in all classes (e.g. `n_jobs` in TSNE).\r\n2. We can't give a custom NN estimators to these classes. (PR #3922 #8999)\r\n3. The handle of input X as a `NearestNeighbors/BallTree/KDTree` object is not consistent, and not well documented. Sometimes it is documented but does not work (e.g. Isomap), or not well documented but it does work (e.g. LocalOutlierFactor). Most classes almost handle it since `NearestNeighbors().fit(NearestNeighbors().fit(X))` works, but a call to `check_array(X)` prevents it (e.g. Isomap, DBSCAN, SpectralEmbedding, SpectralClustering, LocallyLinearEmbedding, TSNE).\r\n4. The handle of X as a precomputed distances matrix is not consistent, and sometimes does not work with sparse matrices (as given by `kneighbors_graph`) (e.g. TSNE #9691).\r\n\r\n### Proposed solutions:\r\n\r\nA. We could generalize the use of precomputed distances matrix, and use pipelines to chain `NearestNeighbors` with other estimators. Yet it might not be possible/efficient for some estimators. I this case one would have to adapt the estimators to allow for the following: `Estimator(neighbors='precomputed').fit(distance_matrix, y)`\r\n\r\nB. We could improve the checking of X to enable more widely having X as a `NearestNeighbors/BallTree/KDTree` fitted object. The changes would be probably limited, however, this solution is not pipeline-friendly.\r\n\r\nC. To be pipeline-friendly, a custom `NearestNeighbors` object could be passed in the params, unfitted. We could then put all NN-related parameters in this estimator parameter, and allow custom estimators with a clear API. This is essentially what is proposed in #8999.", "patch": ""}
{"instance_id": "psf__requests-1088", "file_changes": [{"file": "requests/sessions.py", "changes": {"edited_modules": ["requests/sessions.py:Session"], "edited_entities": ["requests/sessions.py:Session"]}}], "repo": "psf/requests", "base_commit": "be62645dd56580dd7576032b348cf79d880851d8", "problem_statement": "Session pickling support is broken and tests for it are removed\n\nThe commit 42b029552190f6639642d0f62d27abcd1ceed51e removes the `__attrs__` attribute of the `Session` class, which is used in the pickle protocol's `__getstate__` method.\n\nThe tests that are testing this functionality (functions `test_session_pickling` and `test_unpickled_session_requests` in the once present `tests/test_requests.py`) are also removed.\n\nThe commit messages don't seem to indicate any reason for this, and I can't find anything searching in the issues.\n\nIf it is intended that pickling of Session objects not be supported, could you give the reason? And may be the `__getstate__` and `__setstate__` methods should be removed too, as they might send a wrong message.\n\nIf this is unintended (which is what I think is the case), I can work on a pull request to fix this. Please confirm.\n\nThank you.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-19489", "file_changes": [{"file": "doc/whats_new/v1.0.rst", "changes": {}}, {"file": "sklearn/feature_extraction/_dict_vectorizer.py", "changes": {"edited_modules": ["sklearn/feature_extraction/_dict_vectorizer.py:DictVectorizer"], "edited_entities": ["sklearn/feature_extraction/_dict_vectorizer.py:DictVectorizer._transform"]}}, {"file": "sklearn/feature_extraction/tests/test_dict_vectorizer.py", "changes": {"edited_modules": ["sklearn/feature_extraction/tests/test_dict_vectorizer.py:test_dictvectorizer_dense_sparse_equivalence"], "edited_entities": ["sklearn/feature_extraction/tests/test_dict_vectorizer.py:test_dictvectorizer_dense_sparse_equivalence"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "6f7ae911f18fda59669309582706f1aa1f36374d", "problem_statement": "'feature_name' referenced before assignment\n\n<!--\r\nBefore submitting a bug, please make sure the issue hasn't been already\r\naddressed by searching through the past issues.\r\n-->\r\n\r\n#### Describe the bug\r\n\r\nWhen I run some preprocessing on my data the line triggering the error is:\r\n\r\n```\r\nC:\\local_tools\\Anaconda3\\envs\\mother_env\\lib\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py in _transform(self, X, fitting)\r\n    226                                                indices=indices, values=values)\r\n    227 \r\n--> 228                 if feature_name is not None:\r\n    229                     if fitting and feature_name not in vocab:\r\n    230                         vocab[feature_name] = len(feature_names)\r\n\r\nUnboundLocalError: local variable 'feature_name' referenced before assignment\r\n```\r\n\r\n#### Steps/Code to Reproduce\r\n<!--\r\nPlease add a minimal example that we can reproduce the error by running the\r\ncode. Be as succinct as possible, do not depend on external data. In short, we\r\nare going to copy-paste your code and we expect to get the same\r\nresult as you.\r\n\r\nExample:\r\n```python\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nfrom sklearn.decomposition import LatentDirichletAllocation\r\ndocs = [\"Help I have a bug\" for i in range(1000)]\r\nvectorizer = CountVectorizer(input=docs, analyzer='word')\r\nlda_features = vectorizer.fit_transform(docs)\r\nlda_model = LatentDirichletAllocation(\r\n    n_topics=10,\r\n    learning_method='online',\r\n    evaluate_every=10,\r\n    n_jobs=4,\r\n)\r\nmodel = lda_model.fit(lda_features)\r\n```\r\nIf the code is too long, feel free to put it in a public gist and link\r\nit in the issue: https://gist.github.com\r\n-->\r\n\r\nIt involves a bit too much preprocessing to put here but from inspecting the respective source file (see above, sklearn\\feature_extraction\\_dict_vectorizer.py) I have the strong suspicion that ```feature_name``` can go through all if/elif checks without being assigned anything.\r\n\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nFor scikit-learn >= 0.20:\r\nimport sklearn; sklearn.show_versions()\r\nFor scikit-learn < 0.20:\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\nimport imblearn; print(\"Imbalanced-Learn\", imblearn.__version__)\r\n-->\r\n\r\nSystem:\r\n    python: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\r\nexecutable: C:\\local_tools\\Anaconda3\\envs\\mother_env\\python.exe\r\n   machine: Windows-10-10.0.18362-SP0\r\n\r\nPython dependencies:\r\n          pip: 20.3.3\r\n   setuptools: 52.0.0.post20210125\r\n      sklearn: 0.24.1\r\n        numpy: 1.19.2\r\n        scipy: 1.6.0\r\n       Cython: None\r\n       pandas: 1.2.1\r\n   matplotlib: 3.3.4\r\n       joblib: 1.0.1\r\nthreadpoolctl: 2.1.0\r\n\r\nBuilt with OpenMP: True\r\n\r\n<!-- Thanks for contributing! -->", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-8996", "file_changes": [{"file": "benchmarks/bench_plot_approximate_neighbors.py", "changes": {}}, {"file": "doc/modules/classes.rst", "changes": {}}, {"file": "doc/modules/neighbors.rst", "changes": {}}, {"file": "doc/whats_new.rst", "changes": {}}, {"file": "examples/neighbors/plot_approximate_nearest_neighbors_hyperparameters.py", "changes": {}}, {"file": "examples/neighbors/plot_approximate_nearest_neighbors_scalability.py", "changes": {}}, {"file": "sklearn/neighbors/approximate.py", "changes": {"edited_modules": ["sklearn/neighbors/approximate.py:LSHForest"], "edited_entities": ["sklearn/neighbors/approximate.py:LSHForest"]}}, {"file": "sklearn/neighbors/tests/test_approximate.py", "changes": {"edited_modules": ["sklearn/neighbors/tests/test_approximate.py:test_neighbors_accuracy_with_n_candidates", "sklearn/neighbors/tests/test_approximate.py:test_neighbors_accuracy_with_n_estimators", "sklearn/neighbors/tests/test_approximate.py:test_kneighbors", "sklearn/neighbors/tests/test_approximate.py:test_radius_neighbors", "sklearn/neighbors/tests/test_approximate.py:test_radius_neighbors_boundary_handling", "sklearn/neighbors/tests/test_approximate.py:test_distances", "sklearn/neighbors/tests/test_approximate.py:test_fit", "sklearn/neighbors/tests/test_approximate.py:test_partial_fit", "sklearn/neighbors/tests/test_approximate.py:test_hash_functions", "sklearn/neighbors/tests/test_approximate.py:test_candidates", "sklearn/neighbors/tests/test_approximate.py:test_graphs", "sklearn/neighbors/tests/test_approximate.py:test_sparse_input"], "edited_entities": ["sklearn/neighbors/tests/test_approximate.py:test_neighbors_accuracy_with_n_candidates", "sklearn/neighbors/tests/test_approximate.py:test_neighbors_accuracy_with_n_estimators", "sklearn/neighbors/tests/test_approximate.py:test_kneighbors", "sklearn/neighbors/tests/test_approximate.py:test_radius_neighbors", "sklearn/neighbors/tests/test_approximate.py:test_radius_neighbors_boundary_handling", "sklearn/neighbors/tests/test_approximate.py:test_distances", "sklearn/neighbors/tests/test_approximate.py:test_fit", "sklearn/neighbors/tests/test_approximate.py:test_partial_fit", "sklearn/neighbors/tests/test_approximate.py:test_hash_functions", "sklearn/neighbors/tests/test_approximate.py:test_candidates", "sklearn/neighbors/tests/test_approximate.py:test_graphs", "sklearn/neighbors/tests/test_approximate.py:test_sparse_input"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "0fb9a50033574e36a8bd635d8e5c0a793428877c", "problem_statement": "Deprecate LSHForest\n\nLSHForest should be deprecated and scheduled for removal in 0.21. It should also warn about having bad performance. cc @ogrisel", "patch": ""}
{"instance_id": "pallets__flask-3628", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "src/flask/app.py", "changes": {"edited_modules": ["src/flask/app.py:Flask"], "edited_entities": ["src/flask/app.py:Flask.make_response"]}}, {"file": "tests/test_basic.py", "changes": {"edited_modules": ["tests/test_basic.py:from_response_headers", "tests/test_basic.py:test_response_types"], "edited_entities": ["tests/test_basic.py:from_response_headers", "tests/test_basic.py:test_response_types"]}}], "repo": "pallets/flask", "base_commit": "6f2fdc5ac4ad869a21c4c0281d7fa1eb8aa5a689", "problem_statement": "Returning Response and headers causes duplicate headers\n\n<!-- **This issue tracker is a tool to address bugs in Flask itself.\r\nPlease use the Pallets Discord or Stack Overflow for general questions\r\nabout using Flask or issues not related to Flask.** -->\r\n\r\n<!-- If you'd like to report a bug in Flask, fill out the template below. Provide\r\nany extra information that may be useful / related to your problem.\r\nIdeally, create an [MCVE](https://stackoverflow.com/help/mcve), which helps us\r\nunderstand the problem and helps check that it is not caused by something in\r\nyour code. -->\r\n\r\n### Expected Behavior\r\n\r\n```\r\nfrom flask import Flask\r\napp = Flask(__name__)\r\n@app.route('/')\r\ndef issue():\r\n    return {'test': 'test'}, {'Content-Type': 'test'}\r\n```\r\nUsing `curl -v http://127.0.0.1:5000/` to query the view I expect only one `Content-Type` header > `Content-Type: test`\r\n\r\n### Actual Behavior\r\n\r\nDuplicate headers are returned\r\n\r\n```\r\n< Content-Type: application/json\r\n< Content-Type: test\r\n```\r\n\r\n### Environment\r\n\r\n* Python version: 3.8.2\r\n* Flask version: 1.1.2\r\n* Werkzeug version: 1.0.1\r\n\r\n### Context\r\n\r\nThis issue also effects responses created with make_response when using a dict or jsonify body + the headers argument with a 'Content-Type':\r\n\r\n```\r\nfrom flask import Flask, make_response\r\napp = Flask(__name__)\r\n@app.route('/')\r\ndef issue():\r\n    return make_response({'test': 'test'}, {'Content-Type': 'test'})\r\n```\r\n\r\nThis issue is caused by jsonify adding a 'Content-Type' header then make_response uses `extent` to add the additional headers, thus leading to the duplicate.\r\n\r\nReturning a str/bytes body does not have this problem as no 'Content-Type' is added by flask, if one is missing it is added by werkzeug.\r\n\r\nThe reason I came across this issue is we have older code which does `return json.dumps(data), 200, {'Content-Type': 'application/json+somecustomtype'}` and I assumed based on the flask docs that just returning the data and letting flask do the jsonify would be better.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-18408", "file_changes": [{"file": "doc/whats_new/v0.24.rst", "changes": {}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:BaseHistGradientBoosting"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:BaseHistGradientBoosting._raw_predict"]}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:test_staged_predict"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:test_staged_predict"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "2b79665b90bd54fa59701090d5f608a1fc4dd33a", "problem_statement": "Data type mismatch problem when calling HistGradientBoostingClassifier.predict()\n\n<!--\r\nBefore submitting a bug, please make sure the issue hasn't been already\r\naddressed by searching through the past issues.\r\n-->\r\n\r\n#### Describe the bug\r\nIt looks like HistGradientBoostingClassifier has problems on handling datasets with different data types. It works fine when X is `np.float`. However, when X is of the type `uint8`, HistGradientBoostingClassifier crushes when calling `predict()`.\r\n\r\n#### Steps/Code to Reproduce\r\n<!--\r\nPlease add a minimal example that we can reproduce the error by running the\r\ncode. Be as succinct as possible, do not depend on external data. In short, we\r\nare going to copy-paste your code and we expect to get the same\r\nresult as you.\r\n\r\nExample:\r\n```python\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nfrom sklearn.decomposition import LatentDirichletAllocation\r\ndocs = [\"Help I have a bug\" for i in range(1000)]\r\nvectorizer = CountVectorizer(input=docs, analyzer='word')\r\nlda_features = vectorizer.fit_transform(docs)\r\nlda_model = LatentDirichletAllocation(\r\n    n_topics=10,\r\n    learning_method='online',\r\n    evaluate_every=10,\r\n    n_jobs=4,\r\n)\r\nmodel = lda_model.fit(lda_features)\r\n```\r\nIf the code is too long, feel free to put it in a public gist and link\r\nit in the issue: https://gist.github.com\r\n-->\r\n\r\n```\r\nfrom keras.datasets import mnist\r\nfrom sklearn.metrics import accuracy_score\r\nfrom sklearn.experimental import enable_hist_gradient_boosting\r\nfrom sklearn.ensemble import HistGradientBoostingClassifier\r\n\r\n\r\nif __name__ == '__main__':\r\n    \r\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n    X_train = X_train.reshape(X_train.shape[0], -1)\r\n    X_test = X_test.reshape(X_test.shape[0], -1)\r\n    \r\n    model = HistGradientBoostingClassifier(max_iter=100,\r\n                                           loss='categorical_crossentropy',\r\n                                           validation_fraction=None,\r\n                                           random_state=0)\r\n    \r\n    model.fit(X_train, y_train)\r\n    y_pred = model.predict(X_test)\r\n    acc = accuracy_score(y_test, y_pred)\r\n    \r\n    print('Testing Acc: {:.4f} %'.format(100.*acc))\r\n```\r\n\r\n#### Expected Results\r\nThe HistGradientBoostingClassifier successfully returns prediction results.\r\n\r\n#### Actual Results\r\n```\r\n  File \"FILEPATH\", line 21, in <module>\r\n    y_pred = model.predict(X_test)\r\n\r\n  File \"C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\", line 1114, in predict\r\n    encoded_classes = np.argmax(self.predict_proba(X), axis=1)\r\n\r\n  File \"C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\", line 1130, in predict_proba\r\n    raw_predictions = self._raw_predict(X)\r\n\r\n  File \"C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\", line 667, in _raw_predict\r\n    raw_predictions[k, :] += predict(X)\r\n\r\n  File \"C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\predictor.py\", line 47, in predict\r\n    _predict_from_numeric_data(self.nodes, X, out)\r\n\r\n  File \"sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\", line 26, in sklearn.ensemble._hist_gradient_boosting._predictor._predict_from_numeric_data\r\n\r\nValueError: Buffer dtype mismatch, expected 'const X_DTYPE_C' but got 'unsigned char'\r\n```\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nFor scikit-learn >= 0.20:\r\nimport sklearn; sklearn.show_versions()\r\nFor scikit-learn < 0.20:\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\nimport imblearn; print(\"Imbalanced-Learn\", imblearn.__version__)\r\n-->\r\n\r\ncython == 0.29.21\r\nscikit-learn == 0.23.1\r\n\r\n<!-- Thanks for contributing! -->", "patch": ""}
{"instance_id": "huggingface__transformers-9620", "file_changes": [{"file": "examples/question-answering/requirements.txt", "changes": {}}, {"file": "examples/question-answering/run_qa.py", "changes": {"edited_modules": ["examples/question-answering/run_qa.py:main"], "edited_entities": ["examples/question-answering/run_qa.py:main"]}}, {"file": "examples/question-answering/run_qa_beam_search.py", "changes": {"edited_modules": ["examples/question-answering/run_qa_beam_search.py:main"], "edited_entities": ["examples/question-answering/run_qa_beam_search.py:main"]}}, {"file": "examples/question-answering/squad_v2_local/evaluate.py", "changes": {}}, {"file": "examples/question-answering/squad_v2_local/squad_v2_local.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "fa876aee2adf525b597495c10ad9c96896953dbd", "problem_statement": "SQuAD 2.0 metric not supported\n\nHello.\r\nI'm trying to run the official `run_qa.py` code for SQuAD 2.0.\r\n\r\nYou have an open TODO here that is causing a bug: https://github.com/huggingface/transformers/blob/master/examples/question-answering/run_qa.py#L436\r\n\r\nI would like to know what is the status of this TODO, and if it is going to be updated, or is there a way around it.\r\n\r\nThis is the current code:\r\n\r\n```python\r\n    current_dir = os.path.sep.join(os.path.join(__file__).split(os.path.sep)[:-1])\r\n    metric = load_metric(os.path.join(current_dir, \"squad_v2_local\") if data_args.version_2_with_negative else \"squad\")\r\n```\r\n\r\nI receive: \r\n```\r\nFileNotFoundError: Couldn't find file locally at .../squad_v2_local/squad_v2_local.py,\r\n```\r\n\r\nI've tried to change it to: \r\n```python\r\nmetric = load_metric(\"squad_v2\" if data_args.version_2_with_negative else \"squad\")\r\n```\r\n\r\nBut this is the stacktrace I receive: \r\n```\r\nTraceback (most recent call last):\r\n  File \"/data/users/yonatab/transformers_pip/QA/run_qa_val_more_valueable.py\", line 557, in <module>\r\n    main()\r\n  File \"/data/users/yonatab/transformers_pip/QA/run_qa_val_more_valueable.py\", line 538, in main\r\n    results = trainer.evaluate()\r\n  File \"/data/users/yonatab/transformers_pip/QA/trainer_qa.py\", line 63, in evaluate\r\n    metrics = self.compute_metrics(eval_preds)\r\n  File \"/data/users/yonatab/transformers_pip/QA/run_qa_val_more_valueable.py\", line 499, in compute_metrics\r\n    return metric.compute(predictions=p.predictions, references=p.label_ids)\r\n  File \"/data/users/yonatab/transformers_pip/trans_pip/lib/python3.6/site-packages/datasets/metric.py\", line 398, in compute\r\n    output = self._compute(predictions=predictions, references=references, **kwargs)\r\n  File \"/home/ec2-user/.cache/huggingface/modules/datasets_modules/metrics/squad_v2/7529efd518b03f775290694e7b797412cb2253e90b4f843af83cf7434cccb3a8/squad_v2.py\", line 108, in _compute\r\n    exact_raw, f1_raw = get_raw_scores(dataset, predictions)\r\n  File \"/home/ec2-user/.cache/huggingface/modules/datasets_modules/metrics/squad_v2/7529efd518b03f775290694e7b797412cb2253e90b4f843af83cf7434cccb3a8/evaluate.py\", line 111, in get_raw_scores\r\n    gold_answers = [a[\"text\"] for a in qa[\"answers\"] if normalize_answer(a[\"text\"])]\r\n  File \"/home/ec2-user/.cache/huggingface/modules/datasets_modules/metrics/squad_v2/7529efd518b03f775290694e7b797412cb2253e90b4f843af83cf7434cccb3a8/evaluate.py\", line 111, in <listcomp>\r\n    gold_answers = [a[\"text\"] for a in qa[\"answers\"] if normalize_answer(a[\"text\"])]\r\nTypeError: string indices must be integers\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:05<00:00,  2.51it/s]\r\n```\r\n\r\nHow can I solve it? \r\n\r\nThanks", "patch": ""}
{"instance_id": "pandas-dev__pandas-16870", "file_changes": [{"file": "doc/source/user_guide/groupby.rst", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "b5a5268dabb2a4dea1c3c543a1ddff501b87a447", "problem_statement": "(DOC) A `string` passed to `groupby` is hard to understand based on current doc\n\n#### Code Sample, a copy-pastable example if possible\r\nFrom [Here](pandas/doc/source/groupby.rst)\r\n```rst\r\nFor DataFrame objects, a string indicating a column to be used to group. Of course \r\ndf.groupby('A') is just syntactic sugar for df.groupby(df['A']), but \r\nit makes life simpler\r\nFor DataFrame objects, a string indicating an index level to be used to group.\r\n\r\n```\r\n#### Problem description\r\n\r\nThese two sentences are in a kind of conflict with each other, until one read until she read the note below.\r\n#### Expected Output\r\nReword to make it clear that a string may indicate column or index level\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 16.6.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.21.0.dev+193.gb2b5dc32e\r\npytest: 3.1.2\r\npip: 9.0.1\r\nsetuptools: 36.0.1\r\nCython: 0.25.2\r\nnumpy: 1.13.0\r\nscipy: 0.19.0\r\nxarray: None\r\nIPython: 6.0.0\r\nsphinx: 1.6.2\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: None\r\nnumexpr: 2.6.2\r\nfeather: None\r\nmatplotlib: 2.0.2\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 0.9999999\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-12401", "file_changes": [{"file": "doc/source/whatsnew/v0.21.0.txt", "changes": {}}, {"file": "pandas/core/common.py", "changes": {"edited_modules": ["pandas/core/common.py:_apply_if_callable"], "edited_entities": ["pandas/core/common.py:_apply_if_callable"]}}, {"file": "pandas/core/generic.py", "changes": {"edited_modules": ["pandas/core/generic.py:NDFrame"], "edited_entities": ["pandas/core/generic.py:NDFrame.select", "pandas/core/generic.py:NDFrame.filter"]}}, {"file": "pandas/core/indexing.py", "changes": {"edited_modules": ["pandas/core/indexing.py:_NDFrameIndexer", "pandas/core/indexing.py:_LocationIndexer", "pandas/core/indexing.py:_iLocIndexer", "pandas/core/indexing.py:_IXIndexer", "pandas/core/indexing.py:_LocIndexer"], "edited_entities": ["pandas/core/indexing.py:_NDFrameIndexer.__call__", "pandas/core/indexing.py:_NDFrameIndexer.__getitem__", "pandas/core/indexing.py:_NDFrameIndexer", "pandas/core/indexing.py:_NDFrameIndexer._convert_tuple", "pandas/core/indexing.py:_NDFrameIndexer._getitem_iterable", "pandas/core/indexing.py:_NDFrameIndexer._convert_to_indexer", "pandas/core/indexing.py:_LocationIndexer", "pandas/core/indexing.py:_iLocIndexer._getitem_tuple", "pandas/core/indexing.py:_iLocIndexer._get_list_axis", "pandas/core/indexing.py:_NDFrameIndexer._get_label", "pandas/core/indexing.py:_NDFrameIndexer._get_setitem_indexer", "pandas/core/indexing.py:_NDFrameIndexer._multi_take_opportunity", "pandas/core/indexing.py:_NDFrameIndexer._convert_for_reindex", "pandas/core/indexing.py:_NDFrameIndexer._getitem_lowerdim", "pandas/core/indexing.py:_NDFrameIndexer._getitem_nested_tuple", "pandas/core/indexing.py:_NDFrameIndexer._getitem_axis", "pandas/core/indexing.py:_IXIndexer.__init__", "pandas/core/indexing.py:_IXIndexer._has_valid_type", "pandas/core/indexing.py:_LocIndexer._is_scalar_access", "pandas/core/indexing.py:_iLocIndexer._is_valid_list_like", "pandas/core/indexing.py:_iLocIndexer._getitem_axis"]}}, {"file": "pandas/tests/frame/test_alter_axes.py", "changes": {"edited_modules": ["pandas/tests/frame/test_alter_axes.py:TestDataFrameAlterAxes"], "edited_entities": ["pandas/tests/frame/test_alter_axes.py:TestDataFrameAlterAxes.test_set_index_bug"]}}, {"file": "pandas/tests/frame/test_axis_select_reindex.py", "changes": {"edited_modules": ["pandas/tests/frame/test_axis_select_reindex.py:TestDataFrameSelectReindex"], "edited_entities": ["pandas/tests/frame/test_axis_select_reindex.py:TestDataFrameSelectReindex", "pandas/tests/frame/test_axis_select_reindex.py:TestDataFrameSelectReindex.test_select"]}}, {"file": "pandas/tests/frame/test_mutate_columns.py", "changes": {}}, {"file": "pandas/tests/groupby/test_groupby.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_groupby.py:TestGroupBy"], "edited_entities": ["pandas/tests/groupby/test_groupby.py:TestGroupBy._func"]}}, {"file": "pandas/tests/series/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/series/test_indexing.py:TestSeriesIndexing"], "edited_entities": ["pandas/tests/series/test_indexing.py:TestSeriesIndexing.test_select"]}}, {"file": "pandas/tests/test_multilevel.py", "changes": {"edited_modules": ["pandas/tests/test_multilevel.py:TestMultiLevel"], "edited_entities": ["pandas/tests/test_multilevel.py:TestMultiLevel.test_groupby_level_no_obs"]}}], "repo": "pandas-dev/pandas", "base_commit": "48d0460ab9acbee223bae1be699344f8fd232224", "problem_statement": "DEPR: filter & select\n\ndo we need label selectors? we should for sure just have a single method for this. maybe call it `query_labels`? to be consistent with `.query` as the workhorse for data selection.\r\n\r\n- [x] ``.select`` (#17633)\r\n- [ ] ``.filter``\r\n\r\nxref #6599", "patch": ""}
{"instance_id": "psf__requests-1", "file_changes": [{"file": "requests/core.py", "changes": {"edited_modules": ["requests/core.py:Request"], "edited_entities": ["requests/core.py:Request.__init__", "requests/core.py:Request", "requests/core.py:Request._get_opener"]}}], "repo": "psf/requests", "base_commit": "2203c3bccd5e4888a16d73247d540fd6e359d29c", "problem_statement": "Cookie support?\n\nAn feature request (not found in documentation).\n\nDoes this support cookies?\n\nUsecase: I can integrate this module inside an existings framework. This framework generate for me the authentication/session cookie, so to perform request using requests there I need to add the same auth cookie already generated.", "patch": ""}
{"instance_id": "psf__requests-1859", "file_changes": [{"file": "requests/cookies.py", "changes": {"edited_modules": ["requests/cookies.py:morsel_to_cookie"], "edited_entities": ["requests/cookies.py:morsel_to_cookie"]}}], "repo": "psf/requests", "base_commit": "ac4e05874a1a983ca126185a0e4d4e74915f792e", "problem_statement": "Brittle test\n\nThe test `test_expires_valid_str` fails on my OS X box, in Python 2.7:\n\n``` python\n============================= test session starts ==============================\nplatform darwin -- Python 2.7.5 -- pytest-2.3.4\nplugins: cov\ncollected 116 items \n\ntest_requests.py .................................................................................................................F..\n\n=================================== FAILURES ===================================\n_______________ TestMorselToCookieExpires.test_expires_valid_str _______________\n\nself = <test_requests.TestMorselToCookieExpires testMethod=test_expires_valid_str>\n\n    def test_expires_valid_str(self):\n        \"\"\"Test case where we convert expires from string time.\"\"\"\n\n        morsel = Morsel()\n        morsel['expires'] = 'Thu, 01-Jan-1970 00:00:01 GMT'\n        cookie = morsel_to_cookie(morsel)\n>       assert cookie.expires == 1\nE       AssertionError: assert -3599 == 1\nE        +  where -3599 = Cookie(version=0, name=None, value=None, port=None, port_specified=False, domain='', domain_specified=False, domain_in...False, secure=False, expires=-3599, discard=False, comment='', comment_url=False, rest={'HttpOnly': ''}, rfc2109=False).expires\n\ntest_requests.py:1111: AssertionError\n==================== 1 failed, 115 passed in 23.32 seconds =====================\n```\n\nI've not yet got a good theory for this, though I think it's telling that the error is one hour. I don't know _what_ it's telling though, because time is complicated.\n\nAnyway, this test needs to be rewritten to be more accepting of breakage. It's also possible that the intermittent failure of this test represents a problem with the `morsel_to_cookie` function itself, in which case that needs rewriting.", "patch": ""}
{"instance_id": "huggingface__transformers-9438", "file_changes": [{"file": "docs/source/benchmarks.rst", "changes": {}}, {"file": "utils/style_doc.py", "changes": {"edited_modules": ["utils/style_doc.py:style_rst_file"], "edited_entities": ["utils/style_doc.py:style_rst_file"]}}], "repo": "huggingface/transformers", "base_commit": "02e05fb0a532e572b56ba75dad6ba3db625bbdeb", "problem_statement": "Doc styling utils adds parasites new lines\n\n## Environment info\r\n     \r\n- `transformers` version: 4.2.0dev0\r\n- Platform: Windows-10-10.0.18362-SP0\r\n- Python version: 3.7.9\r\n- PyTorch version (GPU?): 1.7.1 (False)\r\n- Tensorflow version (GPU?): 2.3.1 (False)\r\n- Using GPU in script?: Nope\r\n- Using distributed or parallel set-up in script?: Nope\r\n\r\n### Who can help\r\n\r\n@sgugger \r\n\r\n## Information\r\n\r\nRunning the python util to style docs adds parasite new lines in every single docstring. See:\r\n\r\n```bash\r\n$ python utils/style_doc.py src/transformers docs/source --max_len 119 --check_only\r\nTraceback (most recent call last):\r\n  File \"utils/style_doc.py\", line 491, in <module>\r\n    main(*args.files, max_len=args.max_len, check_only=args.check_only)\r\n  File \"utils/style_doc.py\", line 479, in main\r\n    raise ValueError(f\"{len(changed)} files should be restyled!\")\r\nValueError: 345 files should be restyled!\r\n```\r\n\r\nSee this commit for an example of what it does: https://github.com/huggingface/transformers/pull/9150/commits/b4dedd5ca25f043c66d12c774fa00a34c74dffb2\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Checkout and update master branch\r\n2. run `python utils/style_doc.py src/transformers docs/source --max_len 119 --check-only` from transformers root\r\n\r\nOutput:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"utils/style_doc.py\", line 491, in <module>\r\n    main(*args.files, max_len=args.max_len, check_only=args.check_only)\r\n  File \"utils/style_doc.py\", line 479, in main\r\n    raise ValueError(f\"{len(changed)} files should be restyled!\")\r\nValueError: 345 files should be restyled!\r\n```\r\n\r\nIt might have something to do with Windows or a particular setup of my machine because behavior cannot be reproduced by @patrickvonplaten.\r\n\r\n## Expected behavior\r\n\r\nOn master branch, documentation should not need to be restyled", "patch": ""}
{"instance_id": "pallets__flask-4602", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "src/flask/scaffold.py", "changes": {"edited_modules": ["src/flask/scaffold.py:_find_package_path", "src/flask/scaffold.py:find_package"], "edited_entities": ["src/flask/scaffold.py:_find_package_path", "src/flask/scaffold.py:find_package"]}}, {"file": "tests/test_instance_config.py", "changes": {}}, {"file": "tox.ini", "changes": {}}], "repo": "pallets/flask", "base_commit": "fb89745408cc02515815c792355c7e883b2d08a4", "problem_statement": "Flask.auto_find_instance_path() can return wrong path for namespace packages installed in development mode\n\nhttps://github.com/pallets/flask/blob/bd56d19b167822a9a23e2e9e2a07ccccc36baa8d/src/flask/scaffold.py#L798\r\n\r\nIf there are several packages under the same namespace, all installed in development mode, like:\r\n\r\n```\r\n~/namespace-package1/\r\n    namespace/\r\n        package1/\r\n            __init__.py\r\n            app.py\r\n    instance/\r\n\r\n~/namespace-package2/\r\n    namespace/\r\n        package2/\r\n            __init__.py\r\n            app.py\r\n    instance/\r\n```\r\nand the code in `namespace.package2` uses `app.instance_path`, then its expected value is `~/namespace-package2/instance` ([\"Uninstalled package\" decision path](https://flask.palletsprojects.com/en/2.1.x/config/#instance-folders)).\r\n\r\nInstead of that the following happens:\r\n* `find_package()` [cuts import info](https://github.com/pallets/flask/blob/bd56d19b167822a9a23e2e9e2a07ccccc36baa8d/src/flask/scaffold.py#L846) to the very top package name, `namespace`,\r\n* then `_find_package_path()` finds module specification for the whole namespace package, which contains several submodule search locations, like `ModuleSpec(name='namespace', loader=<_frozen_importlib_external._NamespaceLoader object at ...>, submodule_search_locations=_NamespacePath(['~/namespace-package1/namespace', '~/namespace-package2/namespace']))`\r\n* and then the quoted line returns first, i.e. _arbitrary_, package from that namespace, e.g. `~/namespace-package1`, which produces wrong instance path.\r\n\r\nSuggestion: pass also `import_name` into `_find_package_path` and use it for resolving ambiguity at this point, like:\r\n\r\n```\r\ndef _find_package_path(root_mod_name, import_name):\r\n...\r\n            if spec.origin in {\"namespace\", None}:\r\n                package_spec = importlib.util.find_spec(import_name)\r\n                package_path = os.path.commonpath(package_spec.submodule_search_locations)\r\n                return os.path.dirname(next(\r\n                    location for location in spec.submodule_search_locations\r\n                    if package_path.startswith(location)\r\n                ))\r\n```", "patch": ""}
{"instance_id": "huggingface__transformers-20395", "file_changes": [{"file": "src/transformers/tokenization_utils_base.py", "changes": {"edited_modules": ["src/transformers/tokenization_utils_base.py:PreTrainedTokenizerBase"], "edited_entities": ["src/transformers/tokenization_utils_base.py:PreTrainedTokenizerBase.save_pretrained"]}}], "repo": "huggingface/transformers", "base_commit": "0ee71188ff184ee5f8b70081665858301fe4afb1", "problem_statement": "some tokenizer(s) don't save the updated attributes\n\n### System Info\r\n\r\ntransformers version: 4.25.0.dev0\r\nTorch version: 1.13.0+cpu\r\nCuda available: False\r\nCuda version: None\r\nCuDNN version: None\r\nNumber of GPUs available: 0\r\n\r\n### Description\r\n\r\nFor `GPT2Tokenizer(Fast)`, Set `tokenizer.model_max_length` to `128` (originally `1024`), save it then reload, will give `tokenizer.model_max_length` being `1024`.\r\n\r\n### Reproduction\r\n\r\n```python\r\nfrom transformers import GPT2Tokenizer, GPT2TokenizerFast\r\n\r\ntokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\r\nprint(tokenizer.model_max_length)\r\n\r\ntokenizer.model_max_length = 128\r\nprint(tokenizer.model_max_length)\r\n\r\ntokenizer.save_pretrained(\"my-gpt2\")\r\ntokenizer_loaded = GPT2TokenizerFast.from_pretrained(\"my-gpt2\")\r\nprint(tokenizer_loaded.model_max_length)\r\n```\r\n\r\nThe output is\r\n\r\n```bash\r\n1024\r\n128\r\n1024\r\n\r\n```\r\n\r\n\r\n### Expected behavior\r\n\r\n`tokenizer_loaded.model_max_length` should be `128` in the above example. In general, the updated attribute(s) should be saved.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-2190", "file_changes": [{"file": "sklearn/neighbors/binary_tree.pxi", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "0bbd57b322aaa5aeca4f3af2dd7f802360d29673", "problem_statement": "crash in MeanShift tests after make cython (edited from k_means)\n\nThe crash:\n\n```\n[erg@pliny scikit-learn]$ [master*] nosetests -v\n/home/erg/python/scikit-learn/sklearn/feature_selection/selector_mixin.py:7: DeprecationWarning: sklearn.feature_selection.selector_mixin.SelectorMixin has been renamed sklearn.feature_selection.from_model._LearntSelectorMixin, and this alias will be removed in version 0.16\n  DeprecationWarning)\nAffinity Propagation algorithm ... ok\nTests the DBSCAN algorithm with a similarity array. ... ok\nTests the DBSCAN algorithm with a feature vector array. ... ok\nTests the DBSCAN algorithm with a callable metric. ... ok\nsklearn.cluster.tests.test_dbscan.test_pickle ... ok\nCheck that we obtain the correct solution for structured ward tree. ... ok\nCheck that we obtain the correct solution for unstructured ward tree. ... ok\nCheck that the height of ward tree is sorted. ... ok\nCheck that we obtain the correct number of clusters with Ward clustering. ... ok\nCheck that we obtain the correct solution in a simplistic case ... ok\nTest scikit ward with full connectivity (i.e. unstructured) vs scipy ... ok\nCheck that connectivity in the ward tree is propagated correctly during ... ok\nCheck non regression of a bug if a non item assignable connectivity is ... ok\nsklearn.cluster.tests.test_k_means.test_square_norms ... ok\nsklearn.cluster.tests.test_k_means.test_kmeans_dtype ... ok\nsklearn.cluster.tests.test_k_means.test_labels_assignment_and_inertia ... ok\nCheck that dense and sparse minibatch update give the same results ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_plus_plus_init ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_check_fitted ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_new_centers ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_plus_plus_init_2_jobs ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_plus_plus_init_sparse ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_random_init ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_random_init_sparse ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_plus_plus_init_not_precomputed ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_random_init_not_precomputed ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_perfect_init ... ok\nsklearn.cluster.tests.test_k_means.test_mb_k_means_plus_plus_init_dense_array ... ok\nsklearn.cluster.tests.test_k_means.test_mb_kmeans_verbose ... ok\nsklearn.cluster.tests.test_k_means.test_mb_k_means_plus_plus_init_sparse_matrix ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_init_with_large_k ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_k_means_random_init_dense_array ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_k_means_random_init_sparse_csr ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_k_means_perfect_init_dense_array ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_k_means_perfect_init_sparse_csr ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_reassign ... ok\nsklearn.cluster.tests.test_k_means.test_sparse_mb_k_means_callable_init ... ok\nsklearn.cluster.tests.test_k_means.test_mini_batch_k_means_random_init_partial_fit ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_default_init_size ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_tol ... ok\nsklearn.cluster.tests.test_k_means.test_minibatch_set_init_size ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_invalid_init ... ok\nsklearn.cluster.tests.test_k_means.test_mini_match_k_means_invalid_init ... ok\nCheck if copy_x=False returns nearly equal X after de-centering. ... ok\nCheck k_means with a bad initialization does not yield a singleton ... ok\nsklearn.cluster.tests.test_k_means.test_predict ... ok\nsklearn.cluster.tests.test_k_means.test_score ... ok\nsklearn.cluster.tests.test_k_means.test_predict_minibatch_dense_input ... ok\nsklearn.cluster.tests.test_k_means.test_predict_minibatch_kmeanspp_init_sparse_input ... ok\nsklearn.cluster.tests.test_k_means.test_predict_minibatch_random_init_sparse_input ... ok\nsklearn.cluster.tests.test_k_means.test_input_dtypes ... ok\nsklearn.cluster.tests.test_k_means.test_transform ... ok\nsklearn.cluster.tests.test_k_means.test_fit_transform ... ok\nCheck that increasing the number of init increases the quality ... ok\nsklearn.cluster.tests.test_k_means.test_k_means_function ... ok\nTest MeanShift algorithm ... Segmentation fault (core dumped)\n```\n\nSome related warnings?\n\n```\n[erg@pliny ~]$ cython --version\nCython version 0.19.1\n\n[erg@pliny scikit-learn]$ [master*] make cython\nfind sklearn -name \"*.pyx\" | xargs cython\nwarning: sklearn/neighbors/binary_tree.pxi:1199:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1257:48: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1258:46: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1260:45: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1345:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1355:42: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1357:36: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1398:59: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1400:46: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1401:48: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1403:45: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1491:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1544:64: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1589:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1199:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1257:48: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1258:46: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1260:45: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1345:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1355:42: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1357:36: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1398:59: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1400:46: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1401:48: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1403:45: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1491:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1544:64: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\nwarning: sklearn/neighbors/binary_tree.pxi:1589:20: the result of using negative indices inside of code sections marked as 'wraparound=False' is undefined\n```", "patch": ""}
{"instance_id": "huggingface__transformers-16497", "file_changes": [{"file": "templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_tf_{{cookiecutter.lowercase_modelname}}.py", "changes": {"edited_modules": ["templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_tf_{{cookiecutter.lowercase_modelname}}.py:prepare_config_and_inputs"], "edited_entities": ["templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_tf_{{cookiecutter.lowercase_modelname}}.py:prepare_config_and_inputs"]}}, {"file": "tests/albert/test_modeling_tf_albert.py", "changes": {"edited_modules": ["tests/albert/test_modeling_tf_albert.py:TFAlbertModelTester"], "edited_entities": ["tests/albert/test_modeling_tf_albert.py:TFAlbertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/bert/test_modeling_tf_bert.py", "changes": {"edited_modules": ["tests/bert/test_modeling_tf_bert.py:TFBertModelTester"], "edited_entities": ["tests/bert/test_modeling_tf_bert.py:TFBertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/clip/test_modeling_tf_clip.py", "changes": {"edited_modules": ["tests/clip/test_modeling_tf_clip.py:TFCLIPTextModelTester"], "edited_entities": ["tests/clip/test_modeling_tf_clip.py:TFCLIPTextModelTester.prepare_config_and_inputs"]}}, {"file": "tests/convbert/test_modeling_tf_convbert.py", "changes": {"edited_modules": ["tests/convbert/test_modeling_tf_convbert.py:TFConvBertModelTester"], "edited_entities": ["tests/convbert/test_modeling_tf_convbert.py:TFConvBertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/ctrl/test_modeling_tf_ctrl.py", "changes": {"edited_modules": ["tests/ctrl/test_modeling_tf_ctrl.py:TFCTRLModelTester"], "edited_entities": ["tests/ctrl/test_modeling_tf_ctrl.py:TFCTRLModelTester.prepare_config_and_inputs"]}}, {"file": "tests/deberta/test_modeling_tf_deberta.py", "changes": {"edited_modules": ["tests/deberta/test_modeling_tf_deberta.py:TFDebertaModelTester"], "edited_entities": ["tests/deberta/test_modeling_tf_deberta.py:TFDebertaModelTester.prepare_config_and_inputs"]}}, {"file": "tests/deberta_v2/test_modeling_tf_deberta_v2.py", "changes": {"edited_modules": ["tests/deberta_v2/test_modeling_tf_deberta_v2.py:TFDebertaV2ModelTester"], "edited_entities": ["tests/deberta_v2/test_modeling_tf_deberta_v2.py:TFDebertaV2ModelTester.prepare_config_and_inputs"]}}, {"file": "tests/distilbert/test_modeling_tf_distilbert.py", "changes": {"edited_modules": ["tests/distilbert/test_modeling_tf_distilbert.py:TFDistilBertModelTester"], "edited_entities": ["tests/distilbert/test_modeling_tf_distilbert.py:TFDistilBertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/dpr/test_modeling_tf_dpr.py", "changes": {"edited_modules": ["tests/dpr/test_modeling_tf_dpr.py:TFDPRModelTester"], "edited_entities": ["tests/dpr/test_modeling_tf_dpr.py:TFDPRModelTester.prepare_config_and_inputs"]}}, {"file": "tests/electra/test_modeling_tf_electra.py", "changes": {"edited_modules": ["tests/electra/test_modeling_tf_electra.py:TFElectraModelTester"], "edited_entities": ["tests/electra/test_modeling_tf_electra.py:TFElectraModelTester.prepare_config_and_inputs"]}}, {"file": "tests/flaubert/test_modeling_tf_flaubert.py", "changes": {"edited_modules": ["tests/flaubert/test_modeling_tf_flaubert.py:TFFlaubertModelTester"], "edited_entities": ["tests/flaubert/test_modeling_tf_flaubert.py:TFFlaubertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/funnel/test_modeling_tf_funnel.py", "changes": {"edited_modules": ["tests/funnel/test_modeling_tf_funnel.py:TFFunnelModelTester"], "edited_entities": ["tests/funnel/test_modeling_tf_funnel.py:TFFunnelModelTester.prepare_config_and_inputs"]}}, {"file": "tests/gpt2/test_modeling_tf_gpt2.py", "changes": {"edited_modules": ["tests/gpt2/test_modeling_tf_gpt2.py:TFGPT2ModelTester"], "edited_entities": ["tests/gpt2/test_modeling_tf_gpt2.py:TFGPT2ModelTester.prepare_config_and_inputs"]}}, {"file": "tests/gptj/test_modeling_tf_gptj.py", "changes": {"edited_modules": ["tests/gptj/test_modeling_tf_gptj.py:TFGPTJModelTester"], "edited_entities": ["tests/gptj/test_modeling_tf_gptj.py:TFGPTJModelTester.prepare_config_and_inputs"]}}, {"file": "tests/layoutlm/test_modeling_tf_layoutlm.py", "changes": {"edited_modules": ["tests/layoutlm/test_modeling_tf_layoutlm.py:TFLayoutLMModelTester"], "edited_entities": ["tests/layoutlm/test_modeling_tf_layoutlm.py:TFLayoutLMModelTester.prepare_config_and_inputs"]}}, {"file": "tests/longformer/test_modeling_tf_longformer.py", "changes": {"edited_modules": ["tests/longformer/test_modeling_tf_longformer.py:TFLongformerModelTester"], "edited_entities": ["tests/longformer/test_modeling_tf_longformer.py:TFLongformerModelTester.prepare_config_and_inputs"]}}, {"file": "tests/lxmert/test_modeling_tf_lxmert.py", "changes": {"edited_modules": ["tests/lxmert/test_modeling_tf_lxmert.py:TFLxmertModelTester"], "edited_entities": ["tests/lxmert/test_modeling_tf_lxmert.py:TFLxmertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/mobilebert/test_modeling_tf_mobilebert.py", "changes": {"edited_modules": ["tests/mobilebert/test_modeling_tf_mobilebert.py:TFMobileBertModelTester"], "edited_entities": ["tests/mobilebert/test_modeling_tf_mobilebert.py:TFMobileBertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/mpnet/test_modeling_tf_mpnet.py", "changes": {"edited_modules": ["tests/mpnet/test_modeling_tf_mpnet.py:TFMPNetModelTester"], "edited_entities": ["tests/mpnet/test_modeling_tf_mpnet.py:TFMPNetModelTester.prepare_config_and_inputs"]}}, {"file": "tests/openai/test_modeling_tf_openai.py", "changes": {"edited_modules": ["tests/openai/test_modeling_tf_openai.py:TFOpenAIGPTModelTester"], "edited_entities": ["tests/openai/test_modeling_tf_openai.py:TFOpenAIGPTModelTester.prepare_config_and_inputs"]}}, {"file": "tests/rembert/test_modeling_tf_rembert.py", "changes": {"edited_modules": ["tests/rembert/test_modeling_tf_rembert.py:TFRemBertModelTester"], "edited_entities": ["tests/rembert/test_modeling_tf_rembert.py:TFRemBertModelTester.prepare_config_and_inputs"]}}, {"file": "tests/roberta/test_modeling_tf_roberta.py", "changes": {"edited_modules": ["tests/roberta/test_modeling_tf_roberta.py:TFRobertaModelTester"], "edited_entities": ["tests/roberta/test_modeling_tf_roberta.py:TFRobertaModelTester.prepare_config_and_inputs"]}}, {"file": "tests/roformer/test_modeling_tf_roformer.py", "changes": {"edited_modules": ["tests/roformer/test_modeling_tf_roformer.py:TFRoFormerModelTester"], "edited_entities": ["tests/roformer/test_modeling_tf_roformer.py:TFRoFormerModelTester.prepare_config_and_inputs"]}}, {"file": "tests/t5/test_modeling_tf_t5.py", "changes": {"edited_modules": ["tests/t5/test_modeling_tf_t5.py:TFT5ModelTester"], "edited_entities": ["tests/t5/test_modeling_tf_t5.py:TFT5ModelTester.prepare_config_and_inputs"]}}, {"file": "tests/tapas/test_modeling_tf_tapas.py", "changes": {"edited_modules": ["tests/tapas/test_modeling_tf_tapas.py:TFTapasModelTester"], "edited_entities": ["tests/tapas/test_modeling_tf_tapas.py:TFTapasModelTester.prepare_config_and_inputs"]}}, {"file": "tests/test_modeling_tf_common.py", "changes": {"edited_modules": ["tests/test_modeling_tf_common.py:random_attention_mask"], "edited_entities": ["tests/test_modeling_tf_common.py:random_attention_mask"]}}, {"file": "tests/xlm/test_modeling_tf_xlm.py", "changes": {"edited_modules": ["tests/xlm/test_modeling_tf_xlm.py:TFXLMModelTester"], "edited_entities": ["tests/xlm/test_modeling_tf_xlm.py:TFXLMModelTester.prepare_config_and_inputs"]}}, {"file": "tests/xlnet/test_modeling_tf_xlnet.py", "changes": {"edited_modules": ["tests/xlnet/test_modeling_tf_xlnet.py:TFXLNetModelTester"], "edited_entities": ["tests/xlnet/test_modeling_tf_xlnet.py:TFXLNetModelTester.prepare_config_and_inputs"]}}], "repo": "huggingface/transformers", "base_commit": "e4b234834a79541f31be227aadce13f5aafda85a", "problem_statement": "[TODO] Investigate equivalence tests\n\n**(add a lot of assignees just to make you informed and kept updated in the future. Don't hesitate to remove yourself if you think it's irrelevant)**\r\n\r\nCurrently the PT/TF/Flax equivalence tests use `1e-5` as the tolerance for the absolute differences of outputs.\r\n\r\nWe see that these tests failed with a non-negligible (although not carefully defined) frequency.\r\n\r\nCreate this page to track a list of models to investigate.\r\n\r\n- **FlaxWav2Vec2ModelTest** (2.2888184e-05 > 1e-5)\r\n  - https://app.circleci.com/pipelines/github/huggingface/transformers/37363/workflows/a4b06424-0ba8-4fbc-9054-6ff52fbf8145/jobs/411654 \r\n\r\n- **TFGPT2EncoderDecoderModelTest** (0.001009281724691391 > 1e-3)\r\n  - https://app.circleci.com/pipelines/github/huggingface/transformers/37358/workflows/43c12161-33d8-4df5-ba3c-3e62a4507ee7/jobs/411579\r\n    - This also happens to **TFBERTEncoderDecoderModelTest**\r\n    -  This is caused by some sequence in a batch which gets all 0s as attention mask (generated by ids_tensor) - may happens on both encoder and decoder (especially after combining with the causal mask).\r\n    - For **TFBERTEncoderDecoderModelTest**, the difference is smaller than *TFGPT2EncoderDecoderModelTest* (by a magnitude of 5x~10x) -> this is due to the last hidden states in GPT2 is after layer norm (not the case for BERT).\r\n    - If we look the cross attention diff between PT/TF, it is clear that we have the same issue (both in the magnitude of `1e-3`)\r\n    - The encoder attention diff between PT/TF is in the magnitude of `5e-8`: ~~**not very sure why this doesn't get much larger**~~.\r\n      - This is because PT/TF (at least in BERT) has different `encoder_extended_attention_mask`: `1e-4` vs `1e-9`.\r\n\r\n- **TFViTMAEModelTest** (1.013279e-05 > 1e-5)\r\n  - https://app.circleci.com/pipelines/github/huggingface/transformers/37319/workflows/5adfba7a-d12b-4e1e-9a7a-e33c7d5fd6ee/jobs/411002", "patch": ""}
{"instance_id": "pallets__flask-1971", "file_changes": [{"file": "CHANGES", "changes": {}}, {"file": "flask/helpers.py", "changes": {"edited_modules": ["flask/helpers.py:send_file"], "edited_entities": ["flask/helpers.py:send_file"]}}, {"file": "tests/test_helpers.py", "changes": {"edited_modules": ["tests/test_helpers.py:TestSendfile"], "edited_entities": ["tests/test_helpers.py:TestSendfile"]}}], "repo": "pallets/flask", "base_commit": "01081dbe6cdfa3fc43d8e1fff708d4ed95e1be7e", "problem_statement": "Implement RFC 7233\n\nIt would be great to support [RFC 7233 : Hypertext Transfer Protocol (HTTP/1.1): Range Requests](https://tools.ietf.org/html/rfc7233) for next major version, at least for non multipart/byteranges media type.\n\nI'm willing to implement this, so please share your thoughts about this.\n\nWhat must be done:\n- Modify `send_file` method to support Range Requests\n  - Use existing `conditionnal` parameter to enable Range Requests support ?", "patch": ""}
{"instance_id": "pallets__flask-2823", "file_changes": [{"file": "flask/cli.py", "changes": {"edited_modules": ["flask/cli.py:load_dotenv"], "edited_entities": ["flask/cli.py:load_dotenv"]}}], "repo": "pallets/flask", "base_commit": "673e5af658cf029e82d87047dcb7ebee3d343d10", "problem_statement": "Flask complains a .env file exists when not using python-dotenv, even though that .env is a directory\n\nI place my virtualenvs in a `.env` directory in my project directory. Flask 1.x sees this directory and thinks it might be a \"dotenv\" file (even though it is a directory).\r\n\r\n### Expected Behavior\r\n\r\n`flask` should ignore a `.env` directory when `python-dotenv` is not installed.\r\n\r\n### Actual Behavior\r\n\r\n`flask` says:\r\n\r\n> * Tip: There are .env files present. Do \"pip install python-dotenv\" to use them.\r\n\r\n### Environment\r\n\r\n* Python version: 3.6.5\r\n* Flask version: 1.0.2\r\n* Werkzeug version: 0.14.1", "patch": ""}
{"instance_id": "pallets__flask-4220", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "src/flask/typing.py", "changes": {}}], "repo": "pallets/flask", "base_commit": "8e589daaf2cec6a10262b8ff88801127f2fa14fd", "problem_statement": "`template_filter` decorator typing does not support custom filters with multiple arguments\n\n`template_filter` decorator typing does not support custom filters that take in multiple arguments. Consider:\r\n\r\n```py\r\nfrom flask import Flask\r\n\r\n\r\napp = Flask(__name__)\r\n\r\n\r\n@app.template_filter('foo_bar')\r\ndef foo_bar_filter(foo, bar):\r\n    return f'{foo} {bar}'\r\n```\r\n`mypy` will return the following error message:\r\n```\r\nerror: Argument 1 has incompatible type \"Callable[[Any, Any], Any]\"; expected \"Callable[[Any], str]\"  [arg-type]\r\n```\r\nAs custom filters with multiple arguments are supported by Jinja (https://jinja.palletsprojects.com/en/3.0.x/api/#custom-filters), I think this typing error is a false positive.\r\n\r\nEnvironment:\r\n\r\n- Python version: 3.6.13\r\n- Flask version: 2.0.1\r\n- Mypy version: 0.812", "patch": ""}
{"instance_id": "huggingface__transformers-2008", "file_changes": [{"file": "examples/ner/run_ner.py", "changes": {}}, {"file": "examples/ner/run_tf_ner.py", "changes": {"edited_modules": ["examples/ner/run_tf_ner.py:main"], "edited_entities": ["examples/ner/run_tf_ner.py:main"]}}, {"file": "examples/run_glue.py", "changes": {"edited_modules": ["examples/run_glue.py:train", "examples/run_glue.py:main"], "edited_entities": ["examples/run_glue.py:train", "examples/run_glue.py:main"]}}, {"file": "examples/run_language_modeling.py", "changes": {"edited_modules": ["examples/run_language_modeling.py:TextDataset", "examples/run_language_modeling.py:main"], "edited_entities": ["examples/run_language_modeling.py:TextDataset.__init__", "examples/run_language_modeling.py:main"]}}, {"file": "examples/run_squad.py", "changes": {"edited_modules": ["examples/run_squad.py:train", "examples/run_squad.py:main"], "edited_entities": ["examples/run_squad.py:train", "examples/run_squad.py:main"]}}, {"file": "src/transformers/__init__.py", "changes": {}}, {"file": "templates/adding_a_new_example_script/run_xxx.py", "changes": {"edited_modules": ["templates/adding_a_new_example_script/run_xxx.py:set_seed", "templates/adding_a_new_example_script/run_xxx.py:main"], "edited_entities": ["templates/adding_a_new_example_script/run_xxx.py:set_seed", "templates/adding_a_new_example_script/run_xxx.py:main"]}}], "repo": "huggingface/transformers", "base_commit": "a8e3336a850e856188350a93e67d77c07c85b8af", "problem_statement": "Expand run_lm_finetuning.py to all models\n\n## \ud83d\ude80 Feature\r\n\r\n[run_lm_finetuning.py](https://github.com/huggingface/transformers/blob/b0ee7c7df3d49a819c4d6cef977214bd91f5c075/examples/run_lm_finetuning.py) is a very useful tool for finetuning many models the library provided. But it doesn't cover all the models. Currently available models are:\r\n\r\n- gpt2\r\n- openai-gpt\r\n- bert\r\n- roberta\r\n- distilbert\r\n- camembert\r\n\r\nAnd not available ones:\r\n\r\n- ctrl\r\n- xlm\r\n- xlnet\r\n- transfo-xl\r\n- albert\r\n\r\n## Motivation\r\n\r\nMost important part of such a library is that it can be easily finetuned. `run_lm_finetuning.py` gives us that opportunity but why say no more :)", "patch": ""}
{"instance_id": "huggingface__transformers-5212", "file_changes": [{"file": "src/transformers/modeling_tf_utils.py", "changes": {"edited_modules": ["src/transformers/modeling_tf_utils.py:TFPreTrainedModel"], "edited_entities": ["src/transformers/modeling_tf_utils.py:TFPreTrainedModel.generate"]}}, {"file": "src/transformers/modeling_utils.py", "changes": {"edited_modules": ["src/transformers/modeling_utils.py:PreTrainedModel"], "edited_entities": ["src/transformers/modeling_utils.py:PreTrainedModel.generate"]}}], "repo": "huggingface/transformers", "base_commit": "88d7f96e33c3f3e541bcdd913f2ff1e50aa18c1b", "problem_statement": "BartConfig wrong decoder_start_token_id?\n\n# \ud83d\udc1b Bug\r\n\r\n## Information\r\n\r\nModel I am using (Bert, XLNet ...): Bart\r\n\r\nLanguage I am using the model on (English, Chinese ...): English\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nfrom transformers import BartConfig, BartTokenizer\r\nconfig = BartConfig.from_pretrained('facebook/bart-large')\r\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\r\nconfig.decoder_start_token_id\r\n>>> 2\r\ntokenizer.bos_token_id\r\n>>> 0 # != config.decoder_start_token_id\r\ntokenizer.eos_token_id\r\n>>> 2\r\n```\r\n\r\nIt is misleading in the documentation of the function ```generate````\r\n\r\n*decoder_start_token_id=None \u2013 (optional) int If an encoder-decoder model starts decoding with a different token than BOS. Defaults to None and is changed to BOS later.*\r\n\r\n\r\n## Expected behavior\r\n\r\nI expect that decoder_start_token_id = tokenizer.bos_token_id, but maybe the model is designed to start decoding with EOS token.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-16924", "file_changes": [{"file": "sklearn/metrics/_classification.py", "changes": {"edited_modules": ["sklearn/metrics/_classification.py:matthews_corrcoef"], "edited_entities": ["sklearn/metrics/_classification.py:matthews_corrcoef"]}}, {"file": "sklearn/metrics/tests/test_classification.py", "changes": {"edited_modules": ["sklearn/metrics/tests/test_classification.py:test_matthews_corrcoef", "sklearn/metrics/tests/test_classification.py:test_matthews_corrcoef_multiclass"], "edited_entities": ["sklearn/metrics/tests/test_classification.py:test_matthews_corrcoef", "sklearn/metrics/tests/test_classification.py:test_matthews_corrcoef_multiclass"]}}, {"file": "sklearn/utils/_testing.py", "changes": {"edited_modules": ["sklearn/utils/_testing.py:assert_warns_div0"], "edited_entities": ["sklearn/utils/_testing.py:assert_warns_div0"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "bf0886bae0ccbc8c5d285b6e2affe7e40474f970", "problem_statement": "Matthews correlation coefficient metric throws misleading division by zero RuntimeWarning\n\n#### Description\r\nWith tested values all equal, `sklearn.metrics.matthews_corrcoef` throws a `RuntimeWarning` reporting a division by zero. This behavior was already reported in #1937 and reported fixed, but reappears in recent versions.\r\n\r\n#### Steps/Code to Reproduce\r\nThe snippet below reproduces the warning.\r\n```python\r\nimport sklearn.metrics                         \r\ntrues = [1,0,1,1,0]                            \r\npreds = [0,0,0,0,0]                            \r\nsklearn.metrics.matthews_corrcoef(trues, preds)\r\n```\r\n\r\n#### Expected Results\r\nNo warning is thrown.\r\n\r\n#### Actual Results\r\nThe following warning is thrown:\r\n```\r\nC:\\anaconda\\envs\\sklearn-test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\r\n  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\r\n```\r\n\r\n#### Versions\r\n```\r\nSystem:\r\n    python: 3.8.2 (default, Mar 25 2020, 08:56:29) [MSC v.1916 64 bit (AMD64)]\r\nexecutable: C:\\anaconda\\envs\\sklearn-test\\python.exe\r\n   machine: Windows-10-10.0.18362-SP0\r\n\r\nPython dependencies:\r\n       pip: 20.0.2\r\nsetuptools: 46.1.3.post20200330\r\n   sklearn: 0.22.1\r\n     numpy: 1.18.1\r\n     scipy: 1.4.1\r\n    Cython: None\r\n    pandas: None\r\nmatplotlib: None\r\n    joblib: 0.14.1\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-5101", "file_changes": [{"file": "sklearn/decomposition/online_lda.py", "changes": {"edited_modules": ["sklearn/decomposition/online_lda.py:LatentDirichletAllocation"], "edited_entities": ["sklearn/decomposition/online_lda.py:LatentDirichletAllocation._approx_bound", "sklearn/decomposition/online_lda.py:LatentDirichletAllocation._init_latent_vars", "sklearn/decomposition/online_lda.py:LatentDirichletAllocation._em_step"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "4ac6a90a82e4a8d7b5338c18ae8a16559c98ba10", "problem_statement": "LatentDirichletAllocation has superfluous attributes\n\nIt has `dirichlet_component_` (undocumented) and `exp_dirichlet_component_` (exponential of same). I propose to get rid of at least the latter.", "patch": ""}
{"instance_id": "pandas-dev__pandas-76", "file_changes": [{"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame"]}}, {"file": "pandas/core/generic.py", "changes": {"edited_modules": ["pandas/core/generic.py:PandasGeneric"], "edited_entities": ["pandas/core/generic.py:PandasGeneric._reindex_axis"]}}, {"file": "pandas/core/series.py", "changes": {"edited_modules": ["pandas/core/series.py:Series"], "edited_entities": ["pandas/core/series.py:Series.cumsum"]}}, {"file": "pandas/core/sparse.py", "changes": {"edited_modules": ["pandas/core/sparse.py:SparseSeries", "pandas/core/sparse.py:SparseDataFrame"], "edited_entities": ["pandas/core/sparse.py:SparseSeries", "pandas/core/sparse.py:SparseDataFrame.count"]}}, {"file": "pandas/tests/test_frame.py", "changes": {"edited_modules": ["pandas/tests/test_frame.py:TestDataFrame"], "edited_entities": ["pandas/tests/test_frame.py:TestDataFrame", "pandas/tests/test_frame.py:TestDataFrame.test_cumsum"]}}, {"file": "pandas/tests/test_sparse.py", "changes": {"edited_modules": ["pandas/tests/test_sparse.py:TestSparseSeries", "pandas/tests/test_sparse.py:TestSparseDataFrame"], "edited_entities": ["pandas/tests/test_sparse.py:TestSparseSeries", "pandas/tests/test_sparse.py:TestSparseDataFrame.test_count"]}}], "repo": "pandas-dev/pandas", "base_commit": "05123af1b2f8db1bc4f05c22515ef378cbeefbd3", "problem_statement": "Sparse cumsum functions do not work\n\ne.g. SparseSeries.cumsum", "patch": ""}
{"instance_id": "pandas-dev__pandas-16607", "file_changes": [{"file": "doc/source/whatsnew/v0.25.0.rst", "changes": {}}, {"file": "pandas/_libs/tslibs/strptime.pyx", "changes": {}}, {"file": "pandas/core/tools/datetimes.py", "changes": {"edited_modules": ["pandas/core/tools/datetimes.py:to_datetime"], "edited_entities": ["pandas/core/tools/datetimes.py:to_datetime"]}}, {"file": "pandas/tests/indexes/datetimes/test_tools.py", "changes": {"edited_modules": ["pandas/tests/indexes/datetimes/test_tools.py:TestToDatetime"], "edited_entities": ["pandas/tests/indexes/datetimes/test_tools.py:TestToDatetime"]}}], "repo": "pandas-dev/pandas", "base_commit": "65c0441a41b2dcaeebb648274d30978419a8661a", "problem_statement": "to_datetime should support ISO week year\n\n`to_datetime` does not currently seem to support `ISO week year` like `strptime` does:\r\n\r\n```\r\nIn [38]: datetime.date(2016, 1, 1).strftime('%G-%V')\r\nOut[38]: '2015-53'\r\n\r\nIn [39]: datetime.datetime.strptime(datetime.date(2016, 1, 1).strftime('%G-%V')+'-1', '%G-%V-%u')\r\nOut[39]: datetime.datetime(2015, 12, 28, 0, 0)\r\n\r\nIn [41]: pd.to_datetime(datetime.date(2016, 1, 1).strftime('%G-%V')+'-1', format='%G-%V-%u')\r\n        ---------------------------------------------------------------------------\r\n        TypeError                                 Traceback (most recent call last)\r\n        /Users/Robin/.pyenv/versions/3.6.1/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in _convert_listlike(arg, box, format, name, tz)\r\n            443             try:\r\n        --> 444                 values, tz = tslib.datetime_to_datetime64(arg)\r\n            445                 return DatetimeIndex._simple_new(values, name=name, tz=tz)\r\n\r\n        pandas/_libs/tslib.pyx in pandas._libs.tslib.datetime_to_datetime64 (pandas/_libs/tslib.c:33275)()\r\n\r\n        TypeError: Unrecognized value type: <class 'str'>\r\n\r\n        During handling of the above exception, another exception occurred:\r\n\r\n        ValueError                                Traceback (most recent call last)\r\n        <ipython-input-41-7ce30c959690> in <module>()\r\n        ----> 1 pd.to_datetime(datetime.date(2016, 1, 1).strftime('%G-%V')+'-1', format='%G-%V-%u')\r\n\r\n        /Users/Robin/.pyenv/versions/3.6.1/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in to_datetime(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin)\r\n            516         result = _convert_listlike(arg, box, format)\r\n            517     else:\r\n        --> 518         result = _convert_listlike(np.array([arg]), box, format)[0]\r\n            519 \r\n            520     return result\r\n\r\n        /Users/Robin/.pyenv/versions/3.6.1/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in _convert_listlike(arg, box, format, name, tz)\r\n            445                 return DatetimeIndex._simple_new(values, name=name, tz=tz)\r\n            446             except (ValueError, TypeError):\r\n        --> 447                 raise e\r\n            448 \r\n            449     if arg is None:\r\n\r\n        /Users/Robin/.pyenv/versions/3.6.1/lib/python3.6/site-packages/pandas/core/tools/datetimes.py in _convert_listlike(arg, box, format, name, tz)\r\n            412                     try:\r\n            413                         result = tslib.array_strptime(arg, format, exact=exact,\r\n        --> 414                                                       errors=errors)\r\n            415                     except tslib.OutOfBoundsDatetime:\r\n            416                         if errors == 'raise':\r\n\r\n        pandas/_libs/tslib.pyx in pandas._libs.tslib.array_strptime (pandas/_libs/tslib.c:63124)()\r\n\r\n        pandas/_libs/tslib.pyx in pandas._libs.tslib.array_strptime (pandas/_libs/tslib.c:63003)()\r\n\r\n        ValueError: 'G' is a bad directive in format '%G-%V-%u'\r\n\r\n```\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\n\r\npandas: 0.20.1\r\npytest: 3.1.0\r\npip: 9.0.1\r\nsetuptools: 28.8.0\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\nxarray: None\r\nIPython: 6.0.0\r\nsphinx: None\r\npatsy: 0.4.1\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: None\r\ntables: 3.4.2\r\nnumexpr: 2.6.2\r\nfeather: None\r\nmatplotlib: 2.0.2\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 0.999999999\r\nsqlalchemy: 1.1.10\r\npymysql: None\r\npsycopg2: 2.7.1 (dt dec pq3 ext lo64)\r\njinja2: 2.9.6\r\ns3fs: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n</details>", "patch": ""}
{"instance_id": "pallets__flask-3074", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "flask/helpers.py", "changes": {"edited_modules": ["flask/helpers.py:send_file"], "edited_entities": ["flask/helpers.py:send_file"]}}, {"file": "tests/test_helpers.py", "changes": {"edited_modules": ["tests/test_helpers.py:TestSendfile"], "edited_entities": ["tests/test_helpers.py:TestSendfile"]}}], "repo": "pallets/flask", "base_commit": "6ed68f015a50ab35b84a8ea71b0f846ca6a75281", "problem_statement": "send_file doesn't urlencode ':/' in unicode attachment_filename\n\n### Expected Behavior\r\n\r\nWhen sending files with unicode filename (with `:` or `/`) they should be downloaded with name from `filename*` field.\r\n\r\n```python\r\n# -*- coding: utf-8 -*-\r\nimport os\r\nfrom flask import Flask, send_from_directory\r\napp = Flask(__name__)\r\n@app.route('/test/', methods=['GET'])\r\ndef test_route():\r\n    tmp_dir = os.getcwd()\r\n    tmp_filename = __file__\r\n    attachment_filename = u'\u0442\u0435\u0441\u0442:\u0442\u0435\u0441\u0442_\u0442\u0435\u0441\u0442.py'\r\n    return send_from_directory(\r\n        tmp_dir,\r\n        tmp_filename,\r\n        as_attachment=True,\r\n        attachment_filename=attachment_filename\r\n    )\r\nif __name__ == '__main__':\r\n    app.run(host='::', port=5000)\r\n```\r\n### Actual Behavior\r\n\r\nSome browsers (Chrome-based/Safari) ignore `filename*` field when it contains colon or slash. For example file `\u0442\u0435\u0441\u0442:\u0442\u0435\u0441\u0442_\u0442\u0435\u0441\u0442.py` gets downloaded in Chrome/Safari as `__.py` but in Firefox as `\u0442\u0435\u0441\u0442_\u0442\u0435\u0441\u0442_\u0442\u0435\u0441\u0442.py` which is acceptable in my opinion.\r\n\r\nFlask response:\r\n`Content-Disposition: attachment; filename*=\"UTF-8''%D1%82%D0%B5%D1%81%D1%82:%D1%82%D0%B5%D1%81%D1%82_%D1%82%D0%B5%D1%81%D1%82.py\"; filename=\":_.py\"`\r\n\r\n### Environment\r\n\r\n* Python version: 2.7.15\r\n* Flask version: 1.0.2\r\n* Werkzeug version: 0.14.1", "patch": ""}
{"instance_id": "pallets__flask-4099", "file_changes": [{"file": "docs/tutorial/views.rst", "changes": {}}, {"file": "examples/tutorial/flaskr/auth.py", "changes": {"edited_modules": ["examples/tutorial/flaskr/auth.py:register"], "edited_entities": ["examples/tutorial/flaskr/auth.py:register"]}}], "repo": "pallets/flask", "base_commit": "50b7dcbab343c93bb6738bbf116a177e72b1d9ec", "problem_statement": "Harmless race condition in tutorial\n\nI was browsing the flaskr tutorial when I noticed an (admittedly quite unlikely) race condition in the `register` view, specifically:\r\n\r\n```py\r\nif not username:\r\n    error = 'Username is required.'\r\nelif not password:\r\n    error = 'Password is required.'\r\nelif db.execute(\r\n    'SELECT id FROM user WHERE username = ?', (username,)\r\n).fetchone() is not None:\r\n    error = f\"User {username} is already registered.\"\r\n\r\nif error is None:\r\n    db.execute(\r\n        'INSERT INTO user (username, password) VALUES (?, ?)',\r\n        (username, generate_password_hash(password))\r\n    )\r\n    db.commit()\r\n    return redirect(url_for('auth.login'))\r\n```\r\n\r\nIf two requests arrive with the right timing, the following can happen:\r\n\r\n```\r\n   Request 1:                                Request 2:\r\nSELECT id\r\n  FROM user\r\n WHERE username = abc\r\n     |\r\n     v\r\nempty, no such user\r\n\r\n                                          SELECT id\r\n                                            FROM user\r\n                                           WHERE username = abc\r\n                                               |\r\n                                               v\r\n                                          empty, no such user\r\n\r\nINSERT INTO user (username, password)\r\n     VALUES (abc, 123)\r\n     |\r\n     v\r\n    ok\r\n\r\n                                          INSERT INTO user (username, password)\r\n                                               VALUES (abc, 456)\r\n                                               |\r\n                                               v\r\n                                          failed UNIQUE constraint -> \r\n                                          -> sqlite3.IntegrityError ->\r\n                                          -> user gets HTTP 500\r\n```\r\n\r\nWhile the likelihood of this happening is pretty small and the harm practically zero (user gets HTTP 500 and has to manually login/choose a different username), I feel like this is not really the sort of good practice the tutorial should teach. I also believe it's important the developer understands that it's the UNIQUE constraint that ensures their app works correctly and not the if condition in the application code (the tutorial mentions SQL injection attacks and explains what protects the developer against them, so I don't really feel this is out of scope).\r\n\r\nIn my own app I've modified the code to the following:\r\n```py\r\nif not username:\r\n    error = 'Username is required.'\r\nelif not password:\r\n    error = 'Password is required.'\r\nelse:\r\n    try:\r\n        db.execute(\r\n            'INSERT INTO users (username, password) VALUES (?, ?)',\r\n            (username, generate_password_hash(password))\r\n        )\r\n        db.commit()\r\n    except IntegrityError:\r\n        error = f\"User {username} is already registered.\"\r\n    else:\r\n        return redirect(url_for('auth.login'))\r\n```\r\n\r\nI suggest something similar be incorporated into the tutorial, with a short explanation (maybe a comment) of how the UNIQUE constraint does the work for the developer and maybe a note about the principle that one should \"ask forgiveness, not permission.\" I'm not sure on how it's better worded, so I'm making this an issue instead of a pull request.\r\n\r\nCheers, and thank you for your great work!", "patch": ""}
{"instance_id": "pallets__flask-1443", "file_changes": [{"file": "AUTHORS", "changes": {}}, {"file": "CHANGES", "changes": {}}, {"file": "docs/security.rst", "changes": {}}, {"file": "flask/json.py", "changes": {"edited_modules": ["flask/json.py:jsonify"], "edited_entities": ["flask/json.py:jsonify"]}}, {"file": "tests/test_helpers.py", "changes": {"edited_modules": ["tests/test_helpers.py:TestJSON"], "edited_entities": ["tests/test_helpers.py:TestJSON.test_json_as_unicode", "tests/test_helpers.py:TestJSON"]}}], "repo": "pallets/flask", "base_commit": "f17e6061fcffdc290f615d3fdc9d949e9e719574", "problem_statement": "json_encoder not invoked from flask.jsonify\n\nI created a custom JSON encoder class extended from flask.json.JSONEncoder but it is not called when calling flask.jsonify. Additionally, I removed my custom JSON encoder and confirmed that  flask.json.JSONEncoder isn't called either via a break statement in Pycharm.\n\n```\nfrom flask import Flask\nfrom flask import jsonify\nfrom flask.json import JSONEncoder\n\nclass MyEncoder(JSONEncoder):\n    def default(self, obj):\n        if hasattr(obj, '__json__'):\n            return obj.__json__()\n        else:\n            try:\n                iterable = iter(obj)\n            except TypeError:\n                pass\n            else:\n                return list(iterable)\n\n        return JSONEncoder.default(self, obj)\n\n\nclass MyClass(object):\n    key = 'a'\n    value = 'b'\n\n    def __json__(self):\n        return {'key': self.key, 'value': self.value}\n\napp = Flask(__name__)\napp.json_encoder = MyEncoder\n\n@app.route('/')\ndef hello_world():\n    return jsonify(MyClass())\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```", "patch": ""}
{"instance_id": "pallets__flask-2731", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "flask/blueprints.py", "changes": {"edited_modules": ["flask/blueprints.py:BlueprintSetupState"], "edited_entities": ["flask/blueprints.py:BlueprintSetupState.__init__"]}}, {"file": "tests/test_blueprints.py", "changes": {"edited_modules": ["tests/test_blueprints.py:test_blueprint_url_definitions"], "edited_entities": ["tests/test_blueprints.py:test_blueprint_url_definitions"]}}], "repo": "pallets/flask", "base_commit": "f808c20139649b747f604492bc33b61a7dd3e13a", "problem_statement": "Flask 1.0 backwards-incompat with double-slash/no-slash re. #2629\n\nThis is a major backwards-compat breaking change, but I suspect not the intended design and hopefully easy to fix.\r\n\r\nThe issue is related to PR #2629, and this example follows from that:\r\n\r\nGiven blueprint `bp` and app `app`:\r\n\r\n```python\r\n@bp.route('b/')\r\ndef tmp():\r\n    return \"URI should be '/a/b/\"\r\n\r\napp.register_blueprint(bp, url_prefix='/a/')\r\n```\r\n\r\nIn Flask 0.12 the URL is correctly `/a/b`, but in Flask 1.0 it's `/ab`.\r\n\r\nSince issue #2629 relates to resolve double-slashes, I imagine this is a bug (and not a design decision) - and the correct solution would be to remove a slash only when there are two.", "patch": ""}
{"instance_id": "pallets__flask-2594", "file_changes": [{"file": "CHANGES", "changes": {}}, {"file": "flask/cli.py", "changes": {"edited_modules": ["flask/cli.py:run_command"], "edited_entities": ["flask/cli.py:run_command"]}}, {"file": "tests/test_cli.py", "changes": {"edited_modules": ["tests/test_cli.py:test_dotenv_optional"], "edited_entities": ["tests/test_cli.py:test_dotenv_optional"]}}], "repo": "pallets/flask", "base_commit": "22708b048d224a5590fa28d86ca02bac52294f90", "problem_statement": "add ssl_context option to `flask run`\n\n### Expected Behaviour\r\n\r\nI expect to be able to pass the `flask run` command any of the options which are valid for the `Flask.run()` method:\r\n\r\n```sh\r\n$ FLASK_APP=myapp/run.py FLASK_DEBUG=1 flask run --host=0.0.0.0 --ssl_context=adhoc\r\n* Running on https://0.0.0.0:5000/ (Press CTRL+C to quit)\r\n```\r\n\r\nSpecifically, I want to pass `ssl_context=adhoc`, but it seems sensible to extend the command to accept all valid keyword arguments for `Flask.run()` / `werkzeug.serving.run_simple()`.\r\n\r\n### Actual Behaviour\r\n```\r\nError: no such option: --ssl_context\r\nflask run --host=0.0.0.0 --ssl_context=adhoc exited with code 2\r\n```\r\n\r\n### Environment\r\n\r\n* Python version: 3.5.2\r\n* Flask version: 0.12.2\r\n* Werkzeug version: 0.12.2", "patch": ""}
{"instance_id": "pallets__flask-266", "file_changes": [{"file": "docs/blueprints.rst", "changes": {}}], "repo": "pallets/flask", "base_commit": "e4c712ffd2682f963906e1d0d27e67b7f83d95ce", "problem_statement": "Blueprint template lookup not documented enough\n\nThe new blueprint template lookup scheme where the templates folder is just added to the searchpath instead of doing some weird stuff with the names as before. The documentation has to be clearer about that.", "patch": ""}
{"instance_id": "pallets__flask-2118", "file_changes": [{"file": "CHANGES", "changes": {}}, {"file": "flask/config.py", "changes": {"edited_modules": ["flask/config.py:Config"], "edited_entities": ["flask/config.py:Config.from_pyfile"]}}, {"file": "tests/test_config.py", "changes": {"edited_modules": ["tests/test_config.py:test_get_namespace"], "edited_entities": ["tests/test_config.py:test_get_namespace"]}}], "repo": "pallets/flask", "base_commit": "8cd0b03beeac4a41c398ea365475c651c484a9ee", "problem_statement": "config.from_pyfile crashes on Python 3 when source isn't encoded in default encoding\n\nwhen I read my instance config file, I get an error. \r\n\r\n> exec(compile(config_file.read(), filename, 'exec'), d.__dict__)\r\n> UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 437: illegal multibyte sequence\r\nThen I modify the code of config.from_pyfile to this\r\n\r\n> with open(filename, 'rb') as config_file:\r\nThe problem is resolved.", "patch": ""}
{"instance_id": "pallets__flask-2023", "file_changes": [{"file": "CHANGES", "changes": {}}, {"file": "docs/config.rst", "changes": {}}, {"file": "docs/contents.rst.inc", "changes": {}}, {"file": "docs/errorhandling.rst", "changes": {}}, {"file": "flask/app.py", "changes": {"edited_modules": ["flask/app.py:Flask"], "edited_entities": ["flask/app.py:Flask", "flask/app.py:Flask.__init__", "flask/app.py:Flask.logger"]}}, {"file": "flask/logging.py", "changes": {"edited_modules": ["flask/logging.py:_proxy_stream", "flask/logging.py:_should_log_for", "flask/logging.py:create_logger"], "edited_entities": ["flask/logging.py:_proxy_stream", "flask/logging.py:_should_log_for", "flask/logging.py:create_logger"]}}, {"file": "tests/test_basic.py", "changes": {"edited_modules": ["tests/test_basic.py:test_teardown_request_handler_error", "tests/test_basic.py:test_error_handling", "tests/test_basic.py:test_error_handling_processing", "tests/test_basic.py:test_baseexception_error_handling", "tests/test_basic.py:apprunner"], "edited_entities": ["tests/test_basic.py:test_teardown_request_handler_error", "tests/test_basic.py:test_error_handling", "tests/test_basic.py:test_error_handling_processing", "tests/test_basic.py:test_baseexception_error_handling", "tests/test_basic.py:apprunner"]}}, {"file": "tests/test_helpers.py", "changes": {"edited_modules": ["tests/test_helpers.py:TestLogging"], "edited_entities": ["tests/test_helpers.py:TestLogging"]}}, {"file": "tests/test_subclassing.py", "changes": {"edited_modules": ["tests/test_subclassing.py:test_suppressed_exception_logging", "tests/test_subclassing.py:index"], "edited_entities": ["tests/test_subclassing.py:test_suppressed_exception_logging", "tests/test_subclassing.py:index"]}}, {"file": "tests/test_templating.py", "changes": {"edited_modules": ["tests/test_templating.py:test_template_loader_debugging"], "edited_entities": ["tests/test_templating.py:test_template_loader_debugging"]}}, {"file": "tests/test_testing.py", "changes": {"edited_modules": ["tests/test_testing.py:test_test_client_context_binding"], "edited_entities": ["tests/test_testing.py:test_test_client_context_binding"]}}], "repo": "pallets/flask", "base_commit": "85fa8aabf5a7bd0adf204f0c2dacbba1fa6683de", "problem_statement": "How should logging in Flask look like?\n\nFlask started to ship with a default, hardcoded logging handler. Unfortunately this setup makes it harder to install custom logging setups, because then you'll have to undo all the things Flask did to the app logger, or replace the `app.logger` entirely. A symptom of this is #1993, where Flask's own logger had to be tweaked yet again such that messages didn't get logged twice (once via Flask's setup, once via the custom one).\n\nMy question is: **Do we even want Flask to do any logging setup?** It appears that this sort of default logging is only useful during development, so maybe it makes sense to set up a default logging handler in the new Flask CLI instead of from within the application.", "patch": ""}
{"instance_id": "pallets__flask-2866", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "docs/config.rst", "changes": {}}, {"file": "docs/errorhandling.rst", "changes": {}}, {"file": "docs/logging.rst", "changes": {}}, {"file": "src/flask/app.py", "changes": {"edited_modules": ["src/flask/app.py:Flask"], "edited_entities": ["src/flask/app.py:Flask.logger"]}}, {"file": "src/flask/logging.py", "changes": {"edited_modules": ["src/flask/logging.py:create_logger"], "edited_entities": ["src/flask/logging.py:create_logger"]}}, {"file": "tests/test_logging.py", "changes": {"edited_modules": ["tests/test_logging.py:reset_logging", "tests/test_logging.py:test_logger"], "edited_entities": ["tests/test_logging.py:reset_logging", "tests/test_logging.py:test_logger"]}}, {"file": "tests/test_templating.py", "changes": {"edited_modules": ["tests/test_templating.py:test_template_loader_debugging"], "edited_entities": ["tests/test_templating.py:test_template_loader_debugging"]}}], "repo": "pallets/flask", "base_commit": "465da9f610a04d379bb39a0ff03fb6c0b0ea1c45", "problem_statement": "DispatcherMiddleware with different loggers per app in flask 1.0\n\nAfter upgrading to flask 1.0 logging from different apps using DispatcherMiddleware, each log emitted is written to all handlers in the different apps. I assume this caused by `app.logger` always having the name `flask.app`, maybe?\r\n\r\nHere is a example:\r\n\r\n\r\n```\r\nfrom werkzeug.wsgi import DispatcherMiddleware\r\nfrom flask import Flask\r\nfrom logging.handlers import RotatingFileHandler\r\n\r\n\r\nhandler1 = RotatingFileHandler('app1.log')\r\napp1 = Flask('app1')\r\napp1.logger.addHandler(handler1)\r\n\r\nhandler2 = RotatingFileHandler('app2.log')\r\napp2 = Flask('app2')\r\napp2.logger.addHandler(handler2)\r\n\r\n\r\n@app1.route(\"/\")\r\ndef hello():\r\n    app1.logger.error(\"from app1\")\r\n    return ''\r\n\r\n\r\n@app2.route(\"/\")\r\ndef hello2():\r\n    app2.logger.error(\"from app2\")\r\n    return ''\r\n\r\n\r\napp = DispatcherMiddleware(app1, {\r\n    '/app2': app2\r\n})\r\n```\r\n\r\nRun with\r\n```\r\nuwsgi --socket 0.0.0.0:8000 --protocol=http -w app --callable app\r\n```\r\n\r\nAnd then make a request to / and /app2/. Each error log will be written in both logfiles.\r\n\r\n### Environment\r\n\r\n* Python version: 3.6.5\r\n* Flask version: 1.0.2\r\n* Werkzeug version: 0.14.1\r\n\r\nMy actual app is using `current_app.logger` with blueprints with the same behaviour, but I assume it the same issue.", "patch": ""}
{"instance_id": "pallets__flask-5160", "file_changes": [{"file": "CHANGES.rst", "changes": {}}, {"file": "src/flask/helpers.py", "changes": {"edited_modules": ["src/flask/helpers.py:get_root_path"], "edited_entities": ["src/flask/helpers.py:get_root_path"]}}, {"file": "src/flask/scaffold.py", "changes": {"edited_modules": ["src/flask/scaffold.py:_matching_loader_thinks_module_is_package", "src/flask/scaffold.py:_find_package_path"], "edited_entities": ["src/flask/scaffold.py:_matching_loader_thinks_module_is_package", "src/flask/scaffold.py:_find_package_path"]}}], "repo": "pallets/flask", "base_commit": "c8cf4694c60f0d81809468a1b45ec730496cc546", "problem_statement": "Switch to importlib breaks scripts with `app.run()`\n\nWith a trivial script [using `app.run()`](https://flask.palletsprojects.com/en/2.3.x/server/#in-code) such as:\r\n\r\n```python3\r\nfrom flask import Flask\r\n\r\napp = Flask(__name__)\r\n\r\nif __name__ == \"__main__\":\r\n    app.run(debug=True)\r\n```\r\n\r\nThe current git `main` breaks with:\r\n\r\n```pytb\r\nTraceback (most recent call last):\r\n  File \"/home/florian/tmp/flask/app.py\", line 3, in <module>\r\n    app = Flask(__name__)\r\n          ^^^^^^^^^^^^^^^\r\n  File \"/home/florian/tmp/flask/src/flask/app.py\", line 376, in __init__\r\n    instance_path = self.auto_find_instance_path()\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/florian/tmp/flask/src/flask/app.py\", line 630, in auto_find_instance_path\r\n    prefix, package_path = find_package(self.import_name)\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/florian/tmp/flask/src/flask/scaffold.py\", line 898, in find_package\r\n    package_path = _find_package_path(import_name)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/florian/tmp/flask/src/flask/scaffold.py\", line 858, in _find_package_path\r\n    spec = importlib.util.find_spec(root_mod_name)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib.util>\", line 114, in find_spec\r\nValueError: __main__.__spec__ is None\r\n```\r\n\r\nThis seems to be a regression due to 84e11a1e827c0f55f9b9ee15952eddcf8a6492e0 from #5157.\r\n\r\nEnvironment:\r\n\r\n- Python version: 3.11.4\r\n- Flask version: git main", "patch": ""}
{"instance_id": "psf__requests-3633", "file_changes": [{"file": "requests/adapters.py", "changes": {"edited_modules": ["requests/adapters.py:HTTPAdapter"], "edited_entities": ["requests/adapters.py:HTTPAdapter.__init__", "requests/adapters.py:HTTPAdapter.__setstate__", "requests/adapters.py:HTTPAdapter", "requests/adapters.py:HTTPAdapter.get_connection"]}}, {"file": "tests/test_requests.py", "changes": {"edited_modules": ["tests/test_requests.py:TestPreparingURLs"], "edited_entities": ["tests/test_requests.py:TestPreparingURLs.test_parameters_for_nonstandard_schemes"]}}], "repo": "psf/requests", "base_commit": "5a41febce249e7b74eb37ba7914998ff08321c38", "problem_statement": "HTTPS requests through proxies in proposed/3.0.0 aren't configured correctly\n\nIn current master:\n\n```\n>>> import requests\n>>> requests.__version__\n'2.11.1'\n>>> session = requests.Session()\n>>> r = session.get('https://www.jcline.org/', verify=True, proxies={'http': 'http://vagrant:vagrant@localhost:3128', 'https': 'http://vagrant:vagrant@localhost:3128'})\n>>> \n```\n\nIn current proposed/3.0.0:\n\n```\n>>> import requests\n>>> requests.__version__\n'3.0.0'\n>>> session = requests.Session()\n>>> r = session.get('https://www.jcline.org/', verify=True, proxies={'http': 'http://vagrant:vagrant@localhost:3128', 'https': 'http://vagrant:vagrant@localhost:3128'})\nrequests/packages/urllib3/connectionpool.py:838: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/security.html\n  InsecureRequestWarning)\n>>> \n```\n\nThis is a problem I introduced in https://github.com/kennethreitz/requests/pull/3109 :disappointed:. What happens right now is if a request is _not_ through a proxy and it's HTTPS, the urllib3 pool manager's `connection_pool_kw` are updated before requesting a new connection using [requests.adapters.HTTPAdapter._update_poolmanager_ssl_kw](https://github.com/kennethreitz/requests/blob/proposed/3.0.0/requests/adapters.py#L204). If it _is_ through a proxy, the keywords aren't updated and the request is made with the default settings for urllib3.\n\nTo me, the most appealing way to fix this is to add a keyword argument, `connection_kwargs` or something, to all the `urllib3.poolmanager.PoolManager.connection_from_*` methods that is either merged into `connection_pool_kw` or overrides them. That way `urllib3` can handle getting the connection pool with the new kwargs in a thread-safe manner. Currently, `requests` has to manage updating the keys and getting the new connection pool with a lock. It seems like that would be better in `urllib3`.\n\nThe other option is to patch up what's currently in `HTTPAdapter` so it handles updating the proxy manager or plain pool manager based on whether proxies are in use.\n\nWhat do people think?", "patch": ""}
{"instance_id": "psf__requests-2872", "file_changes": [{"file": "requests/utils.py", "changes": {"edited_modules": ["requests/utils.py:super_len"], "edited_entities": ["requests/utils.py:super_len"]}}, {"file": "test_requests.py", "changes": {"edited_modules": ["test_requests.py:UtilsTestCase"], "edited_entities": ["test_requests.py:UtilsTestCase"]}}], "repo": "psf/requests", "base_commit": "4e89ba707714e3b58a46c2ed9e220cff8b7f1e6a", "problem_statement": "Post request hangs in certain cases when body is a StringIO\n\nThis is related to a report for the [Dropbox Python SDK](https://github.com/dropbox/dropbox-sdk-python/issues/27).\n\nThe following hangs:\n\n```\nfrom StringIO import StringIO\ns = StringIO()\ns.write('hello')  # This is seeked to the end\nrequests.post('http://www.google.com', data=s)  # Hangs: A success would be a 405 error\n```\n\nAfter a cursory look, it looks like the request isn't fully formed so the server doesn't attempt to send a response which leaves the client hanging.\n\nIf we call `s.seek(0)`, this works. A bit more counterintuitively, this also works:\n\n```\nrequests.post('http://www.google.com', data=StringIO())\n```", "patch": ""}
{"instance_id": "psf__requests-2756", "file_changes": [{"file": "requests/models.py", "changes": {"edited_modules": ["requests/models.py:PreparedRequest"], "edited_entities": ["requests/models.py:PreparedRequest.prepare_body"]}}, {"file": "test_requests.py", "changes": {"edited_modules": ["test_requests.py:RequestsTestCase"], "edited_entities": ["test_requests.py:RequestsTestCase"]}}], "repo": "psf/requests", "base_commit": "56ecdebcc507c71f2386d3bf2ea14db2d27cc834", "problem_statement": "Json supersedes data in prepare_body\n\nWhen not a stream, json supersedes data in prepare_body:\nhttps://github.com/kennethreitz/requests/blob/f5dacf84468ab7e0631cc61a3f1431a32e3e143c/requests/models.py#L446\n\nThis conflicts with the docstring, which indicates that json is only used when data is not specified:\nhttps://github.com/kennethreitz/requests/blob/f5dacf84468ab7e0631cc61a3f1431a32e3e143c/requests/models.py#L195", "patch": ""}
{"instance_id": "psf__requests-1882", "file_changes": [{"file": "requests/api.py", "changes": {"edited_modules": ["requests/api.py:request"], "edited_entities": ["requests/api.py:request"]}}], "repo": "psf/requests", "base_commit": "1c52d15d9772e459add567cbdc9d38a284a8d939", "problem_statement": "ResourceWarning in python 3.2+\n\nRequests issues a ResourceWarning in python 3.2+ as sockets are not explicitly closed before garbage collection occurs. While ResourceWarnings are not displayed by default, it can be a distraction to some developers when working with warnings enabled.\n\nFile: test.py\n\n``` python\nimport requests\n\ndef make_request():\n    resp = requests.get('http://google.com')\n    resp.close()  # this appears to have no effect, even though the function exists\n\nmake_request()\n```\n\n```\n$ python -Wall test.py \ntest.py:7: ResourceWarning: unclosed <socket.socket object, fd=4, family=2, type=1, proto=6>\n  make_request()\ntest.py:7: ResourceWarning: unclosed <socket.socket object, fd=3, family=2, type=1, proto=6>\n  make_request()\n```\n\nIt would be great if there was a way to prevent the ResourceWarning from occurring, without issuing a `Connection:close` header.", "patch": ""}
{"instance_id": "psf__requests-1208", "file_changes": [{"file": "AUTHORS.rst", "changes": {}}, {"file": "requests/adapters.py", "changes": {"edited_modules": ["requests/adapters.py:HTTPAdapter"], "edited_entities": ["requests/adapters.py:HTTPAdapter.__init__", "requests/adapters.py:HTTPAdapter", "requests/adapters.py:HTTPAdapter.send"]}}, {"file": "requests/api.py", "changes": {"edited_modules": ["requests/api.py:request"], "edited_entities": ["requests/api.py:request"]}}, {"file": "requests/sessions.py", "changes": {"edited_modules": ["requests/sessions.py:SessionRedirectMixin", "requests/sessions.py:Session"], "edited_entities": ["requests/sessions.py:SessionRedirectMixin.resolve_redirects", "requests/sessions.py:Session.request", "requests/sessions.py:Session.send"]}}, {"file": "test_requests.py", "changes": {}}], "repo": "psf/requests", "base_commit": "be62645dd56580dd7576032b348cf79d880851d8", "problem_statement": "Not possible to specify max_retries in v1.X?\n\nIn older versions of requests (pre v1.0), I was able to do:\n\n```\nrequests.get('http://nonexistentdomainfoobar.com', config={\"max_retries\":10})\n```\n\nas far as I can tell, this isn't possible in v.1.0+. `HTTPAdapter.max_retries` uses `DEFAULT_RETRIES` and there's no way to change this.\n\nWould it be possible to restore this feature? If not, perhaps a note in the FAQ informing users that this isn't possible and they'll have to write a loop themselves?", "patch": ""}
{"instance_id": "psf__requests-1228", "file_changes": [{"file": "requests/sessions.py", "changes": {"edited_modules": ["requests/sessions.py:SessionRedirectMixin"], "edited_entities": ["requests/sessions.py:SessionRedirectMixin.resolve_redirects"]}}, {"file": "test_requests.py", "changes": {"edited_modules": ["test_requests.py:RequestsTestCase"], "edited_entities": ["test_requests.py:RequestsTestCase"]}}], "repo": "psf/requests", "base_commit": "1642996798416efaca754e4678506502e4c4c1f3", "problem_statement": "Problem with missing cookies after redirect\n\nI sent this by e-mail - no response. I think this might be of interest to others:\n\n> I have a problem when connecting to a site. Here's the scenario:\n> \n> 1) I enter a login page, which has a form\n> 2) I send (using Requests) a POST with the username, pw, etc.\n>    (This POST includes the SESSIONID)\n> 3) The webpage with a 302,\n> 4) To which requests does automatically a GET to the new address\n> 5) In Firefox, this works, In Requests, I get redirected to the\n>    login - page (with another 302).\n> \n> The only important difference I can detect is that in point 4),\n> Firefox repeats automatically the SESSION ID, which Requests does\n> not do. Can I enable this?\n\nI solved the problem by disabling automatic redirects, and creating\na new request manually, with the sessionid cookie. Now the process\nruns successfully. \n\nThis confirms the necessity of the repeating the cookie in the \nrequest after the 302, but it defeat the 'neatness' of the auto\nredirects.\n\nCheers,\nJohn", "patch": ""}
{"instance_id": "psf__requests-1979", "file_changes": [{"file": "requests/auth.py", "changes": {"edited_modules": ["requests/auth.py:HTTPDigestAuth"], "edited_entities": ["requests/auth.py:HTTPDigestAuth", "requests/auth.py:HTTPDigestAuth.__call__", "requests/auth.py:HTTPDigestAuth.handle_401"]}}], "repo": "psf/requests", "base_commit": "4683f169909857d663275346655975af7190fd62", "problem_statement": "Authentication Handlers lost on redirect.\n\nI'am trying to use the requests library by making a redirection with  Digest authentication method, but the response is 401. I mention that it works with basic authentication. I've captured the packets with wireshark, and noticed that the first HTTP request is without the Authorization header, the 401 unauthorized answered is received, and after that the traffic continues as it should be, the Authorization header is added, the 302 answer is received, and after that with the https cyphers exchange. I don't know why the requests.send method returns 401.", "patch": ""}
{"instance_id": "psf__requests-4239", "file_changes": [{"file": "HISTORY.rst", "changes": {}}, {"file": "requests/utils.py", "changes": {"edited_modules": ["requests/utils.py:check_header_validity"], "edited_entities": ["requests/utils.py:check_header_validity"]}}, {"file": "tests/test_requests.py", "changes": {"edited_modules": ["tests/test_requests.py:TestRequests"], "edited_entities": ["tests/test_requests.py:TestRequests.test_header_value_not_str"]}}], "repo": "psf/requests", "base_commit": "1c2022cf868cb503815f34901ad8e85cf524d01a", "problem_statement": "Add header name to InvalidHeader exception message\n\nrequests.get('http://example.com', headers={'foo': 1})\r\nrequests.exceptions.InvalidHeader: Header value 1 must be of type str or bytes, not <class 'int'>\r\n\r\nIt would be good to add the name of the bad header to make it easier\r\nto track this down in large bodies of code. Something like:\r\n\r\nrequests.exceptions.InvalidHeader: Header foo value 1 must be of type str or bytes, not <class 'int'>\r\n\r\nThanks.\r\n\r\nSummary.\r\n\r\n## Expected Result\r\n\r\nWhat you expected.\r\n\r\n## Actual Result\r\n\r\nWhat happened instead.\r\n\r\n## Reproduction Steps\r\n\r\n```python\r\nimport requests\r\n\r\n```\r\n\r\n## System Information\r\n\r\n    $ python -m requests.help\r\n\r\n```\r\n<paste here>\r\n```\r\n\r\nThis command is only available on Requests v2.16.4 and greater. Otherwise,\r\nplease provide some basic information about your system (Python version,\r\noperating system, &c).e", "patch": ""}
{"instance_id": "psf__requests-2876", "file_changes": [{"file": "requests/sessions.py", "changes": {"edited_modules": ["requests/sessions.py:Session"], "edited_entities": ["requests/sessions.py:Session.prepare_request"]}}], "repo": "psf/requests", "base_commit": "0192aac24123735b3eaf9b08df46429bb770c283", "problem_statement": "Exception messages\n\nAs a user I would like it to be easy to generate simple helpful messages upon an exception. A common way this is done in is to simply cast the exception to a string. However, with requests, the result is often something you don't want to show an end user. For example:\n\n``` python\n    try:\n        downloaded = requests.get(url)\n    except (requests.Timeout) as err:\n        print(str(err))\n```\n\nResults in the following message to the user:\n\n```\n    HTTPSConnectionPool(host='cal.example.com', port=443): Max retries exceeded with url: /ken/ken.ics/00832974-ffb3-42ea-ba3e-84ba3c0a30f6.ics (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7fd4644ef400>, 'Connection to cal.example.com timed out. (connect timeout=0.1)'))\n```\n\nThere is useful information in this message, but it is not easily user accessible and is rather intimidating for end users. The information is probably available in the exception itself, but it is not clear how to get it. Also, it seems like accessing it would likely be different for each type of exception, which greatly increases the complexity of catching and reporting exceptions.\n\nWhat I would expect is something like::\n\n```\n    Connection to cal.example.com timed out.\n```\n\nIt would be very helpful if there were an easy way to generate user friendly error messages from requests exceptions. If there is such a way, I have not been able to find it. Thus, I suggest it be added to the otherwise excellent introduction to requests. If there is not such a way, I would like to to suggest that it be added.", "patch": ""}
{"instance_id": "psf__requests-2411", "file_changes": [{"file": "requests/compat.py", "changes": {}}, {"file": "requests/utils.py", "changes": {"edited_modules": ["requests/utils.py:guess_filename"], "edited_entities": ["requests/utils.py:guess_filename"]}}, {"file": "test_requests.py", "changes": {"edited_modules": ["test_requests.py:UtilsTestCase"], "edited_entities": ["test_requests.py:UtilsTestCase"]}}], "repo": "psf/requests", "base_commit": "e23bf10cf4ecc62f6c3dd6284043516fb833d9ce", "problem_statement": "Requests 2.5.1 doesn't recognize unicode filenames for uploads\n\nAfter merge of https://github.com/kennethreitz/requests/pull/2379, to allow filenames to be `int` types, unicode filenames are no longer recognized under Python 2. \n\nThis checks that the filename is a `builtin` `str`, which has different behaviour on Python 2 and Python 3:\n`requests/utils.py:118:    if name and isinstance(name, builtin_str) and name[0] != '<' and name[-1] != '>':`\n\nIn `requests/compat.py`, `builtin_str` is defines as `str`, which is non-unicode `bytes` in Python 2 and unicode in Python 3. Perhaps the check should be against basestring, or is this change in behaviour intended?", "patch": ""}
{"instance_id": "psf__requests-1397", "file_changes": [{"file": "requests/compat.py", "changes": {}}, {"file": "requests/exceptions.py", "changes": {"edited_modules": ["requests/exceptions.py:InvalidURL"], "edited_entities": ["requests/exceptions.py:InvalidURL"]}}, {"file": "requests/models.py", "changes": {"edited_modules": ["requests/models.py:Response"], "edited_entities": ["requests/models.py:Response.generate"]}}], "repo": "psf/requests", "base_commit": "9473f15909fb3f2329247812e0d3c661421ceafc", "problem_statement": "bug report\n\nDear Kenneth Reitz,\n\nI use your Requests library which is quite cool. I ran into some issues like httplib uncaught exceptions\nwhich (i think) should be handled by Requests.\n## Consider the following code:\n\nimport requests\n## r = requests.get('http://www.bilhetos.com')\n\nIt raises 'httplib.IncompleteRead' exception which is not handled properly in Requests.\n\nPlease consider urls below for testing:\nhttp://www.tusseymountaintitans.com\nhttp://www.abbottpanthers.com\nhttp://www.spanishmoms.com\nhttp://www.long-island-storage.com\nhttp://www.cupertinohelpwanted.com\nhttp://www.hoffmanestateshawks.com\nhttp://www.brothermartincrusaders.com\nhttp://www.1-800-printer.com\nhttp://www.impiretickets.com\nhttp://www.gdickinson.com\nhttp://www.forensicsline.com\nhttp://www.gardeningtime.com\nhttp://www.ecollegetennis.com\nhttp://www.milacasaints.com\nhttp://www.bartoninsuranceagency.com\nhttp://www.djnatural.com\nhttp://www.containers2000.com\nhttp://www.indiancreektimberwolves.com\nhttp://www.athenswarriors.com\nhttp://www.logansportcats.com\nhttp://www.osani.com\nhttp://www.xn--sammler-brse-djb.com\nhttp://www.800usahealth.com\nhttp://www.wealth-wise.com\nhttp://www.foothillmustangs.com\nhttp://www.manasquanbigblue.com\nhttp://www.bilhetos.com\nhttp://www.atlantahomesteam.com\nhttp://www.foxcitiessatellite.com\nhttp://www.chargersmail.com\nhttp://www.fighterplace.com\n\nBest regards,\nVladimir Goncharov", "patch": ""}
{"instance_id": "huggingface__transformers-21330", "file_changes": [{"file": "README.md", "changes": {}}, {"file": "README_es.md", "changes": {}}, {"file": "README_hd.md", "changes": {}}, {"file": "README_ja.md", "changes": {}}, {"file": "README_ko.md", "changes": {}}, {"file": "README_zh-hans.md", "changes": {}}, {"file": "README_zh-hant.md", "changes": {}}, {"file": "docs/source/de/index.mdx", "changes": {}}, {"file": "docs/source/en/_toctree.yml", "changes": {}}, {"file": "docs/source/en/index.mdx", "changes": {}}, {"file": "src/transformers/models/auto/configuration_auto.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "b9af152efb748b1bff8f6fe0130e62ebb8e11a53", "problem_statement": "Add XLM-V\n\n### Model description\n\n[XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models](https://arxiv.org/abs/2301.10472)\r\n\r\nLarge multilingual language models typically rely on a single vocabulary shared across 100+ languages. As these models have increased in parameter count and depth, vocabulary size has remained largely unchanged. This vocabulary bottleneck limits the representational capabilities of multilingual models like XLM-R. In this paper, we introduce a new approach for scaling to very large multilingual vocabularies by de-emphasizing token sharing between languages with little lexical overlap and assigning vocabulary capacity to achieve sufficient coverage for each individual language. Tokenizations using our vocabulary are typically more semantically meaningful and shorter compared to XLM-R. Leveraging this improved vocabulary, we train XLM-V, a multilingual language model with a one million token vocabulary. XLM-V outperforms XLM-R on every task we tested on ranging from natural language inference (XNLI), question answering (MLQA, XQuAD, TyDiQA), and named entity recognition (WikiAnn) to low-resource tasks (Americas NLI, MasakhaNER).\r\n\r\nShould work as [XLM-RoBERTa](https://twitter.com/LiangDavis/status/1618738467315531777?s=20&t=nObyGbBEqmBZr9rmTEAeVg)\n\n### Open source status\n\n- [X] The model implementation is available\n- [X] The model weights are available\n\n### Provide useful links for the implementation\n\n_No response_", "patch": ""}
{"instance_id": "huggingface__transformers-28007", "file_changes": [{"file": "src/transformers/models/whisper/modeling_whisper.py", "changes": {"edited_modules": ["src/transformers/models/whisper/modeling_whisper.py:WhisperForConditionalGeneration"], "edited_entities": ["src/transformers/models/whisper/modeling_whisper.py:WhisperForConditionalGeneration.generate", "src/transformers/models/whisper/modeling_whisper.py:WhisperForConditionalGeneration._extract_token_timestamps"]}}, {"file": "src/transformers/pipelines/automatic_speech_recognition.py", "changes": {"edited_modules": ["src/transformers/pipelines/automatic_speech_recognition.py:AutomaticSpeechRecognitionPipeline"], "edited_entities": ["src/transformers/pipelines/automatic_speech_recognition.py:AutomaticSpeechRecognitionPipeline._forward"]}}, {"file": "tests/models/whisper/test_modeling_whisper.py", "changes": {"edited_modules": ["tests/models/whisper/test_modeling_whisper.py:WhisperModelIntegrationTests"], "edited_entities": ["tests/models/whisper/test_modeling_whisper.py:WhisperModelIntegrationTests"]}}, {"file": "tests/pipelines/test_pipelines_automatic_speech_recognition.py", "changes": {"edited_modules": ["tests/pipelines/test_pipelines_automatic_speech_recognition.py:AutomaticSpeechRecognitionPipelineTests"], "edited_entities": ["tests/pipelines/test_pipelines_automatic_speech_recognition.py:AutomaticSpeechRecognitionPipelineTests"]}}], "repo": "huggingface/transformers", "base_commit": "b8378b658e9846e647d15a8fd85ad1421326b1e5", "problem_statement": "Can't do word timestamps and beam search at the same time (whisper)\n\n### System Info\n\nTested on python 3.8.10, transformers 4.36.0.dev0\r\n\r\n\n\n### Who can help?\n\n@ArthurZucker @sanchit-gandhi (suggested by peregilk)\n\n### Information\n\n- [ ] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\n```\r\nfrom transformers import pipeline\r\nimport torch\r\nmodel = \"NbAiLabBeta/nb-whisper-base\"\r\ndevice = \"cuda:0\"\r\n\r\np = pipeline(\"automatic-speech-recognition\",\r\n             model,\r\n             torch_dtype=torch.float16,\r\n             device=device,\r\n             return_timestamps=\"word\")\r\nargs = {\"language\": \"norwegian\", \"task\": \"transcribe\", \"num_beams\": 3}\r\noutputs = p(audiofile,\r\n            chunk_length_s=28,\r\n            batch_size=6,\r\n            generate_kwargs=args)\r\n```\r\n\r\nFails with:\r\n\r\n> Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/pipelines/automatic_speech_recognition.py\", line 357, in __call__\r\n    return super().__call__(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py\", line 1132, in __call__\r\n    return next(\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\r\n    item = next(self.iterator)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/pipelines/pt_utils.py\", line 266, in __next__\r\n    processed = self.infer(next(self.iterator), **self.params)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py\", line 1046, in forward\r\n    model_outputs = self._forward(model_inputs, **forward_params)\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/pipelines/automatic_speech_recognition.py\", line 552, in _forward\r\n    generate_kwargs[\"num_frames\"] = stride[0] // self.feature_extractor.hop_length\r\nTypeError: unsupported operand type(s) for //: 'tuple' and 'int'\r\n\r\nIt works with *either* num_beams:1 OR return_timestamps=True/False, but not combined.\n\n### Expected behavior\n\nIt should return processed data. :)", "patch": ""}
{"instance_id": "huggingface__transformers-4657", "file_changes": [{"file": "src/transformers/training_args.py", "changes": {"edited_modules": ["src/transformers/training_args.py:TrainingArguments"], "edited_entities": ["src/transformers/training_args.py:TrainingArguments._setup_devices"]}}], "repo": "huggingface/transformers", "base_commit": "b231a413f5d58592bb4d98304c3d3b668c5d4a42", "problem_statement": "--fp causes an issue when running example scripts in distributed mode\n\n# \ud83d\udc1b Bug\r\n\r\n## Information\r\n\r\nModel I am using (Bert, XLNet ...):\r\n`roberta-large`\r\nLanguage I am using the model on (English, Chinese ...):\r\n`English`\r\n\r\nThe problem arises when using:\r\n* the official example scripts\r\n\r\nThe tasks I am working on is:\r\n* Finetuning a LM with `run_language_modeling.py` and the SST-2 task with `run_glue.py`\r\n* my own dataset\r\n\r\n## To reproduce\r\nIf I run either of the following commands, I get the error included below. However, if I remove `--fp`, everything works normally. Also, if I add `--fp`, but run it non-distributed, everything works normally. So, it appears there is an issue with my running `-fp`  in a distributed fashion. I haven't had an issue with this before; so, I'm not sure what the problem is. Any ideas? Thanks in advance.\r\n\r\nI installed apex in two different way, but still get the same results.\r\n```\r\n#Install package required for fp16 computations\r\nRUN git clone https://github.com/NVIDIA/apex.git \\\r\n    && cd apex \\\r\n    && python3 setup.py install --cuda_ext --cpp_ext\r\n```\r\n```\r\nInstall package required for fp16 computations\r\nRUN git clone https://github.com/NVIDIA/apex.git \\\r\n    && cd apex \\\r\n    && pip3 install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\r\n```\r\n```\r\npython3 -m torch.distributed.launch --nproc_per_node 2 run_language_modeling.py --output_dir=/ptcc/shared/lm_roberta_20200528_164228 --model_type=roberta --do_train --train_data_file=/ptcc/data/train.txt --do_eval --eval_data_file=/ptcc/data/test.txt --evaluate_during_training --per_gpu_train_batch_size=2 --per_gpu_eval_batch_size=2 --learning_rate=5e-06 --model_name_or_path=roberta-large --mlm --max_steps=120000 --warmup_steps=10000 --save_steps=12000 --seed=42 --fp16 --logging_dir=/ptcc/shared/roberta_20200528_164228_tf_logs'\r\n```\r\n```\r\npython3 -m torch.distributed.launch --nproc_per_node 2 run_glue.py --model_type roberta --task_name SST-2 --do_train --do_eval --evaluate_during_training --data_dir /ptcc/data/ --per_gpu_train_batch_size 2 --per_gpu_eval_batch_size 2 --learning_rate 1e-06 --output_dir clf_roberta_20200528_162937 --model_name_or_path /ptcc/shared/lm_roberta_20200528_113420 --num_train_epochs 2.0 --save_steps 1000 --seed 42 --fp16 --logging_dir=/ptcc/shared/roberta_20200528_162937_tf_logs\r\n```\r\n\r\n```\r\nptcc_1  | 05/28/2020 20:30:38 - INFO - transformers.trainer -     Starting fine-tuning.\r\nEpoch:   0%|          | 0/2 [00:00<?, ?it/s]       Traceback (most recent call last):\r\nptcc_1  |   File \"/ptcc/run_glue.py\", line 228, in <module>\r\nptcc_1  |     main()\r\nptcc_1  |   File \"/ptcc/run_glue.py\", line 160, in main\r\nptcc_1  |     model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\r\nptcc_1  |   File \"/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\", line 470, in train\r\nptcc_1  |     tr_loss += self._training_step(model, inputs, optimizer)\r\nptcc_1  |   File \"/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\", line 577, in _training_step\r\nptcc_1  |     scaled_loss.backward()\r\nptcc_1  |   File \"/usr/lib/python3.6/contextlib.py\", line 88, in __exit__\r\nptcc_1  |     next(self.gen)\r\nptcc_1  |   File \"/usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg/apex/amp/handle.py\", line 127, in scale_loss\r\nptcc_1  |     should_skip = False if delay_overflow_check else loss_scaler.update_scale()\r\nptcc_1  |   File \"/usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg/apex/amp/scaler.py\", line 200, in update_scale\r\nptcc_1  |     self._has_overflow = self._overflow_buf.item()\r\nptcc_1  | RuntimeError: CUDA error: an illegal memory access was encountered\r\nptcc_1  | /usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\r\nptcc_1  |   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\r\nptcc_1  |                                                  terminate called after throwing an instance of 'c10::Error'\r\nptcc_1  |   what():  CUDA error: an illegal memory access was encountered (insert_events at /pytorch/c10/cuda/CUDACachingAllocator.cpp:771)\r\nptcc_1  | frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f69777f6536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\r\nptcc_1  | frame #1: c10::cuda::CUDACachingAllocator::raw_delete(void*) + 0x7ae (0x7f6977a39fbe in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\r\nptcc_1  | frame #2: c10::TensorImpl::release_resources() + 0x4d (0x7f69777e6abd in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\r\nptcc_1  | frame #3: std::vector<c10d::Reducer::Bucket, std::allocator<c10d::Reducer::Bucket> >::~vector() + 0x1d9 (0x7f69c3926ef9 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #4: c10d::Reducer::~Reducer() + 0x23a (0x7f69c391c84a in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #5: std::_Sp_counted_ptr<c10d::Reducer*, (__gnu_cxx::_Lock_policy)2>::_M_dispose() + 0x12 (0x7f69c38fb7c2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #6: std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() + 0x46 (0x7f69c32be466 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #7: <unknown function> + 0x87146b (0x7f69c38fc46b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #8: <unknown function> + 0x240500 (0x7f69c32cb500 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #9: <unknown function> + 0x24174e (0x7f69c32cc74e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\r\nptcc_1  | frame #10: /usr/bin/python3() [0x572a27]\r\nptcc_1  | frame #11: /usr/bin/python3() [0x54eef2]\r\nptcc_1  | frame #12: /usr/bin/python3() [0x588948]\r\nptcc_1  | frame #13: /usr/bin/python3() [0x5ad438]\r\nptcc_1  | frame #14: /usr/bin/python3() [0x5ad44e]\r\nptcc_1  | frame #15: /usr/bin/python3() [0x5ad44e]\r\nptcc_1  | frame #16: /usr/bin/python3() [0x56b276]\r\nptcc_1  | frame #17: PyDict_SetItemString + 0x153 (0x5709f3 in /usr/bin/python3)\r\nptcc_1  | frame #18: PyImport_Cleanup + 0x76 (0x4f2fc6 in /usr/bin/python3)\r\nptcc_1  | frame #19: Py_FinalizeEx + 0x5e (0x637e2e in /usr/bin/python3)\r\nptcc_1  | frame #20: Py_Main + 0x395 (0x638e95 in /usr/bin/python3)\r\nptcc_1  | frame #21: main + 0xe0 (0x4b0d00 in /usr/bin/python3)\r\nptcc_1  | frame #22: __libc_start_main + 0xe7 (0x7f69e4727b97 in /lib/x86_64-linux-gnu/libc.so.6)\r\nptcc_1  | frame #23: _start + 0x2a (0x5b250a in /usr/bin/python3)\r\n```\r\n\r\n## Environment info\r\n- `transformers` version: 2.10.0\r\n- Platform: Linux-5.3.0-26-generic-x86_64-with-Ubuntu-18.04-bionic\r\n- Python version: 3.6.9\r\n- PyTorch version (GPU?): 1.5.0 (True)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Using GPU in script?: Y,  2 Tesla V100-SXM2\r\n- Using distributed or parallel set-up in script?: Y,  2 Tesla V100-SXM2", "patch": ""}
{"instance_id": "huggingface__transformers-31778", "file_changes": [{"file": "src/transformers/models/whisper/tokenization_whisper.py", "changes": {"edited_modules": ["src/transformers/models/whisper/tokenization_whisper.py:_find_longest_common_sequence"], "edited_entities": ["src/transformers/models/whisper/tokenization_whisper.py:_find_longest_common_sequence"]}}, {"file": "tests/models/whisper/test_tokenization_whisper.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "85a1269e19af022e04bc2aad82572cd5a9e8cdd9", "problem_statement": "Bug in whisper word-level timestamps (`tokenizer._decode_asr`)\n\n### System Info\n\n- `transformers` version: 4.42.3\r\n- Platform: Linux-6.1.85+-x86_64-with-glibc2.35\r\n- Python version: 3.10.12\r\n- Huggingface_hub version: 0.23.4\r\n- Safetensors version: 0.4.3\r\n- Accelerate version: not installed\r\n- Accelerate config: not found\r\n- PyTorch version (GPU?): 2.3.0+cu121 (False)\r\n- Tensorflow version (GPU?): 2.15.0 (False)\r\n- Flax version (CPU?/GPU?/TPU?): 0.8.4 (cpu)\r\n- Jax version: 0.4.26\r\n- JaxLib version: 0.4.26\r\n- Using distributed or parallel set-up in script?: no\n\n### Who can help?\n\n@sanchit-gandhi\n\n### Information\n\n- [ ] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\nMinimal reproduction:\r\n\r\n```py\r\nimport torch\r\n\r\nmodel_outputs = [\r\n    {\r\n        'stride': [30, 0, 5],\r\n        'tokens': torch.tensor([[\r\n            50257, 50362, 8410, 7283, 0, 2329,\r\n            8410, 7283, 0, 2094, 470, 1309,\r\n            534, 10625, 307, 10625, 13, 34668,\r\n            11, 345, 531, 9439, 11, 523,\r\n            655, 8410, 7283, 0, 39134, 16592,\r\n            10560, 3955, 50, 0, 7102, 5446,\r\n            46, 0, 25848, 8410, 7283, 0,\r\n            2773, 661, 4320, 1943, 981, 345,\r\n            821, 8066, 7765, 510, 290, 670,\r\n            1327, 379, 340, 13, 10528, 318,\r\n            5340, 13, 50256\r\n        ]]),\r\n        'token_timestamps': torch.tensor([[\r\n            0, 0, 0, 3.78, 4.22, 5.26, 6.04,\r\n            6.54, 7, 7.94, 8.58, 8.58, 8.88, 9.16,\r\n            9.54, 9.94, 10.6, 11.38, 11.88, 12.38, 12.44,\r\n            12.62, 13, 13.36, 13.64, 14.24, 14.74, 15.12,\r\n            15.4, 15.74, 16.1, 16.54, 16.54, 16.78, 17.08,\r\n            17.2, 17.36, 17.56, 18.08, 18.58, 19.38, 19.88,\r\n            22.54, 22.9, 23.24, 23.5, 24.14, 24.56, 24.7,\r\n            24.94, 24.94, 25.18, 25.54, 25.72, 26.04, 26.34,\r\n            26.46, 26.84, 27.04, 27.14, 27.54, 28.06, 29.92\r\n        ]])\r\n    },\r\n    {\r\n        'stride': [30, 5, 5],\r\n        'tokens': torch.tensor([[\r\n            50257, 50362, 2773, 661, 4320, 1943, 981,\r\n            345, 821, 8066, 7765, 510, 290, 670,\r\n            1327, 379, 340, 13, 10528, 318, 5340,\r\n            13, 921, 815, 651, 284, 262, 966,\r\n            810, 2687, 2073, 561, 11238, 290, 345,\r\n            821, 407, 8066, 2245, 612, 13, 1400,\r\n            11, 644, 389, 345, 4953, 329, 30,\r\n            2141, 340, 0, 2329, 466, 340, 0,\r\n            3363, 11, 345, 460, 0, 2329, 466,\r\n            340, 0, 50256\r\n        ]]),\r\n        'token_timestamps': torch.tensor([[\r\n            0, 0, 0, 2.92, 3.24, 3.5, 4.14,\r\n            4.56, 4.7, 4.74, 4.92, 5.18, 5.54, 5.74,\r\n            6.04, 6.34, 6.46, 6.84, 7.04, 7.18, 7.56,\r\n            8.12, 9.68, 10.7, 10.88, 11.1, 11.24, 11.48,\r\n            11.82, 12.46, 12.82, 13.2, 13.46, 13.72, 14.08,\r\n            14.28, 14.34, 14.56, 14.82, 15.16, 15.72, 16.42,\r\n            16.82, 16.86, 17, 17.1, 17.2, 17.56, 18.06,\r\n            19.28, 19.6, 20.28, 21.96, 22.64, 24.28, 24.76,\r\n            25.18, 25.56, 25.56, 25.84, 26.36, 27.12, 27.54,\r\n            27.82, 28.16, 29.48\r\n        ]])\r\n    },\r\n    {\r\n        'stride': [23.7728125, 5, 0],\r\n        'tokens': torch.tensor([[\r\n            50257, 50362, 2329, 466,\r\n            340, 0, 3363, 345,\r\n            460, 0, 2329, 466,\r\n            340, 0, 1002, 534,\r\n            15867, 318, 3599, 625,\r\n            11, 2245, 3501, 510,\r\n            13, 50256\r\n        ]]),\r\n        'token_timestamps': torch.tensor([[\r\n            0, 0, 0, 2.44, 4.3,\r\n            5.04, 5.06, 5.56, 5.8, 6.32,\r\n            7.12, 7.56, 7.8, 8.72, 10.04,\r\n            12.96, 13.3, 13.44, 13.72, 13.98,\r\n            14.86, 15.5, 16, 16.88, 17.76,\r\n            20.9\r\n        ]])\r\n    }\r\n]\r\n\r\n\r\nfrom transformers import AutoTokenizer\r\ntokenizer = AutoTokenizer.from_pretrained('onnx-community/whisper-tiny.en_timestamped')\r\ntokenizer._decode_asr(model_outputs, return_timestamps='word', return_language=False, time_precision=0.02)\r\n```\r\n\r\nproduces the following **incorrect** transcript:\r\n\r\n```py\r\n(\" DO IT! Just DO IT! Don't let your dreams be dreams. Yesterday, you said tomorrow, so just DO IT! MAKE YOUR DRIMS! CONTRO! JUST DO IT! Some people dream success while you're gonna wake up and work hard at it. Nothing is impossible. You should get to the point where anyone else would quit and you're not gonna stop there. No, what are you waiting for? Do it! Just do it! Yes, you can! Just do it! Yes you can! Just do it! If your tire is starting over, stop giving up.\",\r\n {'chunks': [{'text': ' DO', 'timestamp': (0.0, 3.78)},\r\n   {'text': ' IT!', 'timestamp': (3.78, 5.26)},\r\n   {'text': ' Just', 'timestamp': (5.26, 6.04)},\r\n   {'text': ' DO', 'timestamp': (6.04, 6.54)},\r\n   {'text': ' IT!', 'timestamp': (6.54, 7.94)},\r\n   {'text': \" Don't\", 'timestamp': (7.94, 8.58)},\r\n   {'text': ' let', 'timestamp': (8.58, 8.88)},\r\n   {'text': ' your', 'timestamp': (8.88, 9.16)},\r\n   {'text': ' dreams', 'timestamp': (9.16, 9.54)},\r\n   {'text': ' be', 'timestamp': (9.54, 9.94)},\r\n   {'text': ' dreams.', 'timestamp': (9.94, 11.38)},\r\n   {'text': ' Yesterday,', 'timestamp': (11.38, 12.38)},\r\n   {'text': ' you', 'timestamp': (12.38, 12.44)},\r\n   {'text': ' said', 'timestamp': (12.44, 12.62)},\r\n   {'text': ' tomorrow,', 'timestamp': (12.62, 13.36)},\r\n   {'text': ' so', 'timestamp': (13.36, 13.64)},\r\n   {'text': ' just', 'timestamp': (13.64, 14.24)},\r\n   {'text': ' DO', 'timestamp': (14.24, 14.74)},\r\n   {'text': ' IT!', 'timestamp': (14.74, 15.4)},\r\n   {'text': ' MAKE', 'timestamp': (15.4, 15.74)},\r\n   {'text': ' YOUR', 'timestamp': (15.74, 16.1)},\r\n   {'text': ' DRIMS!', 'timestamp': (16.1, 17.08)},\r\n   {'text': ' CONTRO!', 'timestamp': (17.08, 18.08)},\r\n   {'text': ' JUST', 'timestamp': (18.08, 18.58)},\r\n   {'text': ' DO', 'timestamp': (18.58, 19.38)},\r\n   {'text': ' IT!', 'timestamp': (19.38, 22.54)},\r\n   {'text': ' Some', 'timestamp': (22.54, 22.9)},\r\n   {'text': ' people', 'timestamp': (22.9, 23.24)},\r\n   {'text': ' dream', 'timestamp': (23.24, 23.5)},\r\n   {'text': ' success', 'timestamp': (23.5, 24.14)},\r\n   {'text': ' while', 'timestamp': (24.14, 24.56)},\r\n   {'text': \" you're\", 'timestamp': (24.56, 24.94)},\r\n   {'text': ' gonna', 'timestamp': (24.94, 24.94)},\r\n   {'text': ' wake', 'timestamp': (24.94, 25.18)},\r\n   {'text': ' up', 'timestamp': (25.18, 25.54)},\r\n   {'text': ' and', 'timestamp': (25.54, 25.74)},\r\n   {'text': ' work', 'timestamp': (25.74, 26.04)},\r\n   {'text': ' hard', 'timestamp': (26.04, 26.34)},\r\n   {'text': ' at', 'timestamp': (26.34, 26.46)},\r\n   {'text': ' it.', 'timestamp': (26.46, 27.04)},\r\n   {'text': ' Nothing', 'timestamp': (27.04, 27.18)},\r\n   {'text': ' is', 'timestamp': (27.18, 27.56)},\r\n   {'text': ' impossible.', 'timestamp': (27.56, 29.68)},\r\n   {'text': ' You', 'timestamp': (29.68, 30.7)},\r\n   {'text': ' should', 'timestamp': (30.7, 30.88)},\r\n   {'text': ' get', 'timestamp': (30.88, 31.1)},\r\n   {'text': ' to', 'timestamp': (31.1, 31.24)},\r\n   {'text': ' the', 'timestamp': (31.24, 31.48)},\r\n   {'text': ' point', 'timestamp': (31.48, 31.82)},\r\n   {'text': ' where', 'timestamp': (31.82, 32.46)},\r\n   {'text': ' anyone', 'timestamp': (32.46, 32.82)},\r\n   {'text': ' else', 'timestamp': (32.82, 33.2)},\r\n   {'text': ' would', 'timestamp': (33.2, 33.46)},\r\n   {'text': ' quit', 'timestamp': (33.46, 33.72)},\r\n   {'text': ' and', 'timestamp': (33.72, 34.08)},\r\n   {'text': \" you're\", 'timestamp': (34.08, 34.34)},\r\n   {'text': ' not', 'timestamp': (34.34, 34.56)},\r\n   {'text': ' gonna', 'timestamp': (34.56, 34.82)},\r\n   {'text': ' stop', 'timestamp': (34.82, 35.16)},\r\n   {'text': ' there.', 'timestamp': (35.16, 36.42)},\r\n   {'text': ' No,', 'timestamp': (36.42, 36.86)},\r\n   {'text': ' what', 'timestamp': (36.86, 37.0)},\r\n   {'text': ' are', 'timestamp': (37.0, 37.1)},\r\n   {'text': ' you', 'timestamp': (37.1, 37.2)},\r\n   {'text': ' waiting', 'timestamp': (37.2, 37.56)},\r\n   {'text': ' for?', 'timestamp': (37.56, 39.28)},\r\n   {'text': ' Do', 'timestamp': (39.28, 39.6)},\r\n   {'text': ' it!', 'timestamp': (39.6, 41.96)},\r\n   {'text': ' Just', 'timestamp': (41.96, 42.64)},\r\n   {'text': ' do', 'timestamp': (42.64, 44.28)},\r\n   {'text': ' it!', 'timestamp': (44.28, 45.18)},\r\n   {'text': ' Yes,', 'timestamp': (45.18, 45.56)},\r\n   {'text': ' you', 'timestamp': (45.56, 45.84)},\r\n   {'text': ' can!', 'timestamp': (45.84, 47.12)},\r\n   {'text': ' Just', 'timestamp': (47.12, 47.54)},\r\n   {'text': ' do', 'timestamp': (47.54, 47.82)},\r\n   {'text': ' it!', 'timestamp': (44.3, 45.06)},\r\n   {'text': ' Yes', 'timestamp': (45.06, 45.56)},\r\n   {'text': ' you', 'timestamp': (45.56, 45.8)},\r\n   {'text': ' can!', 'timestamp': (45.8, 47.12)},\r\n   {'text': ' Just', 'timestamp': (47.12, 47.56)},\r\n   {'text': ' do', 'timestamp': (47.56, 47.8)},\r\n   {'text': ' it!', 'timestamp': (47.8, 50.04)},\r\n   {'text': ' If', 'timestamp': (50.04, 52.96)},\r\n   {'text': ' your', 'timestamp': (52.96, 53.3)},\r\n   {'text': ' tire', 'timestamp': (53.3, 53.44)},\r\n   {'text': ' is', 'timestamp': (53.44, 53.72)},\r\n   {'text': ' starting', 'timestamp': (53.72, 53.98)},\r\n   {'text': ' over,', 'timestamp': (53.98, 55.5)},\r\n   {'text': ' stop', 'timestamp': (55.5, 56.0)},\r\n   {'text': ' giving', 'timestamp': (56.0, 56.88)},\r\n   {'text': ' up.', 'timestamp': (56.88, 60.9)}]})\r\n```\r\n\r\n(Notice at ~46 seconds, it goes back in time):\r\n```py\r\n  {'text': ' Yes,', 'timestamp': (45.18, 45.56)},\r\n   {'text': ' you', 'timestamp': (45.56, 45.84)},\r\n   {'text': ' can!', 'timestamp': (45.84, 47.12)},\r\n   {'text': ' Just', 'timestamp': (47.12, 47.54)},\r\n   {'text': ' do', 'timestamp': (47.54, 47.82)},\r\n   {'text': ' it!', 'timestamp': (44.3, 45.06)},\r\n   {'text': ' Yes', 'timestamp': (45.06, 45.56)},\r\n   {'text': ' you', 'timestamp': (45.56, 45.8)},\r\n   {'text': ' can!', 'timestamp': (45.8, 47.12)},\r\n   {'text': ' Just', 'timestamp': (47.12, 47.56)},\r\n   {'text': ' do', 'timestamp': (47.56, 47.8)},\r\n   {'text': ' it!', 'timestamp': (47.8, 50.04)},\r\n```\r\n\r\nFor reference, [this](https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/whisper-timestamps-demo.mp4?download=true) is the media I am transcribing.\n\n### Expected behavior\n\n1. The transcript times should be increasing.\r\n2. If you watch the [video](https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/whisper-timestamps-demo.mp4?download=true), it's clear that the repeated phrasing messes something up, duplicating this in the merged output.\r\n3. Result should be something like:\r\n```diff\r\n  {'text': ' Do', 'timestamp': (39.28, 39.6)},\r\n   {'text': ' it!', 'timestamp': (39.6, 41.96)},\r\n   {'text': ' Just', 'timestamp': (41.96, 42.64)},\r\n   {'text': ' do', 'timestamp': (42.64, 44.28)},\r\n   {'text': ' it!', 'timestamp': (44.28, 45.18)},\r\n-  {'text': ' Yes,', 'timestamp': (45.18, 45.56)},\r\n-  {'text': ' you', 'timestamp': (45.56, 45.84)},\r\n-  {'text': ' can!', 'timestamp': (45.84, 47.12)},\r\n-  {'text': ' Just', 'timestamp': (47.12, 47.54)},\r\n-  {'text': ' do', 'timestamp': (47.54, 47.82)},\r\n-  {'text': ' it!', 'timestamp': (44.3, 45.06)},\r\n-  {'text': ' Yes', 'timestamp': (45.06, 45.56)},\r\n+  {'text': ' Yes', 'timestamp': (45.18, 45.56)},\r\n   {'text': ' you', 'timestamp': (45.56, 45.8)},\r\n   {'text': ' can!', 'timestamp': (45.8, 47.12)},\r\n   {'text': ' Just', 'timestamp': (47.12, 47.56)},\r\n   {'text': ' do', 'timestamp': (47.56, 47.8)},\r\n   {'text': ' it!', 'timestamp': (47.8, 50.04)},\r\n```", "patch": ""}
{"instance_id": "huggingface__transformers-20650", "file_changes": [{"file": ".circleci/create_circleci_config.py", "changes": {}}, {"file": "README.md", "changes": {}}, {"file": "README_es.md", "changes": {}}, {"file": "README_fr.md", "changes": {}}, {"file": "README_hd.md", "changes": {}}, {"file": "README_ja.md", "changes": {}}, {"file": "README_ko.md", "changes": {}}, {"file": "README_zh-hans.md", "changes": {}}, {"file": "README_zh-hant.md", "changes": {}}, {"file": "docs/source/en/_toctree.yml", "changes": {}}, {"file": "docs/source/en/index.md", "changes": {}}, {"file": "src/transformers/__init__.py", "changes": {}}, {"file": "src/transformers/convert_slow_tokenizer.py", "changes": {}}, {"file": "src/transformers/models/__init__.py", "changes": {}}, {"file": "src/transformers/models/auto/configuration_auto.py", "changes": {}}, {"file": "src/transformers/models/auto/image_processing_auto.py", "changes": {}}, {"file": "src/transformers/models/auto/modeling_auto.py", "changes": {}}, {"file": "src/transformers/models/auto/tokenization_auto.py", "changes": {}}, {"file": "src/transformers/utils/dummy_pt_objects.py", "changes": {}}, {"file": "src/transformers/utils/dummy_sentencepiece_objects.py", "changes": {}}, {"file": "src/transformers/utils/dummy_tokenizers_objects.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "1681a6d452b60ff3652a96f03541dfa491124192", "problem_statement": "[New Model] UDOP: Unifying Vision, Text, and Layout for Universal Document Processing\n\n### Model description\r\n\r\nWe propose Universal Document Processing (UDOP), a foundation Document AI model which unifies text, image, and layout modalities together with varied task formats, including document understanding and generation. UDOP leverages the spatial correlation between textual content and document image to model image, text, and layout modalities with one uniform representation. With a novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain downstream tasks into a prompt-based sequence generation scheme. UDOP is pretrained on both large-scale unlabeled document corpora using innovative self-supervised objectives and diverse labeled data. UDOP also learns to generate document images from text and layout modalities via masked image reconstruction. To the best of our knowledge, this is the first time in the field of document AI that one model simultaneously achieves high-quality neural document editing and content customization. Our method sets the state-of-the-art on 9 Document AI tasks, e.g., document understanding and QA, across diverse data domains like finance reports, academic papers, and websites. UDOP ranks first on the leaderboard of the Document Understanding Benchmark (DUE).\r\n\r\n### Open source status\r\n\r\n- [x] The model implementation is available\r\n- [x] The model weights are available\r\n\r\n### Provide useful links for the implementation\r\nUDOP Paper: https://arxiv.org/abs/2212.02623\r\nUDOP Repo: https://github.com/microsoft/UDOP\r\n\r\nUDOP Model Weights: https://huggingface.co/ZinengTang/Udop/tree/main", "patch": ""}
{"instance_id": "huggingface__transformers-18068", "file_changes": [{"file": "src/transformers/generation/stopping_criteria.py", "changes": {"edited_modules": ["src/transformers/generation/stopping_criteria.py:StoppingCriteria"], "edited_entities": ["src/transformers/generation/stopping_criteria.py:StoppingCriteria"]}}, {"file": "src/transformers/generation/utils.py", "changes": {"edited_modules": ["src/transformers/generation/utils.py:GenerationMixin"], "edited_entities": ["src/transformers/generation/utils.py:GenerationMixin.generate"]}}], "repo": "huggingface/transformers", "base_commit": "4b423e607455a7aca1edc4beaa713da58e78ef0b", "problem_statement": "StoppingCriteria \"scores\" is always None\n\n### System Info\n\nI've written a custom StoppingCriteria subclass and I'm trying to utilize the `scores` in my decision logic, but I'm finding that `scores` is always `None`. Is that intentional?\n\n### Who can help?\n\n@patrickvonplaten, @Narsil, @gante\n\n### Information\n\n- [ ] The official example scripts\n- [X] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [X] My own task or dataset (give details below)\n\n### Reproduction\n\n```\r\nclass TopPredictionOutsideTargetSetStoppingCriteria(StoppingCriteria):\r\n    def __init__(self, priority_tokens_ids: list):\r\n        self.priority_token_ids = priority_tokens_ids\r\n\r\n    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\r\n        print(f\"TopPred SCORES? {scores}, input_ids: {input_ids}\")      # <--- \"scores\" is None but \"input_ids\" is correct\r\n        top = torch.topk(scores, 1, dim=1).indices[0]\r\n        if not top in self.priority_token_ids:\r\n            return True\r\n        return False\r\n```\n\n### Expected behavior\n\nSince the function indicates `scores` as an input, I'd expect it to be a non-null value.", "patch": ""}
{"instance_id": "huggingface__transformers-11357", "file_changes": [{"file": "src/transformers/models/bart/modeling_bart.py", "changes": {}}, {"file": "src/transformers/models/bart/modeling_tf_bart.py", "changes": {}}, {"file": "src/transformers/models/blenderbot/modeling_blenderbot.py", "changes": {}}, {"file": "src/transformers/models/blenderbot/modeling_tf_blenderbot.py", "changes": {}}, {"file": "src/transformers/models/blenderbot_small/modeling_blenderbot_small.py", "changes": {}}, {"file": "src/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py", "changes": {}}, {"file": "src/transformers/models/fsmt/modeling_fsmt.py", "changes": {}}, {"file": "src/transformers/models/m2m_100/modeling_m2m_100.py", "changes": {}}, {"file": "src/transformers/models/marian/modeling_marian.py", "changes": {}}, {"file": "src/transformers/models/marian/modeling_tf_marian.py", "changes": {}}, {"file": "src/transformers/models/mbart/modeling_mbart.py", "changes": {}}, {"file": "src/transformers/models/mbart/modeling_tf_mbart.py", "changes": {}}, {"file": "src/transformers/models/pegasus/modeling_pegasus.py", "changes": {}}, {"file": "src/transformers/models/pegasus/modeling_tf_pegasus.py", "changes": {}}, {"file": "src/transformers/models/prophetnet/modeling_prophetnet.py", "changes": {}}, {"file": "src/transformers/models/speech_to_text/modeling_speech_to_text.py", "changes": {}}, {"file": "src/transformers/models/t5/modeling_t5.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "88ac60f7b5f6d4b62245dc21653ea3d5db7d4935", "problem_statement": "possible mistake in documentation\n\nLooking at description of the parameter \"decoder_input_ids\" in \"forward\" method of BartForConditionalGeneration/T5ForConditionalGeneration, I see following:\r\n\r\nBartForConditionalGeneration:\r\ndecoder_input_ids - ... For translation and summarization training, decoder_input_ids should be provided. If no decoder_input_ids is provided, the model will create this tensor by shifting the !!INPUT_IDS!! to the right for denoising pretraining following the paper.\r\n\r\nT5ForConditionalGeneration:\r\ndecoder_input_ids - ... To know more on how to prepare decoder_input_ids for pretraining take a look at T5 Training. If decoder_input_ids and decoder_inputs_embeds are both unset, decoder_input_ids takes the value of  !!INPUT_IDS!!.\r\n\r\nLooks like there should be LABELS instead of INPUT_IDS.\r\n\r\nThanks,\r\n@patrickvonplaten, @patil-suraj", "patch": ""}
{"instance_id": "huggingface__transformers-13826", "file_changes": [{"file": "src/transformers/tokenization_utils_base.py", "changes": {"edited_modules": ["src/transformers/tokenization_utils_base.py:PreTrainedTokenizerBase"], "edited_entities": ["src/transformers/tokenization_utils_base.py:PreTrainedTokenizerBase._get_padding_truncation_strategies"]}}], "repo": "huggingface/transformers", "base_commit": "8bbb53e20b7873ba7f63be70d4d798e0c3568bfa", "problem_statement": "Tokenizer - Raises wrong \"UserWarning: `max_length` is ignored when `padding`=`True`\"\n\nIn the newest version of transformers (4.11.2 & 4.12.0.dev0) I get the following warning:\r\n```\r\nC:\\Anaconda3\\envs\\sbert\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\r\n  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\r\n```\r\n\r\n\r\nCode to re-produce:\r\n```python\r\nfrom transformers import AutoTokenizer\r\n\r\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\r\ntexts = [\"Short sentence\", \"A really really really really really long sentence to test max length\"]\r\n\r\noutput = tokenizer(texts, padding=True, truncation=True, max_length=5, return_tensors='pt')\r\nprint(output['input_ids'].shape)\r\n\r\noutput = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\r\nprint(output['input_ids'].shape)\r\n```\r\n\r\nOutput:\r\n```\r\nC:\\Anaconda3\\envs\\sbert\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\r\n  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\r\ntorch.Size([2, 5])\r\ntorch.Size([2, 14])\r\n```` \r\n\r\n\r\nAs we see, max_length is not ignored when padding = True. It truncates the text as expected to a max_length of 5.\r\n\r\nI would say that the warning is incorrect and should not be raised. \r\n\r\nShould I fix it?\r\n\r\nOr is it really intended that max_length is ignored when padding=True? This would be horrible, I want to truncate my text to a certain max_length.", "patch": ""}
{"instance_id": "huggingface__transformers-3227", "file_changes": [{"file": "examples/utils_multiple_choice.py", "changes": {"edited_modules": ["examples/utils_multiple_choice.py:convert_examples_to_features"], "edited_entities": ["examples/utils_multiple_choice.py:convert_examples_to_features"]}}, {"file": "src/transformers/data/processors/squad.py", "changes": {"edited_modules": ["src/transformers/data/processors/squad.py:squad_convert_example_to_features"], "edited_entities": ["src/transformers/data/processors/squad.py:squad_convert_example_to_features"]}}], "repo": "huggingface/transformers", "base_commit": "010e0460b22ddd7f74e31163f69ab3da2e9741ba", "problem_statement": "An Error report about pipeline\n\n# \ud83d\udc1b Bug\r\n\r\n## Information\r\n\r\nThis may be an easy question, but it has been bothering me all day.\r\n\r\nWhen I run the code: \r\nnlp = pipeline(\"question-answering\")\r\n\r\nIt always tells me: \r\nCouldn't reach server at 'https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-cased-distilled-squad-modelcard.json' to download model card file.\r\nCreating an empty model card.\r\n\r\nIf I ignore it and continue to run the rest of the code: \r\nnlp({\r\n    'question': 'What is the name of the repository ?',\r\n    'context': 'Pipeline have been included in the huggingface/transformers repository'\r\n})\r\n\r\nThe error will appear:\r\nKeyError: 'token_type_ids'", "patch": ""}
{"instance_id": "huggingface__transformers-12762", "file_changes": [{"file": "src/transformers/models/albert/tokenization_albert_fast.py", "changes": {"edited_modules": ["src/transformers/models/albert/tokenization_albert_fast.py:AlbertTokenizerFast"], "edited_entities": ["src/transformers/models/albert/tokenization_albert_fast.py:AlbertTokenizerFast.__init__", "src/transformers/models/albert/tokenization_albert_fast.py:AlbertTokenizerFast"]}}, {"file": "src/transformers/models/barthez/tokenization_barthez_fast.py", "changes": {"edited_modules": ["src/transformers/models/barthez/tokenization_barthez_fast.py:BarthezTokenizerFast"], "edited_entities": ["src/transformers/models/barthez/tokenization_barthez_fast.py:BarthezTokenizerFast.__init__", "src/transformers/models/barthez/tokenization_barthez_fast.py:BarthezTokenizerFast"]}}, {"file": "src/transformers/models/big_bird/tokenization_big_bird_fast.py", "changes": {"edited_modules": ["src/transformers/models/big_bird/tokenization_big_bird_fast.py:BigBirdTokenizerFast"], "edited_entities": ["src/transformers/models/big_bird/tokenization_big_bird_fast.py:BigBirdTokenizerFast.__init__", "src/transformers/models/big_bird/tokenization_big_bird_fast.py:BigBirdTokenizerFast"]}}, {"file": "src/transformers/models/camembert/tokenization_camembert_fast.py", "changes": {"edited_modules": ["src/transformers/models/camembert/tokenization_camembert_fast.py:CamembertTokenizerFast"], "edited_entities": ["src/transformers/models/camembert/tokenization_camembert_fast.py:CamembertTokenizerFast.__init__", "src/transformers/models/camembert/tokenization_camembert_fast.py:CamembertTokenizerFast"]}}, {"file": "src/transformers/models/herbert/tokenization_herbert_fast.py", "changes": {}}, {"file": "src/transformers/models/mbart50/tokenization_mbart50_fast.py", "changes": {"edited_modules": ["src/transformers/models/mbart50/tokenization_mbart50_fast.py:MBart50TokenizerFast"], "edited_entities": ["src/transformers/models/mbart50/tokenization_mbart50_fast.py:MBart50TokenizerFast.__init__", "src/transformers/models/mbart50/tokenization_mbart50_fast.py:MBart50TokenizerFast"]}}, {"file": "src/transformers/models/pegasus/tokenization_pegasus_fast.py", "changes": {"edited_modules": ["src/transformers/models/pegasus/tokenization_pegasus_fast.py:PegasusTokenizerFast"], "edited_entities": ["src/transformers/models/pegasus/tokenization_pegasus_fast.py:PegasusTokenizerFast.__init__", "src/transformers/models/pegasus/tokenization_pegasus_fast.py:PegasusTokenizerFast"]}}, {"file": "src/transformers/models/reformer/tokenization_reformer_fast.py", "changes": {"edited_modules": ["src/transformers/models/reformer/tokenization_reformer_fast.py:ReformerTokenizerFast"], "edited_entities": ["src/transformers/models/reformer/tokenization_reformer_fast.py:ReformerTokenizerFast.__init__", "src/transformers/models/reformer/tokenization_reformer_fast.py:ReformerTokenizerFast"]}}, {"file": "src/transformers/models/t5/tokenization_t5_fast.py", "changes": {"edited_modules": ["src/transformers/models/t5/tokenization_t5_fast.py:T5TokenizerFast"], "edited_entities": ["src/transformers/models/t5/tokenization_t5_fast.py:T5TokenizerFast.__init__", "src/transformers/models/t5/tokenization_t5_fast.py:T5TokenizerFast"]}}, {"file": "src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py", "changes": {"edited_modules": ["src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:XLMRobertaTokenizerFast"], "edited_entities": ["src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:XLMRobertaTokenizerFast.__init__", "src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:XLMRobertaTokenizerFast"]}}, {"file": "src/transformers/models/xlnet/tokenization_xlnet_fast.py", "changes": {"edited_modules": ["src/transformers/models/xlnet/tokenization_xlnet_fast.py:XLNetTokenizerFast"], "edited_entities": ["src/transformers/models/xlnet/tokenization_xlnet_fast.py:XLNetTokenizerFast.__init__", "src/transformers/models/xlnet/tokenization_xlnet_fast.py:XLNetTokenizerFast"]}}, {"file": "src/transformers/tokenization_utils_fast.py", "changes": {"edited_modules": ["src/transformers/tokenization_utils_fast.py:PreTrainedTokenizerFast"], "edited_entities": ["src/transformers/tokenization_utils_fast.py:PreTrainedTokenizerFast", "src/transformers/tokenization_utils_fast.py:PreTrainedTokenizerFast._save_pretrained"]}}, {"file": "tests/test_tokenization_common.py", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "ba1b3db70907b975b5ca52b9957c5ed7a186a0fa", "problem_statement": "t5 fast tokenizer save_vocabulary fails without sentencepiece file\n\n## Environment info\r\n\r\n- `transformers` version: 4.9.0.dev0\r\n- Platform: Linux-5.4.0-1043-gcp-x86_64-with-glibc2.29\r\n- Python version: 3.8.10\r\n- PyTorch version (GPU?): 1.9.0+cu102 (False)\r\n- Tensorflow version (GPU?): 2.5.0 (False)\r\n- Flax version (CPU?/GPU?/TPU?): 0.3.4 (tpu)\r\n- Jax version: 0.2.16\r\n- JaxLib version: 0.1.68\r\n- Using GPU in script?: no (tpu)\r\n- Using distributed or parallel set-up in script?: I guess data parallel\r\n\r\n### Who can help\r\n\r\nModels:\r\n- t5: @patrickvonplaten\r\n\r\nLibrary:\r\n- tokenizers: @LysandreJik\r\n\r\n## Information\r\n\r\nModel I am using (Bert, XLNet ...):\r\n\r\nThe problem arises when using:\r\n* [x] the official example scripts: (give details below)\r\n* [ ] my own modified scripts: (give details below)\r\n\r\nThe tasks I am working on is:\r\n* [x] an official GLUE/SQUaD task: (give the name)\r\n* [] my own task or dataset: (give details below)\r\n\r\nTask is summarization\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Use the [summarization example code](https://github.com/huggingface/transformers/blob/3cd15c1dd62c5c9a9202fae9f00b8eba3eb2b95d/examples/pytorch/summarization/run_summarization.py) and fine tune a pre-trained t5 tokenizer and model created according to the flax mlm example scripts and [t5 tokenizer](https://github.com/huggingface/transformers/blob/master/examples/flax/language-modeling/t5_tokenizer_model.py) -- for instance [t5-base-norwegian](https://huggingface.co/patrickvonplaten/t5-base-norwegian/tree/main)\r\n\r\nWhen the finetuning-summary-trainer saves the model, it will also attempt to save the vocabulary. This will fail with the following stack trace, because the tokenizers `self.vocab_file` is None, where it is expected to point at a sentencepiece file:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/run_summarization.py\", line 620, in <module>\r\n    main()\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/run_summarization.py\", line 545, in main\r\n    trainer.save_model()  # Saves the tokenizer too for easy upload\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/transformers/src/transformers/trainer.py\", line 1883, in save_model\r\n    self._save(output_dir)\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/transformers/src/transformers/trainer.py\", line 1933, in _save\r\n    self.tokenizer.save_pretrained(output_dir)\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/transformers/src/transformers/tokenization_utils_base.py\", line 1958, in save_pretrained\r\n    save_files = self._save_pretrained(\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/transformers/src/transformers/tokenization_utils_fast.py\", line 567, in _save_pretrained\r\n    vocab_files = self.save_vocabulary(save_directory, filename_prefix=filename_prefix)\r\n  File \"/home/yeb/Developer/yhavinga/t5-base-dutch-summarization/transformers/src/transformers/models/t5/tokenization_t5_fast.py\", line 150, in save_vocabulary\r\n    if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_file):\r\n  File \"/usr/lib/python3.8/posixpath.py\", line 374, in abspath\r\n    path = os.fspath(path)\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nThe following hack works around the problem:\r\n```\r\ndiff --git a/src/transformers/models/t5/tokenization_t5_fast.py b/src/transformers/models/t5/tokenization_t5_fast.py\r\nindex 3f972b006..cc238a119 100644\r\n--- a/src/transformers/models/t5/tokenization_t5_fast.py\r\n+++ b/src/transformers/models/t5/tokenization_t5_fast.py\r\n@@ -147,9 +147,10 @@ class T5TokenizerFast(PreTrainedTokenizerFast):\r\n             save_directory, (filename_prefix + \"-\" if filename_prefix else \"\") + VOCAB_FILES_NAMES[\"vocab_file\"]\r\n         )\r\n \r\n-        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_file):\r\n-            copyfile(self.vocab_file, out_vocab_file)\r\n-            logger.info(f\"Copy vocab file to {out_vocab_file}\")\r\n+        if self.vocab_file:\r\n+            if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_file):\r\n+                copyfile(self.vocab_file, out_vocab_file)\r\n+                logger.info(f\"Copy vocab file to {out_vocab_file}\")\r\n \r\n         return (out_vocab_file,)\r\n ```\r\n\r\n## Expected behavior\r\n\r\nNo error.", "patch": ""}
{"instance_id": "huggingface__transformers-28286", "file_changes": [{"file": "examples/pytorch/contrastive-image-text/run_clip.py", "changes": {"edited_modules": ["examples/pytorch/contrastive-image-text/run_clip.py:main"], "edited_entities": ["examples/pytorch/contrastive-image-text/run_clip.py:main"]}}], "repo": "huggingface/transformers", "base_commit": "edb314ae2ba4ac0e89d6a31d48037b8943978bff", "problem_statement": "`contrastive-image-text/run_clip.py` example problems\n\n### System Info\n\n- `transformers` version: 4.37.0.dev0\r\n- Platform: Linux-5.15.0-88-generic-x86_64-with-glibc2.31\r\n- Python version: 3.11.5\r\n- Huggingface_hub version: 0.20.1\r\n- Safetensors version: 0.4.1\r\n- Accelerate version: 0.25.0\r\n- Accelerate config:    not found\r\n- PyTorch version (GPU?): 2.1.2+cu121 (True)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Flax version (CPU?/GPU?/TPU?): not installed (NA)\r\n- Jax version: not installed\r\n- JaxLib version: not installed\r\n- Using GPU in script?: Yes\r\n- Using distributed or parallel set-up in script?: No\n\n### Who can help?\n\n@amyeroberts\n\n### Information\n\n- [X] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [X] My own task or dataset (give details below)\n\n### Reproduction\n\nThe following example script has some issues: https://github.com/huggingface/transformers/blob/main/examples/pytorch/contrastive-image-text/run_clip.py\r\n\r\n#### Minor issue:\r\nWhen using `--train_file dataset.csv`, the tokenizer fails if the caption is \"None\", \"null\" or \"NA\"\r\n\r\n#### Curiosity:\r\n- There seems to be no parameter to specify the hub repository to push to.\r\n- Also, there seems to be no place to track the experiment (like wandb)\r\n\r\n#### Actual issue\r\n\r\nWith the following parameters\r\n```bash\r\n    --model_name_or_path \"openai/clip-vit-base-patch32\" \\\r\n    --freeze_text_model \\\r\n    --train_file \"train.csv\" \\\r\n    --image_column \"image_path\" \\\r\n    --caption_column \"caption\" \\\r\n    --remove_unused_columns=False \\\r\n    --do_train \\\r\n    --per_device_train_batch_size=\"64\" \\\r\n    --per_device_eval_batch_size=\"64\" \\\r\n    --learning_rate=\"5e-5\" --warmup_steps=\"0\" --weight_decay 0.1 \\\r\n    --overwrite_output_dir \\\r\n    --push_to_hub\r\n```\r\n\r\nI get the following error:\r\n```bash\r\n[INFO|trainer.py:1712] 2023-12-30 18:16:36,697 >> ***** Running training *****\r\n[INFO|trainer.py:1713] 2023-12-30 18:16:36,697 >>   Num examples = 348,784\r\n[INFO|trainer.py:1714] 2023-12-30 18:16:36,697 >>   Num Epochs = 3\r\n[INFO|trainer.py:1715] 2023-12-30 18:16:36,698 >>   Instantaneous batch size per device = 64\r\n[INFO|trainer.py:1718] 2023-12-30 18:16:36,698 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\r\n[INFO|trainer.py:1719] 2023-12-30 18:16:36,698 >>   Gradient Accumulation steps = 1\r\n[INFO|trainer.py:1720] 2023-12-30 18:16:36,698 >>   Total optimization steps = 16,350\r\n[INFO|trainer.py:1721] 2023-12-30 18:16:36,698 >>   Number of trainable parameters = 88,111,361\r\n  0%|                                                                                                                                                                                                    | 0/16350 [00:00<?, ?it/s]Traceback (most recent call last):\r\n  File \"/home/amoryo/sign-language/signwriting-clip/signwriting_clip/transformers/examples/pytorch/contrastive-image-text/run_clip.py\", line 590, in <module>\r\n    main()\r\n  File \"/home/amoryo/sign-language/signwriting-clip/signwriting_clip/transformers/examples/pytorch/contrastive-image-text/run_clip.py\", line 559, in main\r\n    train_result = trainer.train(resume_from_checkpoint=checkpoint)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/trainer.py\", line 1534, in train\r\n    return inner_training_loop(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/trainer.py\", line 1860, in _inner_training_loop\r\n    tr_loss_step = self.training_step(model, inputs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/trainer.py\", line 2737, in training_step\r\n    loss = self.compute_loss(model, inputs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/trainer.py\", line 2760, in compute_loss\r\n    outputs = model(**inputs)\r\n              ^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py\", line 1108, in forward\r\n    text_outputs = self.text_model(\r\n                   ^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py\", line 691, in forward\r\n    hidden_states = self.embeddings(input_ids=input_ids, position_ids=position_ids)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/amoryo/conda/envs/clip/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py\", line 219, in forward\r\n    embeddings = inputs_embeds + position_embeddings\r\n                 ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~\r\nRuntimeError: The size of tensor a (128) must match the size of tensor b (77) at non-singleton dimension 1\r\n```\n\n### Expected behavior\n\nExample script should train, and push to hub correctly", "patch": ""}
{"instance_id": "huggingface__transformers-1801", "file_changes": [{"file": "examples/hans/test_hans.py", "changes": {"edited_modules": ["examples/hans/test_hans.py:evaluate"], "edited_entities": ["examples/hans/test_hans.py:evaluate"]}}, {"file": "examples/mm-imdb/run_mmimdb.py", "changes": {"edited_modules": ["examples/mm-imdb/run_mmimdb.py:evaluate"], "edited_entities": ["examples/mm-imdb/run_mmimdb.py:evaluate"]}}, {"file": "examples/ner/run_ner.py", "changes": {"edited_modules": ["examples/ner/run_ner.py:evaluate"], "edited_entities": ["examples/ner/run_ner.py:evaluate"]}}, {"file": "examples/run_language_modeling.py", "changes": {"edited_modules": ["examples/run_language_modeling.py:evaluate"], "edited_entities": ["examples/run_language_modeling.py:evaluate"]}}, {"file": "examples/run_multiple_choice.py", "changes": {"edited_modules": ["examples/run_multiple_choice.py:evaluate"], "edited_entities": ["examples/run_multiple_choice.py:evaluate"]}}, {"file": "examples/run_xnli.py", "changes": {"edited_modules": ["examples/run_xnli.py:evaluate"], "edited_entities": ["examples/run_xnli.py:evaluate"]}}], "repo": "huggingface/transformers", "base_commit": "6d00033e97e1751a897f2317fdfd35dd853cee29", "problem_statement": "run_glue.py RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:3\n\n## \ud83d\udc1b Bug\r\n\r\n<!-- Important information -->\r\n\r\nModel I am using (Bert, XLNet....): Bert\r\n\r\nLanguage I am using the model on (English, Chinese....): English\r\n\r\nThe problem arise when using:\r\n* [ ] the official example scripts: (give details)  : transformers/examples/run_glue.py\r\n* [ ] my own modified scripts: (give details)\r\n\r\nThe tasks I am working on is:\r\n* [ ] an official GLUE/SQUaD task: (give the name) :  MRPC\r\n* [ ] my own task or dataset: (give details)\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1.\r\nI've tested using\r\npython -m pytest -sv ./transformers/tests/\r\npython -m pytest -sv ./examples/\r\nand it works fine without couple of tesks.\r\n\r\n2.\r\nafter test, i downloaded glue datafile via\r\nhttps://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e\r\nand tried run_glue.py\r\n\r\npip install -r ./examples/requirements.txt\r\nexport GLUE_DIR=/path/to/glue\r\nexport TASK_NAME=MRPC\r\n\r\n\r\n3.\r\npython ./examples/run_glue.py \\\r\n    --model_type bert \\\r\n    --model_name_or_path bert-base-uncased \\\r\n    --task_name $TASK_NAME \\\r\n    --do_train \\\r\n    --do_eval \\\r\n    --do_lower_case \\\r\n    --data_dir $GLUE_DIR/$TASK_NAME \\\r\n    --max_seq_length 128 \\\r\n    --per_gpu_eval_batch_size=8   \\\r\n    --per_gpu_train_batch_size=8   \\\r\n    --learning_rate 2e-5 \\\r\n    --num_train_epochs 3.0 \\\r\n    --output_dir /tmp/$TASK_NAME/\r\n\r\nand i got this error.\r\n\r\n`11/11/2019 21:10:50 - INFO - __main__ -     Total optimization steps = 345\r\nEpoch:   0%|                                                                                    | 0/3 [00:00<?, ?it/sTraceback (most recent call last):                                                             | 0/115 [00:00<?, ?it/s]\r\n  File \"./examples/run_glue.py\", line 552, in <module>\r\n    main()\r\n  File \"./examples/run_glue.py\", line 503, in main\r\n    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\r\n  File \"./examples/run_glue.py\", line 146, in train\r\n    outputs = model(**inputs)\r\n  File \"/home/insublee/anaconda3/envs/py_torch4/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/insublee/anaconda3/envs/py_torch4/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 146, in forward\r\n    \"them on device: {}\".format(self.src_device_obj, t.device))\r\nRuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:3`\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n* OS: ubuntu16.04LTS\r\n* Python version:                                                      3.7.5\r\n* PyTorch version:                                                     1.2.0\r\n* PyTorch Transformers version (or branch):             2.1.1\r\n* Using GPU ?                                                           4-way 2080ti\r\n* Distributed of parallel setup ?                                cuda10.0 cudnn 7.6.4\r\n* Any other relevant information:\r\n\r\n## Additional context\r\nthank you.", "patch": ""}
{"instance_id": "huggingface__transformers-6193", "file_changes": [{"file": "src/transformers/modeling_roberta.py", "changes": {"edited_modules": ["src/transformers/modeling_roberta.py:RobertaForMaskedLM"], "edited_entities": ["src/transformers/modeling_roberta.py:RobertaForMaskedLM"]}}], "repo": "huggingface/transformers", "base_commit": "43b9d93875cbf6756baf402a4720ca23d8c75015", "problem_statement": "Some weights not initialized in pre-trained RobertaForMaskedLM\n\nThe bug is similar to #2202.\r\n\r\nI am trying to evaluate MLM perplexity (without training/finetuning) using Roberta with `run_language_modeling.py` (from the [official example](https://github.com/huggingface/transformers/tree/master/examples/language-modeling)). However, some weights seems to be reinitialized instead of getting loading from the pretrained Roberta checkpoint.\r\n\r\n## To Reproduce (~~with master branch~~):\r\n\r\n```\r\nimport logging\r\nlogging.basicConfig(level=logging.INFO)\r\nfrom transformers import RobertaForMaskedLM\r\n_ = RobertaForMaskedLM.from_pretrained('roberta-base')\r\n```\r\n\r\nIt gives the following warning message:\r\n```\r\nWARNING:transformers.modeling_utils:Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'lm_head.decoder.bias']\r\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n```\r\n\r\nThe perplexities I get on direct evaluation on Wikitext-2/103 datasets are also much higher than the official Roberta implementation from fairseq. I suspect this could be the reason.", "patch": ""}
{"instance_id": "huggingface__transformers-30073", "file_changes": [{"file": "docs/source/en/model_doc/hubert.md", "changes": {}}, {"file": "docs/source/en/model_doc/wav2vec2.md", "changes": {}}, {"file": "docs/source/en/perf_infer_gpu_one.md", "changes": {}}, {"file": "src/transformers/models/data2vec/modeling_data2vec_audio.py", "changes": {"edited_modules": ["src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioEncoder", "src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioPreTrainedModel", "src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioEncoderLayer"], "edited_entities": ["src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioEncoder.__init__", "src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioPreTrainedModel", "src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioEncoderLayer.__init__", "src/transformers/models/data2vec/modeling_data2vec_audio.py:Data2VecAudioEncoder.forward"]}}, {"file": "src/transformers/models/hubert/modeling_hubert.py", "changes": {"edited_modules": ["src/transformers/models/hubert/modeling_hubert.py:HubertEncoder", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderStableLayerNorm", "src/transformers/models/hubert/modeling_hubert.py:HubertPreTrainedModel", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderLayer", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderLayerStableLayerNorm"], "edited_entities": ["src/transformers/models/hubert/modeling_hubert.py:HubertEncoder.__init__", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderStableLayerNorm.__init__", "src/transformers/models/hubert/modeling_hubert.py:HubertPreTrainedModel", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderLayer.__init__", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderLayerStableLayerNorm.__init__", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoder.forward", "src/transformers/models/hubert/modeling_hubert.py:HubertEncoderStableLayerNorm.forward"]}}, {"file": "src/transformers/models/sew/modeling_sew.py", "changes": {"edited_modules": ["src/transformers/models/sew/modeling_sew.py:SEWEncoder", "src/transformers/models/sew/modeling_sew.py:SEWPreTrainedModel", "src/transformers/models/sew/modeling_sew.py:SEWEncoderLayer"], "edited_entities": ["src/transformers/models/sew/modeling_sew.py:SEWEncoder.__init__", "src/transformers/models/sew/modeling_sew.py:SEWPreTrainedModel", "src/transformers/models/sew/modeling_sew.py:SEWEncoderLayer.__init__", "src/transformers/models/sew/modeling_sew.py:SEWEncoder.forward"]}}, {"file": "src/transformers/models/unispeech/modeling_unispeech.py", "changes": {"edited_modules": ["src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoder", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderStableLayerNorm", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechPreTrainedModel", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderLayer", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderLayerStableLayerNorm"], "edited_entities": ["src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoder.__init__", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderStableLayerNorm.__init__", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechPreTrainedModel", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderLayer.__init__", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderLayerStableLayerNorm.__init__", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoder.forward", "src/transformers/models/unispeech/modeling_unispeech.py:UniSpeechEncoderStableLayerNorm.forward"]}}, {"file": "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py", "changes": {"edited_modules": ["src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoder", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderStableLayerNorm", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatPreTrainedModel", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderLayer", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderLayerStableLayerNorm"], "edited_entities": ["src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoder.__init__", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderStableLayerNorm.__init__", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatPreTrainedModel", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderLayer.__init__", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderLayerStableLayerNorm.__init__", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoder.forward", "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py:UniSpeechSatEncoderStableLayerNorm.forward"]}}, {"file": "src/transformers/models/wav2vec2/modeling_wav2vec2.py", "changes": {"edited_modules": ["src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2Encoder", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderStableLayerNorm", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2PreTrainedModel", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2ForPreTraining", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderLayer", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderLayerStableLayerNorm"], "edited_entities": ["src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2Encoder.__init__", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderStableLayerNorm.__init__", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2PreTrainedModel", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2ForPreTraining.forward", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderLayer.__init__", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderLayerStableLayerNorm.__init__", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2Encoder.forward", "src/transformers/models/wav2vec2/modeling_wav2vec2.py:Wav2Vec2EncoderStableLayerNorm.forward"]}}, {"file": "src/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py", "changes": {"edited_modules": ["src/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py:Wav2Vec2ConformerForPreTraining"], "edited_entities": ["src/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py:Wav2Vec2ConformerForPreTraining.forward"]}}, {"file": "tests/models/wav2vec2/test_modeling_wav2vec2.py", "changes": {"edited_modules": ["tests/models/wav2vec2/test_modeling_wav2vec2.py:Wav2Vec2ModelIntegrationTest"], "edited_entities": ["tests/models/wav2vec2/test_modeling_wav2vec2.py:Wav2Vec2ModelIntegrationTest.test_inference_mms_1b_all"]}}], "repo": "huggingface/transformers", "base_commit": "836e88caee95eb37a860a6c82bbd2becc6b9dc7b", "problem_statement": "SPDA/FA2 Attention for the Wav2Vec2 Family of Models\n\n### Feature request\n\nAddition of [PyTorch SDPA](https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html) and [Flash Attention 2](https://github.com/Dao-AILab/flash-attention) to the Wav2Vec2 modelling code.\n\n### Motivation\n\nWav2Vec2 and its derived models remain some of the most popular speech recognition and audio classification models in the library. However, only one [attention implementation](https://github.com/huggingface/transformers/blob/9b5a6450d481b0f02834684ffd8b3ba4cbbd6fe0/src/transformers/models/wav2vec2/modeling_wav2vec2.py#L487) is available to users: the slowest and most memory consuming \"eager\" mode. We should update the modelling code to provide two newer attention implementations: SDPA and FA2, both of which are faster and more memory efficient.\r\n\r\nSince Wav2Vec2 copies its attention from BART, and SDPA & FA2 were added for BART in [this PR](https://github.com/huggingface/transformers/pull/27203), this should be quite a straightforward PR, mostly copying out the logic from the BART PR and pasting it into Wav2Vec2. We should then be sure to add two fast tests (one for each of SDPA and FA2), e.g. in the style of the test [here](https://github.com/huggingface/transformers/blob/9b5a6450d481b0f02834684ffd8b3ba4cbbd6fe0/tests/models/whisper/test_modeling_whisper.py#L891), and two slow integration tests, e.g. in the style of the tests [here](https://github.com/huggingface/transformers/blob/9b5a6450d481b0f02834684ffd8b3ba4cbbd6fe0/tests/models/gemma/test_modeling_gemma.py#L657-L659).\n\n### Your contribution\n\nWant to take this one @kamilakesbi?", "patch": ""}
{"instance_id": "huggingface__transformers-11294", "file_changes": [{"file": "src/transformers/configuration_utils.py", "changes": {"edited_modules": ["src/transformers/configuration_utils.py:PretrainedConfig"], "edited_entities": ["src/transformers/configuration_utils.py:PretrainedConfig.__init__"]}}, {"file": "src/transformers/trainer.py", "changes": {"edited_modules": ["src/transformers/trainer.py:Trainer"], "edited_entities": ["src/transformers/trainer.py:Trainer.train"]}}, {"file": "tests/test_trainer.py", "changes": {"edited_modules": ["tests/test_trainer.py:TrainerIntegrationTest"], "edited_entities": ["tests/test_trainer.py:TrainerIntegrationTest"]}}], "repo": "huggingface/transformers", "base_commit": "95ffbe168690d34e385cdd16c69e9a3f8d877abf", "problem_statement": "serious bug with trainer.py when restarting the training from a checkpoint\n\n## Environment info\r\n<!-- You can run the command `transformers-cli env` and copy-and-paste its output below.\r\n     Don't forget to fill out the missing fields in that output! -->\r\n\r\n- `transformers` version: 4.5.1\r\n- Platform: Linux\r\n- Python version: 3.8\r\n- PyTorch version (GPU?): 1.8\r\n- Tensorflow version (GPU?): - \r\n- Using GPU in script?: - \r\n- Using distributed or parallel set-up in script?: - \r\n\r\n### Who can help\r\n<!-- Your issue will be replied to more quickly if you can figure out the right person to tag with @\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @Rocketknight1\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nModel hub:\r\n\r\n- for issues with a model report at https://discuss.huggingface.co/ and tag the model's creator.\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n\r\ntrainer: @sgugger, @patil-suraj\r\n\r\n## Information\r\n\r\nHi, I see this serious issue with trainer.py class, let please consider run_translation.py script [1] after you define the model, let freeze the encoder, or wrap the model in a class. So one can modify the model after this line https://github.com/huggingface/transformers/blob/d9c62047a8d75e18d2849d345ab3394875a712ef/examples/seq2seq/run_translation.py#L331 \r\n\r\nThen, during the training, one can stop the training, and now would like to continue the training from the place it is stopped, if you print the number of parameters inside trainer.py, right before this line:\r\n\r\nhttps://github.com/huggingface/transformers/blob/d9c62047a8d75e18d2849d345ab3394875a712ef/src/transformers/trainer.py#L1062\r\n\r\nlike this \r\n```\r\nfor n,p in model.named_parameters():\r\n   if p.requires_grad:\r\n       print(n)\r\n```\r\n\r\nwhat would we see? We see all parameters are there, even  the ones we made frozen, this is a serious bug that if the user modify the model after creation, those modifications are not considered when restarting the training, could you kindly have a look?\r\nthanks \r\n\r\n[1] https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_translation.py \r\n\r\n\r\n## Expected behavior\r\n\r\nThe user should be able to continue training the modified model as they are modified.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-768", "file_changes": [{"file": "sklearn/utils/arpack.py", "changes": {"edited_modules": ["sklearn/utils/arpack.py:svds", "sklearn/utils/arpack.py:eigs", "sklearn/utils/arpack.py:eigsh"], "edited_entities": ["sklearn/utils/arpack.py:svds", "sklearn/utils/arpack.py:eigs", "sklearn/utils/arpack.py:eigsh"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "0e8e38e3b2f4b79f03fe8a3e655b9f506ab0f2a6", "problem_statement": "Arpack wrappers fail with new scipy\n\nI have scipy 0.11.0.dev-c1ea274. This does not seem to play well with the current arpack wrappers.\nI'm a bit out of my depth there, though.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-21668", "file_changes": [{"file": "azure-pipelines.yml", "changes": {}}, {"file": "doc/computing/parallelism.rst", "changes": {}}, {"file": "sklearn/_build_utils/__init__.py", "changes": {"edited_modules": ["sklearn/_build_utils/__init__.py:cythonize_extensions"], "edited_entities": ["sklearn/_build_utils/__init__.py:cythonize_extensions"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "bb7e34bc52461749e6014787a05a9507eda11011", "problem_statement": "CI with boundscheck=False\n\nI really dislike segmentation faults! Unfortunately, there are many issues reporting them.\r\nFindings in #21654, #21283 were easier with setting `boundscheck = True`.\r\n\r\n**Proposition**\r\nSet up one CI configuration that runs with `boundscheck = True` globally which should be easier now that #21512 is merged.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-29358", "file_changes": [{"file": "doc/about.rst", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "64ab789905077ba8990522688c11177442e5e91f", "problem_statement": "Sprints page\n\n### Describe the issue linked to the documentation\n\nThe following sprints are listed: \r\nhttps://scikit-learn.org/stable/about.html#sprints\r\n\r\nBut, that is a small subset, given the list here: \r\nhttps://blog.scikit-learn.org/sprints/\r\n\r\nAre the sprints posted on the \"About Us\" page of a certain criteria, such as Dev sprints only?\n\n### Suggest a potential alternative/fix\n\n_No response_", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-5991", "file_changes": [{"file": "doc/whats_new.rst", "changes": {}}, {"file": "sklearn/model_selection/_split.py", "changes": {"edited_modules": ["sklearn/model_selection/_split.py:StratifiedShuffleSplit"], "edited_entities": ["sklearn/model_selection/_split.py:StratifiedShuffleSplit._iter_indices"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "41e129f1a6eb17a39ff0b25f682d903d0ae3c5af", "problem_statement": "PERF : StratifiedShuffleSplit is slow when using large number of classes\n\nWhen using large number of classes (e.g. > 10000, e.g for recommender systems), `StratifiedShuffleSplit` is very slow when compared to `ShuffleSplit`. Looking at the code, I believe that the following part: \n\n``` python\n            for i, class_i in enumerate(classes):\n                permutation = rng.permutation(class_counts[i])\n                perm_indices_class_i = np.where((y == class_i))[0][permutation]\n```\n\n`l. 1070` in `sklearn.model_selection._split` is suboptimal : we should build an index matrix holding the indices for each class in the dataset (implying to do a single pass over data, maybe along with a `bincount(classes)`). Indeed np.where does a pass over `y` at each call, leading to a `O(n_classes * len(y))` complexity, whereas it could be `O(len(y))` only.\n\nI obtain a significant gain in perf doing:\n\n``` python\n\n        class_indices = np.zeros((n_classes, class_counts.max()), dtype='int')\n        count = np.zeros(n_classes, dtype='int')\n        for i in range(len(y_indices)):\n            class_indices[y_indices[i], count[y_indices[i]]] = i\n            count[y_indices[i]] += 1\n```\n\nand subsequently replacing\n\n``` python\nperm_indices_class_i = np.where((y == class_i))[0][permutation]\n```\n\n by\n\n``` python\nperm_indices_class_i = class_indices[class_i,:class_counts[i]][permutation]\n```\n\nThis is suboptimal given we iterate over y values using within a Python loop. I believe that the proper way to do this would be to create a `bincount_with_ref` cython function that would both count the occurence of classes and accumulate class index in a  `class_indices` array - in `arrayfuncs.pyx`. Memory usage goes up of `len(y) * sizeof('int')`, which is typically small when compared to `X` size.\n\nWould this be useful ? I'll have to provide benchmarks !", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-10336", "file_changes": [{"file": "doc/whats_new/v0.20.rst", "changes": {}}, {"file": "sklearn/mixture/base.py", "changes": {"edited_modules": ["sklearn/mixture/base.py:BaseMixture"], "edited_entities": ["sklearn/mixture/base.py:BaseMixture.fit"]}}, {"file": "sklearn/mixture/tests/test_bayesian_mixture.py", "changes": {"edited_modules": ["sklearn/mixture/tests/test_bayesian_mixture.py:test_invariant_translation"], "edited_entities": ["sklearn/mixture/tests/test_bayesian_mixture.py:test_invariant_translation"]}}, {"file": "sklearn/mixture/tests/test_gaussian_mixture.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "4143356c3c51831300789e4fdf795d83716dbab6", "problem_statement": "Should mixture models have a clusterer-compatible interface\n\nMixture models are currently a bit different. They are basically clusterers, except they are probabilistic, and are applied to inductive problems unlike many clusterers. But they are unlike clusterers in API:\r\n* they have an `n_components` parameter, with identical purpose to `n_clusters`\r\n* they do not store the `labels_` of the training data\r\n* they do not have a `fit_predict` method\r\n\r\nAnd they are almost entirely documented separately.\r\n\r\nShould we make the MMs more like clusterers?", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-16001", "file_changes": [{"file": "doc/whats_new/v0.23.rst", "changes": {}}, {"file": "sklearn/datasets/_samples_generator.py", "changes": {"edited_modules": ["sklearn/datasets/_samples_generator.py:make_multilabel_classification"], "edited_entities": ["sklearn/datasets/_samples_generator.py:make_multilabel_classification"]}}, {"file": "sklearn/datasets/tests/test_samples_generator.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "d7795a431e30d23f7e8499bdbe89dbdc6e9a068e", "problem_statement": "Possible infinite loop iterations in synthetic data sets generation module\n\nHello,\r\n\r\nI found two code snippets in https://github.com/scikit-learn/scikit-learn/blob/7e85a6d1f/sklearn/datasets/_samples_generator.py are susceptible to infinite loop iterations when using make_multilabel_classification():\r\n\r\n1) https://github.com/scikit-learn/scikit-learn/blob/7e85a6d1f/sklearn/datasets/_samples_generator.py#L357\r\n\r\n2) https://github.com/scikit-learn/scikit-learn/blob/7e85a6d1f/sklearn/datasets/_samples_generator.py#L371\r\n\r\nThese happen when the parameters of make_multilabel_classification functions are EITHER (allowed_unlabeled = False and n_classes = 0) OR length = 0.\r\n\r\nI am using the version 0.20.3 of scikit-learn.\r\n\r\nPlease let me know if you have any questions about this.\r\nThank You", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-933", "file_changes": [{"file": "doc/whats_new.rst", "changes": {}}, {"file": "sklearn/ensemble/_gradient_boosting.c", "changes": {"edited_modules": ["sklearn/ensemble/_gradient_boosting.c:PyInit__gradient_boosting", "sklearn/ensemble/_gradient_boosting.c:__pyx_f_7sklearn_8ensemble_18_gradient_boosting__predict_regression_tree_inplace_fast", "sklearn/ensemble/_gradient_boosting.c:__Pyx_InitCachedBuiltins", "sklearn/ensemble/_gradient_boosting.c:__Pyx_InitCachedConstants", "sklearn/ensemble/_gradient_boosting.c:int"], "edited_entities": ["sklearn/ensemble/_gradient_boosting.c:PyInit__gradient_boosting", "sklearn/ensemble/_gradient_boosting.c:__pyx_f_7sklearn_8ensemble_18_gradient_boosting__predict_regression_tree_inplace_fast", "sklearn/ensemble/_gradient_boosting.c:__Pyx_InitCachedBuiltins", "sklearn/ensemble/_gradient_boosting.c:__Pyx_InitCachedConstants", "sklearn/ensemble/_gradient_boosting.c:int"]}}, {"file": "sklearn/ensemble/_gradient_boosting.pyx", "changes": {}}, {"file": "sklearn/ensemble/forest.py", "changes": {"edited_modules": ["sklearn/ensemble/forest.py:BaseForest", "sklearn/ensemble/forest.py:ForestClassifier", "sklearn/ensemble/forest.py:ForestRegressor"], "edited_entities": ["sklearn/ensemble/forest.py:BaseForest.fit", "sklearn/ensemble/forest.py:ForestClassifier.predict_proba", "sklearn/ensemble/forest.py:ForestRegressor.predict"]}}, {"file": "sklearn/ensemble/gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/gradient_boosting.py:LossFunction", "sklearn/ensemble/gradient_boosting.py:BaseGradientBoosting"], "edited_entities": ["sklearn/ensemble/gradient_boosting.py:LossFunction.update_terminal_regions", "sklearn/ensemble/gradient_boosting.py:BaseGradientBoosting.fit_stage"]}}, {"file": "sklearn/ensemble/tests/test_forest.py", "changes": {"edited_modules": ["sklearn/ensemble/tests/test_forest.py:test_probability", "sklearn/ensemble/tests/test_forest.py:test_multioutput"], "edited_entities": ["sklearn/ensemble/tests/test_forest.py:test_probability", "sklearn/ensemble/tests/test_forest.py:test_multioutput"]}}, {"file": "sklearn/ensemble/tests/test_gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/tests/test_gradient_boosting.py:test_feature_importances"], "edited_entities": ["sklearn/ensemble/tests/test_gradient_boosting.py:test_feature_importances"]}}, {"file": "sklearn/tree/_tree.pyx", "changes": {}}, {"file": "sklearn/tree/tests/test_tree.py", "changes": {"edited_modules": ["sklearn/tree/tests/test_tree.py:test_numerical_stability", "sklearn/tree/tests/test_tree.py:test_min_samples_leaf"], "edited_entities": ["sklearn/tree/tests/test_tree.py:test_numerical_stability", "sklearn/tree/tests/test_tree.py:test_min_samples_leaf"]}}, {"file": "sklearn/tree/tree.py", "changes": {"edited_modules": ["sklearn/tree/tree.py:node_to_str", "sklearn/tree/tree.py:BaseDecisionTree", "sklearn/tree/tree.py:recurse", "sklearn/tree/tree.py:Tree", "sklearn/tree/tree.py:DecisionTreeClassifier", "sklearn/tree/tree.py:ExtraTreeClassifier", "sklearn/tree/tree.py:ExtraTreeRegressor"], "edited_entities": ["sklearn/tree/tree.py:node_to_str", "sklearn/tree/tree.py:BaseDecisionTree.fit", "sklearn/tree/tree.py:recurse", "sklearn/tree/tree.py:Tree", "sklearn/tree/tree.py:BaseDecisionTree.__init__", "sklearn/tree/tree.py:BaseDecisionTree.predict", "sklearn/tree/tree.py:DecisionTreeClassifier.predict_proba", "sklearn/tree/tree.py:ExtraTreeClassifier.__init__", "sklearn/tree/tree.py:ExtraTreeRegressor.__init__"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "0e3cbbdcdfeec1c6b10aea11524add6350a8f4e0", "problem_statement": "Speed up tree construction\n\nCC: @pprett @amueller @bdholt1 \n\nHi folks,\n\nEveryone will agree that tree-based methods have shown to perform quite well (e.g., the recent achievement of Peter!) and are increasingly used by our users. However, the tree module still has a major drawback: it is slow as hell in comparison to other machine learning packages. \n\nFor that reason, I think we should put some more effort into accelerating the tree module. In particular, I would like to suggest to move the whole `Tree` class (not the estimators,  but only our struct-of-arrays representation) from tree.py into Cython in _tree.pyx. First the code would be a lot faster. But second, it could also actually be more readable and maintainable if the whole tree construction process was packaged into a single file, in a single class. Currently, the construction process is indeed split across 2 files, estimator classes, the Tree class and all the Cython routines. (imo, this is a mess.)\n\nTo show that indeed the construction process could be a lot faster, I profiled `recursive_partition` using  line-profiler (see link below). Insignicant Python instructions do actually take quite some time in comparison to the important parts of the algorithm. E.g., line 314 vs line 320. A mere Python if-statement is only twice faster than finding the best threshold!!! \n\nI let you examine  the rest of the profiling report by yourself, but as far as I am concerned, I am convinced that we could indeed significantly speed up the tree module (and be 5-10x faster at least). \n\nhttp://pastebin.com/0rC1QmPy (toggle text warping)\n\nWhat's your opinion about this? Since I am increasingly using the module myself, I can actually work on that  in the days to come.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-27982", "file_changes": [{"file": "sklearn/datasets/_samples_generator.py", "changes": {"edited_modules": ["sklearn/datasets/_samples_generator.py:make_low_rank_matrix"], "edited_entities": ["sklearn/datasets/_samples_generator.py:make_low_rank_matrix"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "77aeb825b6494de1e3a2c1e7233b182e05d55ab0", "problem_statement": "Ensure that we have an example in the docstring of each public function or class\n\nWe should make sure that we have a small example for all public functions or classes. Most of the missing examples are linked to functions.\r\n\r\nI could list the following classes and functions for which `numpydoc` did not find any example:\r\n\r\n- [x] sklearn.base.BaseEstimator\r\n- [x] sklearn.base.BiclusterMixin\r\n- [x] sklearn.base.ClassNamePrefixFeaturesOutMixin\r\n- [x] sklearn.base.ClassifierMixin\r\n- [x] sklearn.base.ClusterMixin\r\n- [x] sklearn.base.DensityMixin\r\n- [x] sklearn.base.MetaEstimatorMixin\r\n- [x] sklearn.base.OneToOneFeatureMixin\r\n- [x] sklearn.base.OutlierMixin\r\n- [x] sklearn.base.RegressorMixin\r\n- [x] sklearn.base.TransformerMixin\r\n- [x] sklearn.base.clone\r\n- [x] sklearn.base.is_classifier\r\n- [x] sklearn.base.is_regressor\r\n- [x] sklearn.cluster.affinity_propagation\r\n- [x] sklearn.cluster.cluster_optics_dbscan\r\n- [x] sklearn.cluster.cluster_optics_xi\r\n- [x] sklearn.cluster.compute_optics_graph\r\n- [x] sklearn.cluster.estimate_bandwidth\r\n- [x] sklearn.cluster.k_means\r\n- [x] sklearn.cluster.mean_shift\r\n- [x] sklearn.cluster.spectral_clustering\r\n- [x] sklearn.cluster.ward_tree\r\n- [x] sklearn.covariance.graphical_lasso\r\n- [x] sklearn.covariance.ledoit_wolf\r\n- [x] sklearn.covariance.ledoit_wolf_shrinkage\r\n- [x] sklearn.covariance.shrunk_covariance\r\n- [x] sklearn.datasets.clear_data_home\r\n- [x] sklearn.datasets.dump_svmlight_file\r\n- [x] sklearn.datasets.fetch_20newsgroups\r\n- [x] sklearn.datasets.fetch_20newsgroups_vectorized\r\n- [x] sklearn.datasets.fetch_california_housing\r\n- [x] sklearn.datasets.fetch_covtype\r\n- [x] sklearn.datasets.fetch_kddcup99\r\n- [x] sklearn.datasets.fetch_lfw_pairs\r\n- [x] sklearn.datasets.fetch_lfw_people\r\n- [x] sklearn.datasets.fetch_olivetti_faces\r\n- [x] sklearn.datasets.fetch_openml\r\n- [x] sklearn.datasets.fetch_rcv1\r\n- [x] sklearn.datasets.fetch_species_distributions\r\n- [x] sklearn.datasets.get_data_home\r\n- [x] sklearn.datasets.load_diabetes\r\n- [x] sklearn.datasets.load_files\r\n- [x] sklearn.datasets.load_linnerud\r\n- [x] sklearn.datasets.load_svmlight_files\r\n- [x] sklearn.datasets.make_biclusters\r\n- [x] sklearn.datasets.make_checkerboard\r\n- [x] sklearn.datasets.make_circles\r\n- [x] sklearn.datasets.make_classification\r\n- [x] sklearn.datasets.make_friedman1\r\n- [x] sklearn.datasets.make_friedman2\r\n- [x] sklearn.datasets.make_friedman3\r\n- [x] sklearn.datasets.make_gaussian_quantiles\r\n- [x] sklearn.datasets.make_hastie_10_2\r\n- [x] sklearn.datasets.make_low_rank_matrix\r\n- [x] sklearn.datasets.make_moons\r\n- [x] sklearn.datasets.make_multilabel_classification\r\n- [x] sklearn.datasets.make_s_curve\r\n- [x] sklearn.datasets.make_sparse_coded_signal\r\n- [x] sklearn.datasets.make_sparse_spd_matrix\r\n- [x] sklearn.datasets.make_sparse_uncorrelated\r\n- [x] sklearn.datasets.make_spd_matrix\r\n- [x] sklearn.datasets.make_swiss_roll\r\n- [x] sklearn.decomposition.dict_learning\r\n- [x] sklearn.decomposition.dict_learning_online\r\n- [x] sklearn.decomposition.sparse_encode\r\n- [x] sklearn.feature_extraction.image.grid_to_graph\r\n- [x] sklearn.feature_extraction.image.img_to_graph\r\n- [x] sklearn.feature_extraction.image.reconstruct_from_patches_2d\r\n- [x] sklearn.feature_selection.SelectorMixin\r\n- [x] sklearn.feature_selection.chi2\r\n- [x] sklearn.feature_selection.f_classif\r\n- [x] sklearn.feature_selection.f_regression\r\n- [x] sklearn.feature_selection.mutual_info_classif\r\n- [x] sklearn.feature_selection.mutual_info_regression\r\n- [x] sklearn.feature_selection.r_regression\r\n- [x] sklearn.gaussian_process.kernels.Kernel\r\n- [x] sklearn.get_config\r\n- [x] sklearn.isotonic.check_increasing\r\n- [x] sklearn.isotonic.isotonic_regression\r\n- [x] sklearn.linear_model.enet_path\r\n- [x] sklearn.linear_model.lars_path\r\n- [x] sklearn.linear_model.lars_path_gram\r\n- [x] sklearn.linear_model.orthogonal_mp\r\n- [x] sklearn.linear_model.orthogonal_mp_gram\r\n- [x] sklearn.linear_model.ridge_regression\r\n- [x] sklearn.manifold.locally_linear_embedding\r\n- [x] sklearn.manifold.smacof\r\n- [x] sklearn.manifold.spectral_embedding\r\n- [x] sklearn.manifold.trustworthiness\r\n- [x] sklearn.metrics.calinski_harabasz_score\r\n- [x] sklearn.metrics.check_scoring\r\n- [x] sklearn.metrics.cohen_kappa_score\r\n- [x] sklearn.metrics.consensus_score\r\n- [x] sklearn.metrics.coverage_error\r\n- [x] sklearn.metrics.davies_bouldin_score\r\n- [x] sklearn.metrics.get_scorer\r\n- [x] sklearn.metrics.get_scorer_names\r\n- [x] sklearn.metrics.homogeneity_completeness_v_measure\r\n- [x] sklearn.metrics.label_ranking_loss\r\n- [x] sklearn.metrics.mutual_info_score\r\n- [x] sklearn.metrics.pairwise.additive_chi2_kernel\r\n- [x] sklearn.metrics.pairwise.chi2_kernel\r\n- [x] sklearn.metrics.pairwise.cosine_distances\r\n- [x] sklearn.metrics.pairwise.cosine_similarity\r\n- [x] sklearn.metrics.pairwise.distance_metrics\r\n- [x] sklearn.metrics.pairwise.kernel_metrics\r\n- [x] sklearn.metrics.pairwise.laplacian_kernel\r\n- [x] sklearn.metrics.pairwise.linear_kernel\r\n- [x] sklearn.metrics.pairwise.paired_cosine_distances\r\n- [x] sklearn.metrics.pairwise.paired_euclidean_distances\r\n- [x] sklearn.metrics.pairwise.pairwise_kernels\r\n- [x] sklearn.metrics.pairwise.polynomial_kernel\r\n- [x] sklearn.metrics.pairwise.rbf_kernel\r\n- [x] sklearn.metrics.pairwise.sigmoid_kernel\r\n- [x] sklearn.metrics.pairwise_distances\r\n- [x] sklearn.metrics.pairwise_distances_argmin\r\n- [x] sklearn.metrics.pairwise_distances_argmin_min\r\n- [x] sklearn.metrics.silhouette_samples\r\n- [x] sklearn.metrics.silhouette_score\r\n- [x] sklearn.model_selection.check_cv\r\n- [x] sklearn.model_selection.permutation_test_score\r\n- [x] sklearn.model_selection.validation_curve\r\n- [x] sklearn.neighbors.sort_graph_by_row_values\r\n- [x] sklearn.preprocessing.binarize\r\n- [x] sklearn.preprocessing.maxabs_scale\r\n- [x] sklearn.preprocessing.minmax_scale\r\n- [x] sklearn.preprocessing.normalize\r\n- [x] sklearn.preprocessing.robust_scale\r\n- [x] sklearn.preprocessing.scale\r\n- [x] sklearn.set_config\r\n- [x] sklearn.show_versions\r\n- [x] sklearn.svm.l1_min_c\r\n- [x] sklearn.utils._safe_indexing\r\n- [x] sklearn.utils.arrayfuncs.min_pos\r\n- [x] sklearn.utils.as_float_array\r\n- [x] sklearn.utils.assert_all_finite\r\n- [x] sklearn.utils.check_X_y\r\n- [x] sklearn.utils.check_array\r\n- [x] sklearn.utils.check_consistent_length\r\n- [x] sklearn.utils.check_random_state\r\n- [x] sklearn.utils.check_scalar\r\n- [x] sklearn.utils.class_weight.compute_class_weight\r\n- [x] sklearn.utils.class_weight.compute_sample_weight\r\n- [x] sklearn.utils.deprecated\r\n- [x] sklearn.utils.discovery.all_displays\r\n- [x] sklearn.utils.discovery.all_estimators\r\n- [x] sklearn.utils.discovery.all_functions\r\n- [x] sklearn.utils.estimator_checks.check_estimator\r\n- [x] sklearn.utils.estimator_html_repr\r\n- [x] sklearn.utils.extmath.density\r\n- [x] sklearn.utils.extmath.randomized_range_finder\r\n- [x] sklearn.utils.extmath.safe_sparse_dot\r\n- [x] sklearn.utils.indexable\r\n- [x] sklearn.utils.metadata_routing.MetadataRequest\r\n- [x] sklearn.utils.metadata_routing.MetadataRouter\r\n- [x] sklearn.utils.metadata_routing.MethodMapping\r\n- [x] sklearn.utils.metadata_routing.get_routing_for_object\r\n- [x] sklearn.utils.metadata_routing.process_routing\r\n- [x] sklearn.utils.murmurhash3_32\r\n- [x] sklearn.utils.parallel.Parallel\r\n- [x] sklearn.utils.parallel.delayed\r\n- [x] sklearn.utils.parallel_backend\r\n- [x] sklearn.utils.random.sample_without_replacement\r\n- [x] sklearn.utils.register_parallel_backend\r\n- [x] sklearn.utils.safe_mask\r\n- [x] sklearn.utils.safe_sqr\r\n- [x] sklearn.utils.sparsefuncs.incr_mean_variance_axis\r\n- [x] sklearn.utils.sparsefuncs.inplace_column_scale\r\n- [x] sklearn.utils.sparsefuncs.inplace_csr_column_scale\r\n- [x] sklearn.utils.sparsefuncs.inplace_row_scale\r\n- [x] sklearn.utils.sparsefuncs.inplace_swap_column\r\n- [x] sklearn.utils.sparsefuncs.inplace_swap_row\r\n- [x] sklearn.utils.sparsefuncs.mean_variance_axis\r\n- [x] sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1\r\n- [x] sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2\r\n- [x] sklearn.utils.validation.check_is_fitted\r\n- [x] sklearn.utils.validation.check_memory\r\n- [x] sklearn.utils.validation.check_symmetric\r\n- [x] sklearn.utils.validation.column_or_1d\r\n\r\nThe code used to find the list above is detailed below:\r\n\r\n<details>\r\n\r\n```python\r\nimport importlib\r\nimport inspect\r\nfrom pathlib import Path\r\n\r\nfrom numpydoc.docscrape import NumpyDocString\r\n\r\npath_sklearn_doc = Path(\r\n    \"/{path_to_git_repo}/scikit-learn/doc/_build/html/stable/\"\r\n    \"modules/generated\"\r\n)\r\n\r\nmissing_examples_name = []\r\nfor document in path_sklearn_doc.glob(\"*.html\"):\r\n    extracted_doc = []\r\n    full_name = document.stem\r\n    try:\r\n        module_name, class_or_function_name = full_name.rsplit(\".\", maxsplit=1)\r\n        module = importlib.import_module(module_name)\r\n        class_or_function = getattr(module, class_or_function_name)\r\n    except (ValueError, AttributeError, ImportError):\r\n        # This is due to the experimental module and function with\r\n        # module name\r\n        continue\r\n    is_class = inspect.isclass(class_or_function)\r\n    docstring = NumpyDocString(class_or_function.__doc__)\r\n    if not docstring[\"Examples\"]:\r\n        missing_examples_name.append(full_name)\r\n\r\nfor full_name in sorted(missing_examples_name):\r\n    print(f\"- [ ] {full_name}\")\r\n```\r\n\r\n</details>", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-19269", "file_changes": [{"file": "doc/whats_new/v1.1.rst", "changes": {}}, {"file": "sklearn/datasets/_base.py", "changes": {"edited_modules": ["sklearn/datasets/_base.py:load_files"], "edited_entities": ["sklearn/datasets/_base.py:load_files"]}}, {"file": "sklearn/datasets/tests/test_base.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "e11c4d21a4579f0d49f414a4b76e386f80f0f074", "problem_statement": "sklearn.datasets.load_files select file extension\n\n<!--\r\nIf you want to propose a new algorithm, please refer first to the scikit-learn\r\ninclusion criterion:\r\nhttps://scikit-learn.org/stable/faq.html#what-are-the-inclusion-criteria-for-new-algorithms\r\n-->\r\n\r\n#### Describe the workflow you want to enable\r\nWhen using load_files in a directory where there are different kinds of files (.txt, .png, ...), the user might want to load only certain files (*.txt for example). This feature would put load_files closer to the function `index_directory` from tensorflow.python.keras.preprocessing.dataset_utils.py. \r\n\r\n\r\nFor MacOs users, .DStore files also gets loaded which is an undesired behaviour.\r\n\r\n#### Describe your proposed solution\r\nAdd an argument to select the types of files to load.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-8364", "file_changes": [{"file": "examples/svm/plot_separating_hyperplane.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "cdd693bf955acd2a97cce48011d168c6b1ef316d", "problem_statement": "Matplotlib update on CI makes example look different\n\nThe examples look different on the current dev website, in particular the classifier comparison that's on the landing pages looks a bit odd now:\r\nhttp://scikit-learn.org/dev/auto_examples/classification/plot_classifier_comparison.html\r\n\r\nI suspect the culprit is the CI upgrading to matplotlib v2. I think we should go through the examples and see how they are holding up with the new styles.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-15005", "file_changes": [{"file": "sklearn/datasets/_base.py", "changes": {"edited_modules": ["sklearn/datasets/_base.py:load_files", "sklearn/datasets/_base.py:load_wine", "sklearn/datasets/_base.py:load_iris", "sklearn/datasets/_base.py:load_breast_cancer", "sklearn/datasets/_base.py:load_digits", "sklearn/datasets/_base.py:load_diabetes", "sklearn/datasets/_base.py:load_linnerud", "sklearn/datasets/_base.py:load_boston"], "edited_entities": ["sklearn/datasets/_base.py:load_files", "sklearn/datasets/_base.py:load_wine", "sklearn/datasets/_base.py:load_iris", "sklearn/datasets/_base.py:load_breast_cancer", "sklearn/datasets/_base.py:load_digits", "sklearn/datasets/_base.py:load_diabetes", "sklearn/datasets/_base.py:load_linnerud", "sklearn/datasets/_base.py:load_boston"]}}, {"file": "sklearn/datasets/_california_housing.py", "changes": {"edited_modules": ["sklearn/datasets/_california_housing.py:fetch_california_housing"], "edited_entities": ["sklearn/datasets/_california_housing.py:fetch_california_housing"]}}, {"file": "sklearn/datasets/_covtype.py", "changes": {"edited_modules": ["sklearn/datasets/_covtype.py:fetch_covtype"], "edited_entities": ["sklearn/datasets/_covtype.py:fetch_covtype"]}}, {"file": "sklearn/datasets/_kddcup99.py", "changes": {"edited_modules": ["sklearn/datasets/_kddcup99.py:fetch_kddcup99"], "edited_entities": ["sklearn/datasets/_kddcup99.py:fetch_kddcup99"]}}, {"file": "sklearn/datasets/_lfw.py", "changes": {"edited_modules": ["sklearn/datasets/_lfw.py:fetch_lfw_people", "sklearn/datasets/_lfw.py:fetch_lfw_pairs"], "edited_entities": ["sklearn/datasets/_lfw.py:fetch_lfw_people", "sklearn/datasets/_lfw.py:fetch_lfw_pairs"]}}, {"file": "sklearn/datasets/_olivetti_faces.py", "changes": {"edited_modules": ["sklearn/datasets/_olivetti_faces.py:fetch_olivetti_faces"], "edited_entities": ["sklearn/datasets/_olivetti_faces.py:fetch_olivetti_faces"]}}, {"file": "sklearn/datasets/_openml.py", "changes": {"edited_modules": ["sklearn/datasets/_openml.py:fetch_openml"], "edited_entities": ["sklearn/datasets/_openml.py:fetch_openml"]}}, {"file": "sklearn/datasets/_rcv1.py", "changes": {"edited_modules": ["sklearn/datasets/_rcv1.py:fetch_rcv1"], "edited_entities": ["sklearn/datasets/_rcv1.py:fetch_rcv1"]}}, {"file": "sklearn/datasets/_samples_generator.py", "changes": {"edited_modules": ["sklearn/datasets/_samples_generator.py:make_classification", "sklearn/datasets/_samples_generator.py:make_multilabel_classification", "sklearn/datasets/_samples_generator.py:make_hastie_10_2", "sklearn/datasets/_samples_generator.py:make_regression", "sklearn/datasets/_samples_generator.py:make_circles", "sklearn/datasets/_samples_generator.py:make_moons", "sklearn/datasets/_samples_generator.py:make_blobs", "sklearn/datasets/_samples_generator.py:make_friedman1", "sklearn/datasets/_samples_generator.py:make_friedman2", "sklearn/datasets/_samples_generator.py:make_friedman3", "sklearn/datasets/_samples_generator.py:make_low_rank_matrix", "sklearn/datasets/_samples_generator.py:make_sparse_coded_signal", "sklearn/datasets/_samples_generator.py:make_sparse_uncorrelated", "sklearn/datasets/_samples_generator.py:make_spd_matrix", "sklearn/datasets/_samples_generator.py:make_sparse_spd_matrix", "sklearn/datasets/_samples_generator.py:make_swiss_roll", "sklearn/datasets/_samples_generator.py:make_s_curve", "sklearn/datasets/_samples_generator.py:make_gaussian_quantiles", "sklearn/datasets/_samples_generator.py:make_biclusters", "sklearn/datasets/_samples_generator.py:make_checkerboard"], "edited_entities": ["sklearn/datasets/_samples_generator.py:make_classification", "sklearn/datasets/_samples_generator.py:make_multilabel_classification", "sklearn/datasets/_samples_generator.py:make_hastie_10_2", "sklearn/datasets/_samples_generator.py:make_regression", "sklearn/datasets/_samples_generator.py:make_circles", "sklearn/datasets/_samples_generator.py:make_moons", "sklearn/datasets/_samples_generator.py:make_blobs", "sklearn/datasets/_samples_generator.py:make_friedman1", "sklearn/datasets/_samples_generator.py:make_friedman2", "sklearn/datasets/_samples_generator.py:make_friedman3", "sklearn/datasets/_samples_generator.py:make_low_rank_matrix", "sklearn/datasets/_samples_generator.py:make_sparse_coded_signal", "sklearn/datasets/_samples_generator.py:make_sparse_uncorrelated", "sklearn/datasets/_samples_generator.py:make_spd_matrix", "sklearn/datasets/_samples_generator.py:make_sparse_spd_matrix", "sklearn/datasets/_samples_generator.py:make_swiss_roll", "sklearn/datasets/_samples_generator.py:make_s_curve", "sklearn/datasets/_samples_generator.py:make_gaussian_quantiles", "sklearn/datasets/_samples_generator.py:make_biclusters", "sklearn/datasets/_samples_generator.py:make_checkerboard"]}}, {"file": "sklearn/datasets/_species_distributions.py", "changes": {"edited_modules": ["sklearn/datasets/_species_distributions.py:fetch_species_distributions"], "edited_entities": ["sklearn/datasets/_species_distributions.py:fetch_species_distributions"]}}, {"file": "sklearn/datasets/_svmlight_format_io.py", "changes": {"edited_modules": ["sklearn/datasets/_svmlight_format_io.py:load_svmlight_file", "sklearn/datasets/_svmlight_format_io.py:load_svmlight_files", "sklearn/datasets/_svmlight_format_io.py:dump_svmlight_file"], "edited_entities": ["sklearn/datasets/_svmlight_format_io.py:load_svmlight_file", "sklearn/datasets/_svmlight_format_io.py:load_svmlight_files", "sklearn/datasets/_svmlight_format_io.py:dump_svmlight_file"]}}, {"file": "sklearn/datasets/_twenty_newsgroups.py", "changes": {"edited_modules": ["sklearn/datasets/_twenty_newsgroups.py:fetch_20newsgroups", "sklearn/datasets/_twenty_newsgroups.py:fetch_20newsgroups_vectorized"], "edited_entities": ["sklearn/datasets/_twenty_newsgroups.py:fetch_20newsgroups", "sklearn/datasets/_twenty_newsgroups.py:fetch_20newsgroups_vectorized"]}}, {"file": "sklearn/datasets/tests/test_base.py", "changes": {"edited_modules": ["sklearn/datasets/tests/test_base.py:test_load_digits_n_class_lt_10"], "edited_entities": ["sklearn/datasets/tests/test_base.py:test_load_digits_n_class_lt_10"]}}, {"file": "sklearn/linear_model/tests/test_omp.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "839b356f45fac7724eab739dcc129a0c8f650a23", "problem_statement": "Implement SLEP009: keyword-only arguments\n\n[SLEP009](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep009/proposal.html) is all but accepted.\r\n\r\nIt proposes to make most parameters keyword-only.\r\n\r\nWe should do this by first:\r\n* [x] Merging #13311 \r\n* [x] Perhaps getting some stats on usage of positional arguments as per https://github.com/scikit-learn/enhancement_proposals/pull/19#issuecomment-514671933\r\n* [ ] applying the deprecation to each subpackage. Checked means PR opened at least.\r\n  * [x] base\r\n  * [x] calibration\r\n  * [x] cluster\r\n  * [x] compose\r\n  * [x] covariance\r\n  * [x] cross_decomposition\r\n  * [x] datasets\r\n  * [x] decomposition\r\n  * [x] discriminant_analysis\r\n  * [x] dummy\r\n  * [x] ensemble\r\n  * [x] feature_extraction\r\n  * [x] feature_selection\r\n  * [x] gaussian_process\r\n  * [x] impute\r\n  * [x] inspection\r\n  * [x] isotonic\r\n  * [x] kernel_approximation\r\n  * [x] kernel_ridge\r\n  * [x] linear_model\r\n  * [x] manifold\r\n  * [x] metrics\r\n  * [x] metrics.pairwise\r\n  * [x] mixture\r\n  * [x] model_selection\r\n  * [x] multiclass\r\n  * [x] multioutput\r\n  * [x] naive_bayes\r\n  * [x] neighbors\r\n  * [x] neural_network\r\n  * [x] pipeline\r\n  * [x] preprocessing\r\n  * [x] random_projection\r\n  * [x] semi_supervised\r\n  * [x] svm\r\n  * [x] tree\r\n  * [x] utils\r\n\r\n\r\nWe might along the way establish rules of thumb and principles like  \"are the semantics reasonably clear when the argument is passed positionally?\" As I noted on the mailing list, I think they are clear for PCA's components, for Pipeline's steps, and for GridSearchCV's estimator and parameter grid. Other parameters of those estimators seem more suitable for keyword-only. Trickier is whether n_components in TSNE should follow PCA in being positional... It's not as commonly set by users.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-12779", "file_changes": [{"file": "sklearn/utils/_random.pyx", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "62d205980446a1abc1065f4332fd74eee57fcf73", "problem_statement": "Remove \"from __future__ import XXX\"\n\nGiven #12746, I think we should remove ``from __future__ import XXX``, right? @adrinjalali \r\n```\r\n$ git grep \"from __future__ import\" | wc -l\r\n147\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-12306", "file_changes": [{"file": "sklearn/impute/_base.py", "changes": {"edited_modules": ["sklearn/impute/_base.py:SimpleImputer"], "edited_entities": ["sklearn/impute/_base.py:SimpleImputer"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "45019594938f92f3344c80bb0d351793dd91334b", "problem_statement": "SimpleImputer to Crash on Constant Imputation with string value when dataset is encoded Numerically\n\n#### Description\r\nThe title kind of describes it. It might be pretty logical, but just putting it out here as it took a while for me to realize and debug what exactly happened. \r\n\r\nThe SimpleImputer has the ability to impute missing values with a constant. If the data is categorical, it is possible to impute with a string value. However, when fetching a dataset from OpenML (or many other datasets from different sources) the data is encoded numerically automatically as numeric. When applying the SimpleImputer and a string value, scikit-learn crashes. I assume there's not a lot that can be done about this, as everything behaves exactly as you would expect when you dive deep into the code, but maybe the documentation can be extended a little bit (probably on SimpleImputer side, or maybe on the side of the data sources). \r\n\r\nWhat do you think?\r\n\r\n#### Steps/Code to Reproduce\r\n```\r\nimport numpy as np\r\nimport sklearn.datasets\r\nimport sklearn.compose\r\nimport sklearn.tree\r\nimport sklearn.impute\r\n\r\nX, y = sklearn.datasets.fetch_openml('Australian', 4, return_X_y=True)\r\n\r\nnumeric_imputer = sklearn.impute.SimpleImputer(strategy='mean')\r\nnumeric_scaler = sklearn.preprocessing.StandardScaler()\r\n\r\nnominal_imputer = sklearn.impute.SimpleImputer(strategy='constant', fill_value='missing')\r\nnominal_encoder = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')\r\n\r\nnumeric_idx = [1, 2, 7, 10, 13]\r\nnominal_idx = [0, 3, 4, 5, 6, 8, 9, 11, 12]\r\n\r\nprint('missing numeric vals:', np.count_nonzero(~np.isnan(X[:, numeric_idx])))\r\nprint('missing nominal vals:', np.count_nonzero(~np.isnan(X[:, nominal_idx])))\r\n\r\n\r\nclf_nom = sklearn.pipeline.make_pipeline(nominal_imputer, nominal_encoder)\r\nclf_nom.fit(X[:, nominal_idx], y)\r\n```\r\n\r\n#### Expected Results\r\nA fitted classifier? Depending on how you write the documentation, the current error could also be the expected result. \r\n\r\n#### Actual Results\r\n```\r\nmissing numeric vals: 3450\r\nmissing nominal vals: 6210\r\nTraceback (most recent call last):\r\n  File \"/home/janvanrijn/projects/sklearn-bot/testjan.py\", line 23, in <module>\r\n    clf_nom.fit(X[:, nominal_idx], y)\r\n  File \"/home/janvanrijn/anaconda3/envs/sklearn-bot/lib/python3.6/site-packages/sklearn/pipeline.py\", line 265, in fit\r\n    Xt, fit_params = self._fit(X, y, **fit_params)\r\n  File \"/home/janvanrijn/anaconda3/envs/sklearn-bot/lib/python3.6/site-packages/sklearn/pipeline.py\", line 230, in _fit\r\n    **fit_params_steps[name])\r\n  File \"/home/janvanrijn/anaconda3/envs/sklearn-bot/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 329, in __call__\r\n    return self.func(*args, **kwargs)\r\n  File \"/home/janvanrijn/anaconda3/envs/sklearn-bot/lib/python3.6/site-packages/sklearn/pipeline.py\", line 614, in _fit_transform_one\r\n    res = transformer.fit_transform(X, y, **fit_params)\r\n  File \"/home/janvanrijn/anaconda3/envs/sklearn-bot/lib/python3.6/site-packages/sklearn/base.py\", line 465, in fit_transform\r\n    return self.fit(X, y, **fit_params).transform(X)\r\n  File \"/home/janvanrijn/anaconda3/envs/sklearn-bot/lib/python3.6/site-packages/sklearn/impute.py\", line 241, in fit\r\n    \"data\".format(fill_value))\r\nValueError: 'fill_value'=missing is invalid. Expected a numerical value when imputing numerical data\r\n```\r\n\r\n#### Versions\r\n```\r\nPython=3.6.0\r\nnumpy==1.15.2\r\nscikit-learn==0.20.0\r\nscipy==1.1.0\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-16556", "file_changes": [{"file": "doc/whats_new/v1.1.rst", "changes": {}}, {"file": "sklearn/ensemble/_stacking.py", "changes": {"edited_modules": ["sklearn/ensemble/_stacking.py:StackingClassifier", "sklearn/ensemble/_stacking.py:StackingRegressor", "sklearn/ensemble/_stacking.py:_BaseStacking"], "edited_entities": ["sklearn/ensemble/_stacking.py:StackingClassifier", "sklearn/ensemble/_stacking.py:StackingRegressor", "sklearn/ensemble/_stacking.py:_BaseStacking.fit"]}}, {"file": "sklearn/ensemble/tests/test_stacking.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "5ad3421a5b5759ecfaaab93406592d988f5d487f", "problem_statement": "Add Pre-fit Model to Stacking Model\n\n<!--\r\nIf you want to propose a new algorithm, please refer first to the scikit-learn\r\ninclusion criterion:\r\nhttps://scikit-learn.org/stable/faq.html#what-are-the-inclusion-criteria-for-new-algorithms\r\n-->\r\n\r\n#### Describe the workflow you want to enable\r\n\r\nAllow pre-fit models to stacking model such as `StackingClassifier` and `StackingRegressor` so that the final estimator can use their predictions directly without fitting the model on the given training data. \r\n\r\nThe motivation for this functionality originates from situation in which it is not possible to fit model on the entire dataset (due to compliance or other non-technical restrictions) or simply a research question to test with different models trained on different data. I feel this added flexibility could be beneficial in the long term. \r\n\r\n#### Describe your proposed solution\r\n\r\nOne possible solution I have in mind is to exclude fitted estimators during fitting. We can iterate through the list of estimators and see if they have been fitted (which sklearn already has helper functions). If yes, we skip them when fitting the estimators. \r\n\r\n#### Describe alternatives you've considered, if relevant\r\n\r\nAnother option I thought about was to ask users to specify if they want to exclude fitting certain estimators. But in this case, I feel it is safer to check the estimators' status regardless, which makes the manual input somewhat redundant.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-7603", "file_changes": [{"file": "sklearn/tree/tests/test_tree.py", "changes": {"edited_modules": ["sklearn/tree/tests/test_tree.py:test_error"], "edited_entities": ["sklearn/tree/tests/test_tree.py:test_error"]}}, {"file": "sklearn/tree/tree.py", "changes": {"edited_modules": ["sklearn/tree/tree.py:BaseDecisionTree"], "edited_entities": ["sklearn/tree/tree.py:BaseDecisionTree.fit"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "9b2aac9e5c8749243c73f2377519d2f2c407b095", "problem_statement": "When min_samples_split and min_samples_leaf are greater than or equal to 1.0 and 0.5, no error is thrown.\n\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\n#### Description\n\nThis is a silent bug in version 0.18.0, as a result of the following change: \"Random forest, extra trees, decision trees and gradient boosting estimator accept the parameter min_samples_split and min_samples_leaf provided as a percentage of the training samples. By yelite and Arnaud Joly.\"\n\nThe bug is that no error is thrown when large float values are passed. In theory, it would be useless to set `min_samples_split` to 1.0 or more, or `min_samples_leaf` to 0.5 or more. For example, `min_samples_split=2` gives a very different result compared with `min_samples_split=2.0`. In this case, accidentally setting `min_samples_split=2.0` in 0.18.0 would produce a tree with no splits. In this example, the error would be completely silent, and difficult to debug. This would probably be an unexpected outcome, especially for users coming from version 0.17.1, where these two values (`2.0` and `2`) would behave identically.\n#### Steps/Code to Reproduce\n\nExample:\n\n```\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX, y = iris.data[:, [0,1,2]], iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n\nrf = RandomForestClassifier(n_estimators=5, min_samples_leaf=3.0)\nrf.fit(X_train, y_train)\nprint \"rf score %s\" % rf.score(X_test, y_test)\n```\n#### Expected Results\n\nThe RandomForestClassifier scores in the ~0.9 range in 0.17.1, and I believe an error should be thrown in 0.18.0.\n#### Actual Results\n\nThe RandomForestClassifier scores in the ~0.3 range in 0.18.0, with no error thrown.\n#### Versions\n\n```\nDarwin-15.6.0-x86_64-i386-64bit\n('Python', '2.7.11 (default, Jan 22 2016, 08:29:18) \\n[GCC 4.2.1 Compatible Apple LLVM 7.0.2 (clang-700.1.81)]')\n('NumPy', '1.11.2')\n('SciPy', '0.17.0')\n('Scikit-Learn', '0.18')\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-11568", "file_changes": [{"file": "doc/modules/classes.rst", "changes": {}}, {"file": "sklearn/cluster/__init__.py", "changes": {}}, {"file": "sklearn/cluster/dbscan_.py", "changes": {"edited_modules": ["sklearn/cluster/dbscan_.py:dbscan"], "edited_entities": ["sklearn/cluster/dbscan_.py:dbscan"]}}, {"file": "sklearn/cluster/optics_.py", "changes": {"edited_modules": ["sklearn/cluster/optics_.py:optics"], "edited_entities": ["sklearn/cluster/optics_.py:optics"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "86476582a3759b82fd163d27522bd2de6ad95b6c", "problem_statement": "TST: optics function is not tested\n\nRelated to https://github.com/scikit-learn/scikit-learn/pull/1984 that was merged: it seems that the `optics` function (that @amueller added to the `cluster/__init__.py` in https://github.com/scikit-learn/scikit-learn/pull/11567) is not tested (at least not in `test_optics.py`)\r\n\r\n(so the function `optics` that wraps the `OPTICS` class)", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-5022", "file_changes": [{"file": "benchmarks/bench_covertype.py", "changes": {}}, {"file": "benchmarks/bench_sgd_regression.py", "changes": {}}, {"file": "benchmarks/bench_sparsify.py", "changes": {}}, {"file": "doc/modules/kernel_approximation.rst", "changes": {}}, {"file": "doc/modules/linear_model.rst", "changes": {}}, {"file": "doc/modules/sgd.rst", "changes": {}}, {"file": "doc/tutorial/text_analytics/working_with_text_data.rst", "changes": {}}, {"file": "doc/whats_new.rst", "changes": {}}, {"file": "examples/linear_model/plot_sgd_iris.py", "changes": {}}, {"file": "examples/linear_model/plot_sgd_separating_hyperplane.py", "changes": {}}, {"file": "examples/linear_model/plot_sgd_weighted_samples.py", "changes": {}}, {"file": "sklearn/decomposition/tests/test_kernel_pca.py", "changes": {"edited_modules": ["sklearn/decomposition/tests/test_kernel_pca.py:test_gridsearch_pipeline", "sklearn/decomposition/tests/test_kernel_pca.py:test_gridsearch_pipeline_precomputed", "sklearn/decomposition/tests/test_kernel_pca.py:test_nested_circles"], "edited_entities": ["sklearn/decomposition/tests/test_kernel_pca.py:test_gridsearch_pipeline", "sklearn/decomposition/tests/test_kernel_pca.py:test_gridsearch_pipeline_precomputed", "sklearn/decomposition/tests/test_kernel_pca.py:test_nested_circles"]}}, {"file": "sklearn/ensemble/tests/test_bagging.py", "changes": {"edited_modules": ["sklearn/ensemble/tests/test_bagging.py:test_classification", "sklearn/ensemble/tests/test_bagging.py:test_base_estimator"], "edited_entities": ["sklearn/ensemble/tests/test_bagging.py:test_classification", "sklearn/ensemble/tests/test_bagging.py:test_base_estimator"]}}, {"file": "sklearn/ensemble/tests/test_base.py", "changes": {"edited_modules": ["sklearn/ensemble/tests/test_base.py:test_base", "sklearn/ensemble/tests/test_base.py:test_base_zero_n_estimators", "sklearn/ensemble/tests/test_base.py:test_base_not_int_n_estimators", "sklearn/ensemble/tests/test_base.py:test_set_random_states", "sklearn/ensemble/tests/test_base.py:make_steps"], "edited_entities": ["sklearn/ensemble/tests/test_base.py:test_base", "sklearn/ensemble/tests/test_base.py:test_base_zero_n_estimators", "sklearn/ensemble/tests/test_base.py:test_base_not_int_n_estimators", "sklearn/ensemble/tests/test_base.py:test_set_random_states", "sklearn/ensemble/tests/test_base.py:make_steps"]}}, {"file": "sklearn/feature_selection/tests/test_from_model.py", "changes": {"edited_modules": ["sklearn/feature_selection/tests/test_from_model.py:test_invalid_input", "sklearn/feature_selection/tests/test_from_model.py:test_input_estimator_unchanged", "sklearn/feature_selection/tests/test_from_model.py:test_partial_fit", "sklearn/feature_selection/tests/test_from_model.py:test_prefit", "sklearn/feature_selection/tests/test_from_model.py:test_threshold_without_refitting"], "edited_entities": ["sklearn/feature_selection/tests/test_from_model.py:test_invalid_input", "sklearn/feature_selection/tests/test_from_model.py:test_input_estimator_unchanged", "sklearn/feature_selection/tests/test_from_model.py:test_partial_fit", "sklearn/feature_selection/tests/test_from_model.py:test_prefit", "sklearn/feature_selection/tests/test_from_model.py:test_threshold_without_refitting"]}}, {"file": "sklearn/linear_model/passive_aggressive.py", "changes": {"edited_modules": ["sklearn/linear_model/passive_aggressive.py:PassiveAggressiveClassifier", "sklearn/linear_model/passive_aggressive.py:PassiveAggressiveRegressor"], "edited_entities": ["sklearn/linear_model/passive_aggressive.py:PassiveAggressiveClassifier", "sklearn/linear_model/passive_aggressive.py:PassiveAggressiveRegressor", "sklearn/linear_model/passive_aggressive.py:PassiveAggressiveClassifier.__init__", "sklearn/linear_model/passive_aggressive.py:PassiveAggressiveClassifier.partial_fit", "sklearn/linear_model/passive_aggressive.py:PassiveAggressiveRegressor.__init__", "sklearn/linear_model/passive_aggressive.py:PassiveAggressiveRegressor.partial_fit"]}}, {"file": "sklearn/linear_model/perceptron.py", "changes": {"edited_modules": ["sklearn/linear_model/perceptron.py:Perceptron"], "edited_entities": ["sklearn/linear_model/perceptron.py:Perceptron", "sklearn/linear_model/perceptron.py:Perceptron.__init__"]}}, {"file": "sklearn/linear_model/sgd_fast.pyx", "changes": {}}, {"file": "sklearn/linear_model/stochastic_gradient.py", "changes": {"edited_modules": ["sklearn/linear_model/stochastic_gradient.py:BaseSGD", "sklearn/linear_model/stochastic_gradient.py:fit_binary", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier", "sklearn/linear_model/stochastic_gradient.py:SGDClassifier", "sklearn/linear_model/stochastic_gradient.py:BaseSGDRegressor", "sklearn/linear_model/stochastic_gradient.py:SGDRegressor"], "edited_entities": ["sklearn/linear_model/stochastic_gradient.py:BaseSGD.__init__", "sklearn/linear_model/stochastic_gradient.py:fit_binary", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier._fit", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier._fit_multiclass", "sklearn/linear_model/stochastic_gradient.py:SGDClassifier", "sklearn/linear_model/stochastic_gradient.py:BaseSGDRegressor._fit_regressor", "sklearn/linear_model/stochastic_gradient.py:SGDRegressor", "sklearn/linear_model/stochastic_gradient.py:BaseSGD._validate_params", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier.__init__", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier._partial_fit", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier._fit_binary", "sklearn/linear_model/stochastic_gradient.py:BaseSGDClassifier.partial_fit", "sklearn/linear_model/stochastic_gradient.py:SGDClassifier.__init__", "sklearn/linear_model/stochastic_gradient.py:BaseSGDRegressor.__init__", "sklearn/linear_model/stochastic_gradient.py:BaseSGDRegressor._partial_fit", "sklearn/linear_model/stochastic_gradient.py:BaseSGDRegressor.partial_fit", "sklearn/linear_model/stochastic_gradient.py:BaseSGDRegressor._fit", "sklearn/linear_model/stochastic_gradient.py:SGDRegressor.__init__"]}}, {"file": "sklearn/linear_model/tests/test_huber.py", "changes": {"edited_modules": ["sklearn/linear_model/tests/test_huber.py:test_huber_scaling_invariant", "sklearn/linear_model/tests/test_huber.py:test_huber_and_sgd_same_results"], "edited_entities": ["sklearn/linear_model/tests/test_huber.py:test_huber_scaling_invariant", "sklearn/linear_model/tests/test_huber.py:test_huber_and_sgd_same_results"]}}, {"file": "sklearn/linear_model/tests/test_passive_aggressive.py", "changes": {"edited_modules": ["sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_accuracy", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_partial_fit", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_refit", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_correctness", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_undefined_methods", "sklearn/linear_model/tests/test_passive_aggressive.py:test_class_weights", "sklearn/linear_model/tests/test_passive_aggressive.py:test_partial_fit_weight_class_balanced", "sklearn/linear_model/tests/test_passive_aggressive.py:test_equal_class_weight", "sklearn/linear_model/tests/test_passive_aggressive.py:test_wrong_class_weight_label", "sklearn/linear_model/tests/test_passive_aggressive.py:test_wrong_class_weight_format", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_mse", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_partial_fit", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_correctness", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_undefined_methods"], "edited_entities": ["sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_accuracy", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_partial_fit", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_refit", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_correctness", "sklearn/linear_model/tests/test_passive_aggressive.py:test_classifier_undefined_methods", "sklearn/linear_model/tests/test_passive_aggressive.py:test_class_weights", "sklearn/linear_model/tests/test_passive_aggressive.py:test_partial_fit_weight_class_balanced", "sklearn/linear_model/tests/test_passive_aggressive.py:test_equal_class_weight", "sklearn/linear_model/tests/test_passive_aggressive.py:test_wrong_class_weight_label", "sklearn/linear_model/tests/test_passive_aggressive.py:test_wrong_class_weight_format", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_mse", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_partial_fit", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_correctness", "sklearn/linear_model/tests/test_passive_aggressive.py:test_regressor_undefined_methods"]}}, {"file": "sklearn/linear_model/tests/test_perceptron.py", "changes": {"edited_modules": ["sklearn/linear_model/tests/test_perceptron.py:test_perceptron_accuracy", "sklearn/linear_model/tests/test_perceptron.py:test_perceptron_correctness", "sklearn/linear_model/tests/test_perceptron.py:test_undefined_methods"], "edited_entities": ["sklearn/linear_model/tests/test_perceptron.py:test_perceptron_accuracy", "sklearn/linear_model/tests/test_perceptron.py:test_perceptron_correctness", "sklearn/linear_model/tests/test_perceptron.py:test_undefined_methods"]}}, {"file": "sklearn/linear_model/tests/test_sgd.py", "changes": {"edited_modules": ["sklearn/linear_model/tests/test_sgd.py:CommonTest", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase", "sklearn/linear_model/tests/test_sgd.py:test_l1_ratio", "sklearn/linear_model/tests/test_sgd.py:test_underflow_or_overlow", "sklearn/linear_model/tests/test_sgd.py:test_numerical_stability_large_gradient", "sklearn/linear_model/tests/test_sgd.py:test_large_regularization"], "edited_entities": ["sklearn/linear_model/tests/test_sgd.py:CommonTest.factory", "sklearn/linear_model/tests/test_sgd.py:CommonTest._test_warm_start", "sklearn/linear_model/tests/test_sgd.py:CommonTest.test_input_format", "sklearn/linear_model/tests/test_sgd.py:CommonTest.test_clone", "sklearn/linear_model/tests/test_sgd.py:CommonTest.test_late_onset_averaging_reached", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_n_iter_param", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_average_binary_computed_correctly", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_at_least_two_labels", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_multiclass", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_multiclass_average", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_multiclass_with_init_coef", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_multiclass_njobs", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_proba", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sgd_l1", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_class_weights", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_equal_class_weight", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_wrong_class_weight_label", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_wrong_class_weight_format", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_weights_multiplied", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_balanced_weight", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_sample_weights", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_wrong_sample_weights", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase._test_partial_fit_equal_fit", "sklearn/linear_model/tests/test_sgd.py:DenseSGDClassifierTestCase.test_multiple_fit", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_sgd", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_sgd_averaged_computed_correctly", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_sgd_averaged_partial_fit", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_average_sparse", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_sgd_least_squares_fit", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_sgd_epsilon_insensitive", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_sgd_huber_fit", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase.test_elasticnet_convergence", "sklearn/linear_model/tests/test_sgd.py:DenseSGDRegressorTestCase._test_partial_fit_equal_fit", "sklearn/linear_model/tests/test_sgd.py:test_l1_ratio", "sklearn/linear_model/tests/test_sgd.py:test_underflow_or_overlow", "sklearn/linear_model/tests/test_sgd.py:test_numerical_stability_large_gradient", "sklearn/linear_model/tests/test_sgd.py:test_large_regularization"]}}, {"file": "sklearn/model_selection/tests/test_search.py", "changes": {"edited_modules": ["sklearn/model_selection/tests/test_search.py:test_stochastic_gradient_loss_param"], "edited_entities": ["sklearn/model_selection/tests/test_search.py:test_stochastic_gradient_loss_param"]}}, {"file": "sklearn/model_selection/tests/test_validation.py", "changes": {"edited_modules": ["sklearn/model_selection/tests/test_validation.py:test_learning_curve_batch_and_incremental_learning_are_equal", "sklearn/model_selection/tests/test_validation.py:test_learning_curve_with_shuffle"], "edited_entities": ["sklearn/model_selection/tests/test_validation.py:test_learning_curve_batch_and_incremental_learning_are_equal", "sklearn/model_selection/tests/test_validation.py:test_learning_curve_with_shuffle"]}}, {"file": "sklearn/tests/test_learning_curve.py", "changes": {"edited_modules": ["sklearn/tests/test_learning_curve.py:test_learning_curve_batch_and_incremental_learning_are_equal"], "edited_entities": ["sklearn/tests/test_learning_curve.py:test_learning_curve_batch_and_incremental_learning_are_equal"]}}, {"file": "sklearn/tests/test_multiclass.py", "changes": {"edited_modules": ["sklearn/tests/test_multiclass.py:test_ovr_partial_fit", "sklearn/tests/test_multiclass.py:test_ovo_ties", "sklearn/tests/test_multiclass.py:test_ovo_ties2"], "edited_entities": ["sklearn/tests/test_multiclass.py:test_ovr_partial_fit", "sklearn/tests/test_multiclass.py:test_ovo_ties", "sklearn/tests/test_multiclass.py:test_ovo_ties2"]}}, {"file": "sklearn/tests/test_multioutput.py", "changes": {"edited_modules": ["sklearn/tests/test_multioutput.py:test_multi_target_regression_partial_fit", "sklearn/tests/test_multioutput.py:test_multi_target_sample_weight_partial_fit", "sklearn/tests/test_multioutput.py:test_multi_output_classification_partial_fit_parallelism", "sklearn/tests/test_multioutput.py:test_multi_output_classification_partial_fit", "sklearn/tests/test_multioutput.py:test_multi_output_classifiation_partial_fit_no_first_classes_exception", "sklearn/tests/test_multioutput.py:test_multi_output_classification_partial_fit_sample_weights"], "edited_entities": ["sklearn/tests/test_multioutput.py:test_multi_target_regression_partial_fit", "sklearn/tests/test_multioutput.py:test_multi_target_sample_weight_partial_fit", "sklearn/tests/test_multioutput.py:test_multi_output_classification_partial_fit_parallelism", "sklearn/tests/test_multioutput.py:test_multi_output_classification_partial_fit", "sklearn/tests/test_multioutput.py:test_multi_output_classifiation_partial_fit_no_first_classes_exception", "sklearn/tests/test_multioutput.py:test_multi_output_classification_partial_fit_sample_weights"]}}, {"file": "sklearn/utils/estimator_checks.py", "changes": {"edited_modules": ["sklearn/utils/estimator_checks.py:check_class_weight_classifiers", "sklearn/utils/estimator_checks.py:check_class_weight_balanced_classifiers", "sklearn/utils/estimator_checks.py:check_class_weight_balanced_linear_classifier", "sklearn/utils/estimator_checks.py:check_parameters_default_constructible", "sklearn/utils/estimator_checks.py:set_checking_parameters", "sklearn/utils/estimator_checks.py:check_estimator_sparse_data", "sklearn/utils/estimator_checks.py:check_estimators_nan_inf", "sklearn/utils/estimator_checks.py:check_classifiers_one_label"], "edited_entities": ["sklearn/utils/estimator_checks.py:check_class_weight_classifiers", "sklearn/utils/estimator_checks.py:check_class_weight_balanced_classifiers", "sklearn/utils/estimator_checks.py:check_class_weight_balanced_linear_classifier", "sklearn/utils/estimator_checks.py:check_parameters_default_constructible", "sklearn/utils/estimator_checks.py:set_checking_parameters", "sklearn/utils/estimator_checks.py:check_estimator_sparse_data", "sklearn/utils/estimator_checks.py:check_estimators_nan_inf", "sklearn/utils/estimator_checks.py:check_classifiers_one_label"]}}, {"file": "sklearn/utils/weight_vector.pyx", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "ebf2bf81075ae1f4eb47ea0f54981c512bda5ceb", "problem_statement": "Deprecate n_iter in SGDClassifier and implement max_iter.\n\nWe should implement a stopping condition based on the scaled norm of the parameter update as done in the new SAG solver for LogisticRegression / Ridge. The convergence check should be done at the end of the each epoch to avoid introducing too much overhead.\n\nOther classes sharing the same underlying implementation should be updated as well, e.g.:\n- SGDRegressor\n- PassiveAggressiveClassifier\n- Perceptron\n\nmaybe others.\n\nWe should store the effective number of iterations in a new `n_iter_` attribute on the estimator at the end of `fit` as done in many other scikit-learn model that accept a `max_iter` hyperparam.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-28976", "file_changes": [{"file": "sklearn/cluster/_hdbscan/_reachability.pyx", "changes": {}}, {"file": "sklearn/cluster/_hdbscan/hdbscan.py", "changes": {"edited_modules": ["sklearn/cluster/_hdbscan/hdbscan.py:HDBSCAN"], "edited_entities": ["sklearn/cluster/_hdbscan/hdbscan.py:HDBSCAN"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "dc1cad2b3fddb8b9069d7cfd89cb1039260baf8e", "problem_statement": "`min_samples` in HDSCAN\n\n### Describe the issue linked to the documentation\n\nI find the description of the `min_samples` argument in sklearn.cluster.HDBSCAN confusing.\r\n\r\nIt says \"The number of samples in a neighborhood for a point to be considered as a core point. This includes the point itself.\"\r\n\r\nBut if I understand everything correctly `min_samples` corresponds to the $k$ used to compute the core distance $\\text{core}_k\\left(x\\right)$ for every sample $x$ where the $k$'th core distance for some sample $x$ is defined as the distance to the $k$'th nearest-neighbor of $x$ (counting itself). (-> which exactly what is happening in the code here: https://github.com/scikit-learn-contrib/hdbscan/blob/fc94241a4ecf5d3668cbe33b36ef03e6160d7ab7/hdbscan/_hdbscan_reachability.pyx#L45-L47, where it is called `min_points`)\r\n\r\nI don't understand how both of these descriptions are equivalent. I would assume that other people might find that confusing as well.\r\n\r\nLink in Code: https://github.com/scikit-learn/scikit-learn/blob/8721245511de2f225ff5f9aa5f5fadce663cd4a3/sklearn/cluster/_hdbscan/hdbscan.py#L441-L444\r\n\r\nLink in Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN\n\n### Suggest a potential alternative/fix\n\n_No response_", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-901", "file_changes": [{"file": "sklearn/base.py", "changes": {}}, {"file": "sklearn/cluster/affinity_propagation_.py", "changes": {"edited_modules": ["sklearn/cluster/affinity_propagation_.py:AffinityPropagation"], "edited_entities": ["sklearn/cluster/affinity_propagation_.py:AffinityPropagation"]}}, {"file": "sklearn/cluster/dbscan_.py", "changes": {"edited_modules": ["sklearn/cluster/dbscan_.py:DBSCAN"], "edited_entities": ["sklearn/cluster/dbscan_.py:DBSCAN"]}}, {"file": "sklearn/cluster/hierarchical.py", "changes": {"edited_modules": ["sklearn/cluster/hierarchical.py:Ward"], "edited_entities": ["sklearn/cluster/hierarchical.py:Ward"]}}, {"file": "sklearn/cluster/k_means_.py", "changes": {"edited_modules": ["sklearn/cluster/k_means_.py:KMeans", "sklearn/cluster/k_means_.py:MiniBatchKMeans"], "edited_entities": ["sklearn/cluster/k_means_.py:KMeans", "sklearn/cluster/k_means_.py:MiniBatchKMeans"]}}, {"file": "sklearn/cluster/mean_shift_.py", "changes": {"edited_modules": ["sklearn/cluster/mean_shift_.py:MeanShift"], "edited_entities": ["sklearn/cluster/mean_shift_.py:MeanShift"]}}, {"file": "sklearn/cluster/spectral.py", "changes": {"edited_modules": ["sklearn/cluster/spectral.py:SpectralClustering"], "edited_entities": ["sklearn/cluster/spectral.py:SpectralClustering"]}}, {"file": "sklearn/cluster/tests/test_k_means.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "127415b209ca1df3f8502bdf74de56c33aff2565", "problem_statement": "add predict and fit_predict to more clustering algorithms\n\nWe should add `predict` and `fit_predict` to other clustering algorithms than `KMeans`: they are useful to retrieve cluster labels independently of the underlying attribute names...", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-4700", "file_changes": [{"file": "sklearn/cross_validation.py", "changes": {"edited_modules": ["sklearn/cross_validation.py:cross_val_predict"], "edited_entities": ["sklearn/cross_validation.py:cross_val_predict"]}}, {"file": "sklearn/tests/test_cross_validation.py", "changes": {"edited_modules": ["sklearn/tests/test_cross_validation.py:MockClassifier"], "edited_entities": ["sklearn/tests/test_cross_validation.py:MockClassifier.predict"]}}, {"file": "sklearn/utils/mocking.py", "changes": {"edited_modules": ["sklearn/utils/mocking.py:CheckingClassifier"], "edited_entities": ["sklearn/utils/mocking.py:CheckingClassifier.fit", "sklearn/utils/mocking.py:CheckingClassifier", "sklearn/utils/mocking.py:CheckingClassifier.predict"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "9385c45c0379ceab913daa811b1e7d4128faee35", "problem_statement": "cross_val_predict AttributeError with lists\n\nWhen calling the cross_val_predict with an X parameter that is a list type, an AttributeError is raised on line 1209. This is because it is checking for the shape of the X parameter, but a list does not have the shape attribute.\n\nThe documentation says that this function supports lists so I am supposing that it isn't intended behavior. Commenting out that line also makes the rest of the function work perfectly fine.\n\nAlso not that the cross_val_score function, that takes the same arguments, works fine.\n\nI can provide the dataset I used if necessary.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-19705", "file_changes": [{"file": ".circleci/config.yml", "changes": {}}, {"file": ".travis.yml", "changes": {}}, {"file": "azure-pipelines.yml", "changes": {}}, {"file": "build_tools/azure/install.sh", "changes": {}}, {"file": "build_tools/azure/posix-32.yml", "changes": {}}, {"file": "build_tools/azure/test_script.sh", "changes": {}}, {"file": "doc/conftest.py", "changes": {"edited_modules": ["doc/conftest.py:setup_preprocessing"], "edited_entities": ["doc/conftest.py:setup_preprocessing"]}}, {"file": "doc/modules/sgd.rst", "changes": {}}, {"file": "doc/tutorial/statistical_inference/supervised_learning.rst", "changes": {}}, {"file": "doc/whats_new/v1.0.rst", "changes": {}}, {"file": "pyproject.toml", "changes": {}}, {"file": "sklearn/_min_dependencies.py", "changes": {}}, {"file": "sklearn/decomposition/_truncated_svd.py", "changes": {"edited_modules": ["sklearn/decomposition/_truncated_svd.py:TruncatedSVD"], "edited_entities": ["sklearn/decomposition/_truncated_svd.py:TruncatedSVD"]}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_loss.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_loss.py:test_derivatives"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_loss.py:test_derivatives"]}}, {"file": "sklearn/utils/tests/test_validation.py", "changes": {"edited_modules": ["sklearn/utils/tests/test_validation.py:test_check_array_dtype_numeric_errors"], "edited_entities": ["sklearn/utils/tests/test_validation.py:test_check_array_dtype_numeric_errors"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "053d2d1af477d9dc17e69162b9f2298c0fda5905", "problem_statement": "[RFC] Minimal scipy version for 1.0 (or 0.26) release\n\n#### Proposal\r\nI'd like to propose to increase the minimal scipy version to 1.0.\r\n```python\r\nSCIPY_MIN_VERSION = '1.0.0'\r\n```\r\n\r\n#### Reasoning\r\n\r\n1. In case we should release scikit-learn 1.0, it would be a good fit:smirk:\r\n2. Linear quantile regression #9978 could make it into the next release. It uses `scipy.optimize.linprog` under the hood. Scipy 1.0.0 has introduced a new solver `method=\"interior-point\"` which is set as default method. Having it available would help us to avoid to support the `\"simplex\"` method in scikit-learn. Note, that scipy v1.3.0 introduced the `\"revised simplex\"` method and version 1.5 the `\"highs**\"` solvers which are much preferred.\r\n   I think we should avoid the legacy simplex method.\r\n3. *Your reason for scipy 1.0.0.*", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-19304", "file_changes": [{"file": "sklearn/ensemble/_forest.py", "changes": {"edited_modules": ["sklearn/ensemble/_forest.py:BaseForest", "sklearn/ensemble/_forest.py:RandomForestRegressor"], "edited_entities": ["sklearn/ensemble/_forest.py:BaseForest.fit", "sklearn/ensemble/_forest.py:RandomForestRegressor"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "a0ba256dbe9380b5d2cf9cee133482fc87768267", "problem_statement": "Poisson criterion in RandomForestRegressor\n\n#### Describe the workflow you want to enable\r\nI want to officially use the Poisson splitting criterion in `RandomForestRegressor`.\r\n\r\n#### Describe your proposed solution\r\n#17386 implemented the poisson splitting criterion for `DecisionTreeRegressor` and `ExtraTreeRegressor`. This also enabled&mdash;somewhat silently&mdash;to do:\r\n```\r\nimport numpy as np\r\nfrom sklearn.ensemble import RandomForestRegressor\r\ny = [0, 1, 2]\r\nX = np.arange(6).reshape(3, 2)\r\nrf = RandomForestRegressor(criterion=\"poisson\")\r\nrf.fit(X, y)\r\n```\r\nNote: The same is true for `ensemble.ExtraTreesRegressor`.\r\n\r\nTasks:\r\n\r\n- [ ] Add the poisson splitting criterion to the docstring of `RandomForestRegressor`.\r\n- [ ] Add input validation (non-negative `y`) to `RandomForestRegressor`.\r\n- [ ] Expand the tests for `RandomForestRegressor`.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-4846", "file_changes": [{"file": "sklearn/linear_model/ridge.py", "changes": {"edited_modules": ["sklearn/linear_model/ridge.py:RidgeClassifier", "sklearn/linear_model/ridge.py:RidgeClassifierCV"], "edited_entities": ["sklearn/linear_model/ridge.py:RidgeClassifier.fit", "sklearn/linear_model/ridge.py:RidgeClassifierCV.fit"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "8453daa6b983ee2fd73d537e81e58b3f6b0e3147", "problem_statement": "RidgeClassifier triggers data copy\n\nRidgeClassifier always triggers a data copy even when not using sample weights.\n\nRegression introduced in #4838.\n\nSee:\nhttps://github.com/scikit-learn/scikit-learn/pull/4838#discussion_r32090535", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-7467", "file_changes": [{"file": "sklearn/feature_selection/rfe.py", "changes": {"edited_modules": ["sklearn/feature_selection/rfe.py:RFECV"], "edited_entities": ["sklearn/feature_selection/rfe.py:RFECV.fit"]}}, {"file": "sklearn/feature_selection/tests/test_rfe.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "c9e227b70d64f73b953d8d60629d6ac63e02a91c", "problem_statement": "float numbers can't be set to RFECV's parameter \"step\"\n\n#### Description\n\nWhen I use RFECV with parameter 'step' as a float number will cause warnings/errors \"rfe.py:203: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\".  And the analysis can't be finished until integer or 1/2.\n\nI read description of RFECV and learned that parameter 'step' can accept float. (introduction online: If greater than or equal to 1, then step corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then step corresponds to the percentage (rounded down) of features to remove at each iteration.)\n\nAnd I didn't read any bugs from source script. Please tell.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-17814", "file_changes": [{"file": "sklearn/linear_model/_coordinate_descent.py", "changes": {"edited_modules": ["sklearn/linear_model/_coordinate_descent.py:ElasticNet"], "edited_entities": ["sklearn/linear_model/_coordinate_descent.py:ElasticNet.fit"]}}, {"file": "sklearn/linear_model/tests/test_coordinate_descent.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "9b42b0cc7d5cf6978805619bc2433e3888c38d0c", "problem_statement": "l1_ratio in sklearn.linear_model's ElasticNet greater than 1?\n\nI accidentally ran ElasticNet (from sklearn.linear_model) for l1_ratio >1, and no error or warning was raised. From the docsstring, it says that ``0 < l1_ratio < 1``. Should we raise a ValueError or something? Found this with @mathurinm.\r\n\r\nIf this turns out to be something to be done, I could help out if someone could point me towards the right direction. Thanks !\r\n\r\np/s: Not sure if this should be under bugs/documentations/others, so I listed it under others. Sklearn version is 0.22.1.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-8499", "file_changes": [{"file": "sklearn/svm/src/liblinear/liblinear_helper.c", "changes": {"edited_modules": ["sklearn/svm/src/liblinear/liblinear_helper.c:free_problem"], "edited_entities": ["sklearn/svm/src/liblinear/liblinear_helper.c:free_problem"]}}, {"file": "sklearn/svm/src/liblinear/linear.cpp", "changes": {"edited_modules": ["sklearn/svm/src/liblinear/linear.cpp:free_model_content"], "edited_entities": ["sklearn/svm/src/liblinear/linear.cpp:free_model_content"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "38c7e93b1edcbfb85060cf7c14cca3ab47b9267c", "problem_statement": "Memory leak in LogisticRegression\n\nDear all,\r\n\r\nwhile running many logistic regressions, I encountered a continuous memory increase on several (Debian) machines. The problem is isolated in this code:\r\n\r\n```python\r\nimport sklearn\r\nfrom sklearn.linear_model import LogisticRegression\r\nimport numpy as np\r\nimport time\r\nimport psutil\r\nimport os\r\n\r\nif __name__ == \"__main__\":\r\n    print(\"Sklearn version: %s\" % sklearn.__version__)\r\n    n_samples = 2\r\n    n_features = 2\r\n    data = np.arange(n_samples*n_features).reshape((n_samples,n_features))\r\n    labels = np.arange(n_samples)\r\n    last_output_time = 0\r\n    process = psutil.Process(os.getpid())\r\n    for i in range(10000000):\r\n        clf = LogisticRegression()\r\n        clf.fit(X=data, y=labels)\r\n        del clf\r\n        if time.time()-last_output_time >= 5:\r\n            print(process.get_memory_info()[0] / float(2 ** 20))\r\n            last_output_time = time.time()\r\n```\r\nThis was Python 2.7 under Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u1 (2017-02-22) x86_64 GNU/Linux, with scikit-learn 0.18.1. Is this reproducable?", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-29906", "file_changes": [{"file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:make_missing_value_data"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:make_missing_value_data"]}}, {"file": "sklearn/inspection/tests/test_permutation_importance.py", "changes": {"edited_modules": ["sklearn/inspection/tests/test_permutation_importance.py:test_permutation_importance_equivalence_array_dataframe"], "edited_entities": ["sklearn/inspection/tests/test_permutation_importance.py:test_permutation_importance_equivalence_array_dataframe"]}}, {"file": "sklearn/preprocessing/_discretization.py", "changes": {"edited_modules": ["sklearn/preprocessing/_discretization.py:KBinsDiscretizer"], "edited_entities": ["sklearn/preprocessing/_discretization.py:KBinsDiscretizer", "sklearn/preprocessing/_discretization.py:KBinsDiscretizer.__init__", "sklearn/preprocessing/_discretization.py:KBinsDiscretizer.fit"]}}, {"file": "sklearn/preprocessing/tests/test_discretization.py", "changes": {"edited_modules": ["sklearn/preprocessing/tests/test_discretization.py:test_KBD_inverse_transform_Xt_deprecation", "sklearn/preprocessing/tests/test_discretization.py:test_fit_transform", "sklearn/preprocessing/tests/test_discretization.py:test_valid_n_bins", "sklearn/preprocessing/tests/test_discretization.py:test_invalid_n_bins_array", "sklearn/preprocessing/tests/test_discretization.py:test_fit_transform_n_bins_array", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_effect_sample_weight", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_no_mutating_sample_weight", "sklearn/preprocessing/tests/test_discretization.py:test_same_min_max", "sklearn/preprocessing/tests/test_discretization.py:test_transform_1d_behavior", "sklearn/preprocessing/tests/test_discretization.py:test_numeric_stability", "sklearn/preprocessing/tests/test_discretization.py:test_encode_options", "sklearn/preprocessing/tests/test_discretization.py:test_nonuniform_strategies", "sklearn/preprocessing/tests/test_discretization.py:test_inverse_transform", "sklearn/preprocessing/tests/test_discretization.py:test_transform_outside_fit_range", "sklearn/preprocessing/tests/test_discretization.py:test_overwrite", "sklearn/preprocessing/tests/test_discretization.py:test_redundant_bins", "sklearn/preprocessing/tests/test_discretization.py:test_percentile_numeric_stability", "sklearn/preprocessing/tests/test_discretization.py:test_consistent_dtype", "sklearn/preprocessing/tests/test_discretization.py:test_32_equal_64", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_subsample_default", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscrtizer_get_feature_names_out", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_subsample"], "edited_entities": ["sklearn/preprocessing/tests/test_discretization.py:test_KBD_inverse_transform_Xt_deprecation", "sklearn/preprocessing/tests/test_discretization.py:test_fit_transform", "sklearn/preprocessing/tests/test_discretization.py:test_valid_n_bins", "sklearn/preprocessing/tests/test_discretization.py:test_invalid_n_bins_array", "sklearn/preprocessing/tests/test_discretization.py:test_fit_transform_n_bins_array", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_effect_sample_weight", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_no_mutating_sample_weight", "sklearn/preprocessing/tests/test_discretization.py:test_same_min_max", "sklearn/preprocessing/tests/test_discretization.py:test_transform_1d_behavior", "sklearn/preprocessing/tests/test_discretization.py:test_numeric_stability", "sklearn/preprocessing/tests/test_discretization.py:test_encode_options", "sklearn/preprocessing/tests/test_discretization.py:test_nonuniform_strategies", "sklearn/preprocessing/tests/test_discretization.py:test_inverse_transform", "sklearn/preprocessing/tests/test_discretization.py:test_transform_outside_fit_range", "sklearn/preprocessing/tests/test_discretization.py:test_overwrite", "sklearn/preprocessing/tests/test_discretization.py:test_redundant_bins", "sklearn/preprocessing/tests/test_discretization.py:test_percentile_numeric_stability", "sklearn/preprocessing/tests/test_discretization.py:test_consistent_dtype", "sklearn/preprocessing/tests/test_discretization.py:test_32_equal_64", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_subsample_default", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscrtizer_get_feature_names_out", "sklearn/preprocessing/tests/test_discretization.py:test_kbinsdiscretizer_subsample"]}}, {"file": "sklearn/preprocessing/tests/test_polynomial.py", "changes": {"edited_modules": ["sklearn/preprocessing/tests/test_polynomial.py:test_spline_transformer_kbindiscretizer"], "edited_entities": ["sklearn/preprocessing/tests/test_polynomial.py:test_spline_transformer_kbindiscretizer"]}}, {"file": "sklearn/preprocessing/tests/test_target_encoder.py", "changes": {"edited_modules": ["sklearn/preprocessing/tests/test_target_encoder.py:test_invariance_of_encoding_under_label_permutation"], "edited_entities": ["sklearn/preprocessing/tests/test_target_encoder.py:test_invariance_of_encoding_under_label_permutation"]}}, {"file": "sklearn/tests/test_docstring_parameters.py", "changes": {"edited_modules": ["sklearn/tests/test_docstring_parameters.py:test_fit_docstring_attributes"], "edited_entities": ["sklearn/tests/test_docstring_parameters.py:test_fit_docstring_attributes"]}}, {"file": "sklearn/utils/_indexing.py", "changes": {"edited_modules": ["sklearn/utils/_indexing.py:resample"], "edited_entities": ["sklearn/utils/_indexing.py:resample"]}}, {"file": "sklearn/utils/_test_common/instance_generator.py", "changes": {}}, {"file": "sklearn/utils/stats.py", "changes": {"edited_modules": ["sklearn/utils/stats.py:_weighted_percentile"], "edited_entities": ["sklearn/utils/stats.py:_weighted_percentile"]}}, {"file": "sklearn/utils/tests/test_indexing.py", "changes": {}}, {"file": "sklearn/utils/tests/test_stats.py", "changes": {}}], "repo": "scikit-learn/scikit-learn", "base_commit": "e25e8e2119ab6c5aa5072b05c0eb60b10aee4b05", "problem_statement": "Incorrect sample weight handling in `KBinsDiscretizer`\n\n### Describe the bug\r\n\r\nSample weights are not properly passed through when specifying subsample within KBinsDiscretizer.\r\n\r\n### Steps/Code to Reproduce\r\n\r\n```python\r\nfrom sklearn.datasets import make_blobs\r\nfrom sklearn.preprocessing import KBinsDiscretizer\r\nimport numpy as np\r\n\r\nrng = np.random.RandomState(42)\r\n\r\n# Four centres \r\ncentres = np.array([[0, 0], [0, 5], [3, 1], [2, 4], [8, 8]])\r\nX, _ = make_blobs(\r\n            n_samples=100,\r\n            cluster_std=0.5,\r\n            centers=centres,\r\n            random_state=10,\r\n        )\r\n\r\n# Randomly generate sample weights\r\nsample_weight = rng.randint(0, 10, size=X.shape[0])\r\n\r\nest = KBinsDiscretizer(n_bins=4, strategy='quantile', subsample=20,\r\n                                    random_state=10).fit(X, sample_weight=sample_weight)\r\n```\r\n\r\n\r\n### Expected Results\r\n\r\nNo error is thrown\r\n\r\n### Actual Results\r\n\r\n```\r\n[253](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/preprocessing/_discretization.py:253) if sample_weight is not None:\r\n--> [254](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/preprocessing/_discretization.py:254)     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\r\n    [256](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/preprocessing/_discretization.py:256) bin_edges = np.zeros(n_features, dtype=object)\r\n    [257](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/preprocessing/_discretization.py:257) for jj in range(n_features):\r\n\r\nFile ~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2133, in _check_sample_weight(sample_weight, X, dtype, copy, ensure_non_negative)\r\n   [2130](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2130)         raise ValueError(\"Sample weights must be 1D array or scalar\")\r\n   [2132](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2132)     if sample_weight.shape != (n_samples,):\r\n-> [2133](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2133)         raise ValueError(\r\n   [2134](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2134)             \"sample_weight.shape == {}, expected {}!\".format(\r\n   [2135](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2135)                 sample_weight.shape, (n_samples,)\r\n   [2136](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2136)             )\r\n   [2137](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2137)         )\r\n   [2139](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2139) if ensure_non_negative:\r\n   [2140](https://file+.vscode-resource.vscode-cdn.net/Users/shrutinath/sklearn-dev/~/sklearn-dev/scikit-learn/sklearn/utils/validation.py:2140)     check_non_negative(sample_weight, \"`sample_weight`\")\r\n\r\nValueError: sample_weight.shape == (100,), expected (20,)!\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\nSystem:\r\n    python: 3.12.4 | packaged by conda-forge | (main, Jun 17 2024, 10:13:44) [Clang 16.0.6 ]\r\nexecutable: /Users/shrutinath/micromamba/envs/scikit-learn/bin/python\r\n   machine: macOS-14.3-arm64-arm-64bit\r\n\r\nPython dependencies:\r\n      sklearn: 1.6.dev0\r\n          pip: 24.0\r\n   setuptools: 70.1.1\r\n        numpy: 2.0.0\r\n        scipy: 1.14.0\r\n       Cython: 3.0.10\r\n       pandas: 2.2.2\r\n   matplotlib: 3.9.0\r\n       joblib: 1.4.2\r\nthreadpoolctl: 3.5.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       user_api: blas\r\n   internal_api: openblas\r\n    num_threads: 8\r\n         prefix: libopenblas\r\n...\r\n    num_threads: 8\r\n         prefix: libomp\r\n       filepath: /Users/shrutinath/micromamba/envs/scikit-learn/lib/libomp.dylib\r\n        version: None\r\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\r\n```", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-6656", "file_changes": [{"file": "doc/modules/ensemble.rst", "changes": {}}, {"file": "doc/whats_new/v0.23.rst", "changes": {}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/common.pxd", "changes": {}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:BaseHistGradientBoosting", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:HistGradientBoostingRegressor", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:HistGradientBoostingClassifier"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:BaseHistGradientBoosting.__init__", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:BaseHistGradientBoosting", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:BaseHistGradientBoosting.fit", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:HistGradientBoostingRegressor", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:HistGradientBoostingClassifier", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:HistGradientBoostingRegressor.__init__", "sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:HistGradientBoostingClassifier.__init__"]}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/grower.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeNode", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower", "sklearn/ensemble/_hist_gradient_boosting/grower.py:_fill_predictor_node_array"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeNode.__init__", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower.__init__", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeNode", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower._intilialize_root", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower._compute_best_split_and_push", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower.split_next", "sklearn/ensemble/_hist_gradient_boosting/grower.py:TreeGrower._finalize_leaf", "sklearn/ensemble/_hist_gradient_boosting/grower.py:_fill_predictor_node_array"]}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/splitting.pyx", "changes": {}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:test_early_stopping_on_test_set_with_warm_start"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:test_early_stopping_on_test_set_with_warm_start"]}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py:test_grow_tree", "sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py:test_split_on_nan_with_infinite_values"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py:test_grow_tree", "sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py:test_split_on_nan_with_infinite_values"]}}, {"file": "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py", "changes": {"edited_modules": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_histogram_split", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_gradient_and_hessian_sanity", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_split_indices", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_min_gain_to_split", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_splitting_missing_values"], "edited_entities": ["sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_histogram_split", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_gradient_and_hessian_sanity", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_split_indices", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_min_gain_to_split", "sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py:test_splitting_missing_values"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "dcfb3df9a3df5aa2a608248316d537cd6b3643ee", "problem_statement": "var.monotone option in GradientBoosting\n\nHi, is it possible to add the equivalent of the var.monotone option in R GBM package to the GradientBoostingClassifier/Regressor? Sometimes it is really useful when we know/want some factors to have monotonic effect to avoid overfitting and non-intuitive results.\n\nThanks!", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-6783", "file_changes": [{"file": "sklearn/cross_validation.py", "changes": {"edited_modules": ["sklearn/cross_validation.py:_score"], "edited_entities": ["sklearn/cross_validation.py:_score"]}}, {"file": "sklearn/model_selection/_validation.py", "changes": {"edited_modules": ["sklearn/model_selection/_validation.py:_score"], "edited_entities": ["sklearn/model_selection/_validation.py:_score"]}}, {"file": "sklearn/model_selection/tests/test_validation.py", "changes": {"edited_modules": ["sklearn/model_selection/tests/test_validation.py:test_cross_val_predict_with_method"], "edited_entities": ["sklearn/model_selection/tests/test_validation.py:test_cross_val_predict_with_method"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "417788c6a54c39614b82acf1a04b1f97f8a32199", "problem_statement": "\"scoring must return a number\" error with custom scorer\n\n#### Description\n\nI'm encountering the same error (`ValueError: scoring must return a number, got [...] (<class 'numpy.core.memmap.memmap'>) instead.`) as #6147, despite running v0.17.1. This is because I'm creating my own scorer, following the example in this [article](http://bigdataexaminer.com/data-science/dealing-with-unbalanced-classes-svm-random-forests-and-decision-trees-in-python/).\n#### Steps/Code to Reproduce\n\n``` python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom functools import partial\n\ndef cutoff_predict(clf, X, cutoff):\n    return (clf.predict_proba(X)[:, 1] > cutoff).astype(int)\n\ndef perc_diff_score(y, ypred, X=None):\n    values = X[:,0]\n    actual_value = np.sum(np.multiply(y, values))\n    predict_value = np.sum(np.multiply(ypred, values))\n    difference = predict_value - actual_value\n    percent_diff = abs(difference * 100 / actual_value )\n    return -1*percent_diff\n\ndef perc_diff_cutoff(clf, X, y, cutoff=None):\n    ypred = cutoff_predict(clf, X, cutoff)\n    return perc_diff_score(y, ypred, X)\n\ndef perc_diff_score_cutoff(cutoff):\n    return partial(perc_diff_cutoff, cutoff=cutoff)\n\nclf = RandomForestClassifier()\nX_train, y_train = make_classification(n_samples=int(1e6), n_features=5, random_state=0)\nvalues = abs(100000 * np.random.randn(len(X_train))).reshape((X_train.shape[0], 1))\nX_train = np.append(values, X_train, 1)\n\ncutoff = 0.1\nvalidated = cross_val_score(clf, X_train, y_train, scoring=perc_diff_score_cutoff(cutoff),\n                            verbose=3,\n                            n_jobs=-1,\n                            )\n```\n#### Expected Results\n\nNo error.\n#### Actual Results\n\nSame error as in #6147 :\n\n```\n/home/gillesa/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.pyc in _score(estimator=ExtraTreesClassifier(bootstrap=False, class_weig..., random_state=None, verbose=0, warm_start=False), X_test=memmap([[  0.,   9.,  56., ...,   1.,   0.,   0....      [  0.,   6.,  57., ...,   1.,   0.,   0.]]), y_test=memmap([0, 0, 0, ..., 0, 0, 0]), scorer=make_scorer(roc_auc_score, needs_threshold=True))\n   1604         score = scorer(estimator, X_test)\n   1605     else:\n   1606         score = scorer(estimator, X_test, y_test)\n   1607     if not isinstance(score, numbers.Number):\n   1608         raise ValueError(\"scoring must return a number, got %s (%s) instead.\"\n-> 1609                          % (str(score), type(score)))\n   1610     return score\n   1611\n   1612\n   1613 def _permutation_test_score(estimator, X, y, cv, scorer):\n\nValueError: scoring must return a number, got 0.671095795498 (<class 'numpy.core.memmap.memmap'>) instead.\n```\n#### Workaround\n\nUpdated `perc_diff_score()` as follows to add cast to `float`.:\n\n``` python\ndef perc_diff_score(y, ypred, X=None):\n    values = X[:,0]\n    actual_value = np.sum(np.multiply(y, values))\n    predict_value = np.sum(np.multiply(ypred, values))\n    difference = predict_value - actual_value\n    percent_diff = np.float(abs(difference * 100 / actual_value ))\n    return -1*percent_diff\n```\n#### Versions\n\nDarwin-15.4.0-x86_64-i386-64bit\nPython 3.5.1 |Anaconda 4.0.0 (x86_64)| (default, Dec  7 2015, 11:24:55) \n[GCC 4.2.1 (Apple Inc. build 5577)]import numpy; print(\"NumPy\", numpy.**version**)\nNumPy 1.11.0\nSciPy 0.17.0\nScikit-Learn 0.17.1", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-3722", "file_changes": [{"file": "doc/whats_new.rst", "changes": {}}, {"file": "sklearn/preprocessing/_weights.py", "changes": {}}, {"file": "sklearn/preprocessing/data.py", "changes": {"edited_modules": ["sklearn/preprocessing/data.py:scale", "sklearn/preprocessing/data.py:_mean_and_std"], "edited_entities": ["sklearn/preprocessing/data.py:scale", "sklearn/preprocessing/data.py:_mean_and_std"]}}, {"file": "sklearn/preprocessing/tests/test_data.py", "changes": {"edited_modules": ["sklearn/preprocessing/tests/test_data.py:test_one_hot_encoder_unknown_transform"], "edited_entities": ["sklearn/preprocessing/tests/test_data.py:test_one_hot_encoder_unknown_transform"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "3f49cee020a91a0be5d0d5602d29b3eefce9d758", "problem_statement": "preprocessing.scale provides consistent results on arrays with zero variance\n\nI'm using Python 2.7, NumPy 1.8.2 and scikit-learn 0.14.1 on x64 linux (all installed through Anaconda) and getting very inconsistent results for preprocessing.scale function:\n\n> print preprocessing.scale(np.zeros(6) + np.log(1e-5))\n> [ 0.  0.  0.  0.  0.  0.]\n> \n> print preprocessing.scale(np.zeros(8) + np.log(1e-5))\n> [-1. -1. -1. -1. -1. -1. -1. -1.]\n> \n> print preprocessing.scale(np.zeros(22) + np.log(1e-5))\n> [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n\nI would guess this is not is supposed to be happening. Quick investigation, points to the fact that np.std() of second and third array is not exactly zero, but very close to machine zero. sklearn still uses it to divide data (it doesn't go into the \"std == 0.0\" case in the code).\n\nNote that in the case of the array, this can be easily fixed by passing with_std=False, but when that happens for one of the many features in 2D matrix this is not an option.", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-13362", "file_changes": [{"file": "doc/whats_new/v0.21.rst", "changes": {}}, {"file": "sklearn/linear_model/ridge.py", "changes": {"edited_modules": ["sklearn/linear_model/ridge.py:_ridge_regression", "sklearn/linear_model/ridge.py:_BaseRidge"], "edited_entities": ["sklearn/linear_model/ridge.py:_ridge_regression", "sklearn/linear_model/ridge.py:_BaseRidge.fit"]}}, {"file": "sklearn/linear_model/tests/test_ridge.py", "changes": {"edited_modules": ["sklearn/linear_model/tests/test_ridge.py:test_raises_value_error_if_solver_not_supported", "sklearn/linear_model/tests/test_ridge.py:test_ridge_fit_intercept_sparse"], "edited_entities": ["sklearn/linear_model/tests/test_ridge.py:test_raises_value_error_if_solver_not_supported", "sklearn/linear_model/tests/test_ridge.py:test_ridge_fit_intercept_sparse"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "eda99f3cec70ba90303de0ef3ab7f988657fadb9", "problem_statement": "return_intercept==True in ridge_regression raises an exception\n\n<!--\r\nIf your issue is a usage question, submit it here instead:\r\n- StackOverflow with the scikit-learn tag: https://stackoverflow.com/questions/tagged/scikit-learn\r\n- Mailing List: https://mail.python.org/mailman/listinfo/scikit-learn\r\nFor more information, see User Questions: http://scikit-learn.org/stable/support.html#user-questions\r\n-->\r\n\r\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\n<!-- Example: Joblib Error thrown when calling fit on LatentDirichletAllocation with evaluate_every > 0-->\r\n\r\n#### Steps/Code to Reproduce\r\n\r\n```python\r\nfrom sklearn.linear_model import ridge_regression\r\nridge_regression([[0], [1], [3]], [0, 1, 3], 1, solver='auto', return_intercept=True)\r\n```\r\n\r\n#### Expected Results\r\n<!-- Example: No error is thrown. Please paste or describe the expected results.-->\r\n\r\n`(array([1]), 0)` (the values can differ, but at least no exception should be raised)\r\n\r\n#### Actual Results\r\n<!-- Please paste or specifically describe the actual output or traceback. -->\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nUnboundLocalError                         Traceback (most recent call last)\r\n<ipython-input-5-84df44249e86> in <module>\r\n----> 1 ridge_regression([[0], [1], [3]], [1, 2, 3], 1, solver='auto', return_intercept=True)\r\n\r\n~/.pyenv/versions/3.7.2/envs/kaggle-3.7.2/lib/python3.7/site-packages/sklearn/linear_model/ridge.py in ridge_regression(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept)\r\n    450         return coef, n_iter, intercept\r\n    451     elif return_intercept:\r\n--> 452         return coef, intercept\r\n    453     elif return_n_iter:\r\n    454         return coef, n_iter\r\n\r\nUnboundLocalError: local variable 'intercept' referenced before assignment\r\n```\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nFor scikit-learn >= 0.20:\r\nimport sklearn; sklearn.show_versions()\r\nFor scikit-learn < 0.20:\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\n-->\r\n\r\n```\r\nLinux-4.20.8-arch1-1-ARCH-x86_64-with-arch\r\nPython 3.7.2 (default, Feb 22 2019, 18:13:04) \r\n[GCC 8.2.1 20181127]\r\nNumPy 1.16.1\r\nSciPy 1.2.1\r\nScikit-Learn 0.21.dev0\r\n```\r\n\r\n\r\n\r\n<!-- Thanks for contributing! -->", "patch": ""}
{"instance_id": "pandas-dev__pandas-7261", "file_changes": [{"file": "doc/source/v0.14.1.txt", "changes": {}}, {"file": "pandas/core/base.py", "changes": {"edited_modules": ["pandas/core/base.py:IndexOpsMixin"], "edited_entities": ["pandas/core/base.py:IndexOpsMixin.max", "pandas/core/base.py:IndexOpsMixin.min"]}}, {"file": "pandas/tests/test_base.py", "changes": {"edited_modules": ["pandas/tests/test_base.py:TestIndexOps"], "edited_entities": ["pandas/tests/test_base.py:TestIndexOps"]}}, {"file": "pandas/tseries/index.py", "changes": {"edited_modules": ["pandas/tseries/index.py:DatetimeIndex"], "edited_entities": ["pandas/tseries/index.py:DatetimeIndex.min", "pandas/tseries/index.py:DatetimeIndex.max"]}}], "repo": "pandas-dev/pandas", "base_commit": "df2fb490a58f272067b33aad372bb4fe2393bb93", "problem_statement": "API: Should Index.min and max use nanmin and nanmax?\n\nIndex and Series `min` and `max` handles `nan` and `NaT` differently. Even though `min` and `max` are defined in `IndexOpsMixin`, `Series` doesn't use them and use `NDFrame` definitions.\n\n```\npd.Index([np.nan, 1.0]).min()\n# nan\n\npd.Index([np.nan, 1.0]).max()\n# nan\n\npd.DatetimeIndex([pd.NaT, '2011-01-01']).min()\n# NaT\n\npd.DatetimeIndex([pd.NaT, '2011-01-01']).max()\n#2011-01-01 00:00:00\n\n# Series excludes nan and NaT\npd.Series([np.nan, 1.0]).min()\n#1.0\n\npd.Series([np.nan, 1.0]).max()\n#1.0\n\npd.Series([pd.NaT, pd.Timestamp('2011-01-01')]).min()\n#2011-01-01 00:00:00\n\npd.Series([pd.NaT, pd.Timestamp('2011-01-01')]).max()\n#2011-01-01 00:00:00\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-7943", "file_changes": [{"file": "doc/source/timeseries.rst", "changes": {}}, {"file": "doc/source/v0.15.0.txt", "changes": {}}, {"file": "pandas/core/generic.py", "changes": {"edited_modules": ["pandas/core/generic.py:NDFrame"], "edited_entities": ["pandas/core/generic.py:NDFrame", "pandas/core/generic.py:NDFrame.tz_localize", "pandas/core/generic.py:NDFrame._tz_localize"]}}, {"file": "pandas/tseries/index.py", "changes": {"edited_modules": ["pandas/tseries/index.py:DatetimeIndex"], "edited_entities": ["pandas/tseries/index.py:DatetimeIndex", "pandas/tseries/index.py:DatetimeIndex.__new__", "pandas/tseries/index.py:DatetimeIndex._generate", "pandas/tseries/index.py:DatetimeIndex.tz_localize"]}}, {"file": "pandas/tseries/tests/test_timezones.py", "changes": {"edited_modules": ["pandas/tseries/tests/test_timezones.py:TestTimeZoneSupportPytz"], "edited_entities": ["pandas/tseries/tests/test_timezones.py:TestTimeZoneSupportPytz.test_infer_dst", "pandas/tseries/tests/test_timezones.py:TestTimeZoneSupportPytz"]}}, {"file": "pandas/tseries/tests/test_tslib.py", "changes": {"edited_modules": ["pandas/tseries/tests/test_tslib.py:TestTimestamp"], "edited_entities": ["pandas/tseries/tests/test_tslib.py:TestTimestamp.test_tz"]}}, {"file": "pandas/tslib.pyx", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "abd5333e7a3332921707888de9621c52dd3408e6", "problem_statement": "tz_localize should support is_dst input array\n\nWhen storing datetimes with timezone information in mysql I split out the is_dst flag into a separate column.  Then when reconstructing the Timestamps I am either forced to iterate through each row and call pytz.timezone.localize on every Timestamp which is very slow or do some magic with localizing what I can and then manually dealing with the fall transition time (note that infer_dst won't work because there could be many rows that have transitions in them).  I would much rather create the DatetimeIndex from the column of dates and then call tz_localize with the is_dst column.  This would then appropriately set the offset.\n\n```\ndi = DatetimeIndex(frame['DateColumn'])\ndi = di.tz_localize(TimeZone, is_dst_flat=frame['IsDstColumn'])\n```\n\nThoughts?", "patch": ""}
{"instance_id": "pandas-dev__pandas-16773", "file_changes": [{"file": "asv_bench/benchmarks/sparse.py", "changes": {}}, {"file": "doc/source/whatsnew/v0.21.0.txt", "changes": {}}, {"file": "pandas/core/sparse/frame.py", "changes": {"edited_modules": ["pandas/core/sparse/frame.py:SparseDataFrame"], "edited_entities": ["pandas/core/sparse/frame.py:SparseDataFrame._init_dict"]}}, {"file": "pandas/tests/reshape/test_reshape.py", "changes": {}}, {"file": "pandas/tests/sparse/test_frame.py", "changes": {"edited_modules": ["pandas/tests/sparse/test_frame.py:TestSparseDataFrame"], "edited_entities": ["pandas/tests/sparse/test_frame.py:TestSparseDataFrame"]}}], "repo": "pandas-dev/pandas", "base_commit": "a9421af1aac906cc38d025ed5db4a2b55cb8b9bc", "problem_statement": "SparseDataFrame constructor has horrible performance for df with many columns\n\n#### Code Sample\r\n\r\nThis is an example taken directly from the [docs](https://pandas.pydata.org/pandas-docs/stable/sparse.html#sparsedataframe), only that I've changed the sparsity of the arrays from 90% to 99%.\r\n\r\n```python\r\nimport pandas as pd\r\nfrom scipy.sparse import csr_matrix\r\nimport numpy as np\r\n\r\narr = np.random.random(size=(1000, 5))\r\narr[arr < .99] = 0\r\nsp_arr = csr_matrix(arr)\r\n%timeit sdf = pd.SparseDataFrame(sp_arr)\r\n```\r\n```\r\n 4.78 ms \u00b1 381 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n```\r\n\r\nNow, here's what happens when I increase the number of columns from 5 to 2000:\r\n\r\n```python\r\nimport pandas as pd\r\nfrom scipy.sparse import csr_matrix\r\nimport numpy as np\r\n\r\narr = np.random.random(size=(1000, 2000))\r\narr[arr < .99] = 0\r\nsp_arr = csr_matrix(arr)\r\n%timeit sdf = pd.SparseDataFrame(sp_arr)\r\n```\r\n```\r\n8.69 s \u00b1 208 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n```\r\n\r\nNote that initializing a the `scipy.sparse.csr_matrix` object itself is way (!!!) faster:\r\n\r\n```python\r\nimport pandas as pd\r\nfrom scipy.sparse import csr_matrix\r\nimport numpy as np\r\n\r\narr = np.random.random(size=(1000, 2000))\r\narr[arr < .99] = 0\r\n%timeit sp_arr = csr_matrix(arr)\r\n```\r\n```\r\n13 ms \u00b1 248 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n```\r\n\r\n#### Problem description\r\n\r\nThe construction of a SparseDataFrame with many columns is ridiculously slow. I've traced the problem to [this line](https://github.com/pandas-dev/pandas/blob/1c0b63281db0486aa8182d550e9bceb641e5f9a4/pandas/core/sparse/frame.py#L162) in the `SparseDataFrame._init_dict()` function. I don't know why the data frame is constructed by assigning individual columns of a `DataFrame` object. I think the `DataFrame._init_dict` method uses a much more efficient method.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.3.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.10.0-24-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.20.2\r\npytest: 3.1.2\r\npip: 9.0.1\r\nsetuptools: 36.0.1\r\nCython: 0.25.2\r\nnumpy: 1.12.1\r\nscipy: 0.19.0\r\nxarray: None\r\nIPython: 6.1.0\r\nsphinx: 1.6.1\r\npatsy: None\r\ndateutil: 2.6.0\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: None\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: 0.9.6\r\nlxml: None\r\nbs4: 4.6.0\r\nhtml5lib: 0.999999999\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.9.6\r\ns3fs: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-26058", "file_changes": [{"file": "pandas/core/indexes/base.py", "changes": {"edited_modules": ["pandas/core/indexes/base.py:Index"], "edited_entities": ["pandas/core/indexes/base.py:Index"]}}, {"file": "pandas/core/indexes/interval.py", "changes": {"edited_modules": ["pandas/core/indexes/interval.py:IntervalIndex"], "edited_entities": ["pandas/core/indexes/interval.py:IntervalIndex"]}}], "repo": "pandas-dev/pandas", "base_commit": "ba48fc4a033f11513fa2dd44c946e18b7bc27ad2", "problem_statement": "DOC: test new sphinx 2 release\n\nThe docs are currently being built with sphinx 1.8.5 (see eg https://travis-ci.org/pandas-dev/pandas/jobs/518832177 for a recent build on master).\r\n\r\nSphinx has released 2.0.0 (http://www.sphinx-doc.org/en/master/changes.html#release-2-0-0-released-mar-29-2019), and it would be good to test our docs with this new release, and see if we need to make changes / report regressions to sphinx.\r\n\r\nFor somebody wanting to tackle this:\r\n- test it locally to see if there are big problems with building the docs\r\n- make a PR that ensures sphinx 2 is installed in the doc environment, so we can check the build log on travis (I am actually not fully sure why it is not yet picking up sphinx 2 on travis, since we don't pin the version in the [travis-36-doc.yaml file](https://github.com/pandas-dev/pandas/blob/a07ed594ec6a5befc967fb1b18244bbeb3bc2bf1/ci/deps/travis-36-doc.yaml#L36)", "patch": ""}
{"instance_id": "pandas-dev__pandas-10078", "file_changes": [{"file": "pandas/tests/frame/test_constructors.py", "changes": {}}, {"file": "pandas/tests/frame/test_missing.py", "changes": {"edited_modules": ["pandas/tests/frame/test_missing.py:TestDataFrameInterpolate"], "edited_entities": ["pandas/tests/frame/test_missing.py:TestDataFrameInterpolate.test_interp_ignore_all_good"]}}, {"file": "pandas/tests/groupby/test_apply.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_apply.py:test_apply_datetime_issue"], "edited_entities": ["pandas/tests/groupby/test_apply.py:test_apply_datetime_issue"]}}, {"file": "pandas/tests/groupby/test_categorical.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_categorical.py:test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans"], "edited_entities": ["pandas/tests/groupby/test_categorical.py:test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans"]}}, {"file": "pandas/tests/groupby/test_groupby.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_groupby.py:test_groupby_crash_on_nunique"], "edited_entities": ["pandas/tests/groupby/test_groupby.py:test_groupby_crash_on_nunique"]}}, {"file": "pandas/tests/indexing/multiindex/test_loc.py", "changes": {"edited_modules": ["pandas/tests/indexing/multiindex/test_loc.py:test_loc_nan_multiindex"], "edited_entities": ["pandas/tests/indexing/multiindex/test_loc.py:test_loc_nan_multiindex"]}}, {"file": "pandas/tests/indexing/test_loc.py", "changes": {"edited_modules": ["pandas/tests/indexing/test_loc.py:test_loc_setitem_float_intindex"], "edited_entities": ["pandas/tests/indexing/test_loc.py:test_loc_setitem_float_intindex"]}}, {"file": "pandas/tests/io/parser/test_index_col.py", "changes": {"edited_modules": ["pandas/tests/io/parser/test_index_col.py:test_multi_index_naming_not_all_at_beginning"], "edited_entities": ["pandas/tests/io/parser/test_index_col.py:test_multi_index_naming_not_all_at_beginning"]}}, {"file": "pandas/tests/reshape/test_concat.py", "changes": {"edited_modules": ["pandas/tests/reshape/test_concat.py:test_concat_datetimeindex_freq"], "edited_entities": ["pandas/tests/reshape/test_concat.py:test_concat_datetimeindex_freq"]}}, {"file": "pandas/tests/reshape/test_pivot.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "45d8d77f27cf0dbc8cefe932f8fb64f6982b9527", "problem_statement": "Pandas attempts to convert some strings to timestamps when grouping by a timestamp and aggregating?\n\nI am working through logs of web requests, and when I want to find the most common, say, user agent string for a (disguised) user, I run something like the following:\n\n```\nfrom pandas import Series, DataFrame, Timestamp\n\ntdf = DataFrame({'day': {0: Timestamp('2015-02-24 00:00:00'),  1: Timestamp('2015-02-24 00:00:00'),\n                                      2: Timestamp('2015-02-24 00:00:00'), 3: Timestamp('2015-02-24 00:00:00'),\n                                      4: Timestamp('2015-02-24 00:00:00')},\n                            'userAgent': {0: 'some UA string', 1: 'some UA string', 2: 'some UA string',\n                                                 3: 'another UA string', 4: 'some UA string'},\n                             'userId': {0: '17661101',  1: '17661101', 2: '17661101', 3: '17661101', 4: '17661101'}})\n\ndef most_common_values(df):\n    return Series({c: s.value_counts().index[0] for c,s in df.iteritems()})\n\ntdf.groupby('day').apply(most_common_values)\n```\n\nNote that in this (admittedly unusual) example, all of the lines are identical. I'm not sure if that is necessary to recreate the issue. And, I'm obscuring the exact purpose of this code, but it reproduces the bug: The 'userId' comes back as a Timestamp, not a string. This happens after the function most_common_values returns, since that userId string is not returned as a timestamp. if we change the value of the userId to an int:\n\n```\ntdf['userId'] = tdf.userId.astype(int)\n```\n\nor if the value of the associated integer  is small enough:\n\n```\ntdf['userId'] = '15320104`\n```\n\nthen the results are what we'd expect (the most common value as its original type is returned.)\n\nI imagine that for some reason something like a dateutil parser is being called on strings by default but that probably shoulnd't be happening...", "patch": ""}
{"instance_id": "pandas-dev__pandas-21356", "file_changes": [{"file": "doc/source/whatsnew/v0.23.1.txt", "changes": {}}, {"file": "pandas/io/json/normalize.py", "changes": {"edited_modules": ["pandas/io/json/normalize.py:nested_to_record"], "edited_entities": ["pandas/io/json/normalize.py:nested_to_record"]}}, {"file": "pandas/tests/io/json/test_normalize.py", "changes": {"edited_modules": ["pandas/tests/io/json/test_normalize.py:TestNestedToRecord", "pandas/tests/io/json/test_normalize.py:TestJSONNormalize"], "edited_entities": ["pandas/tests/io/json/test_normalize.py:TestNestedToRecord.test_nonetype_top_level_bottom_level", "pandas/tests/io/json/test_normalize.py:TestNestedToRecord.test_nonetype_multiple_levels", "pandas/tests/io/json/test_normalize.py:TestJSONNormalize.test_missing_field", "pandas/tests/io/json/test_normalize.py:TestNestedToRecord", "pandas/tests/io/json/test_normalize.py:TestNestedToRecord.test_nonetype_dropping"]}}], "repo": "pandas-dev/pandas", "base_commit": "636dd01fdacba0c8f0e7b5aaa726165983fc861d", "problem_statement": "JSON nested_to_record Silently Drops Top-Level None Values\n\nxref https://github.com/pandas-dev/pandas/pull/21164#issuecomment-394510095\r\n\r\n`nested_to_record` is silently dropping `None` values that appear at the top of the JSON. This is IMO unexpected and undesirable.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [3]: data = {\r\n   ...:     \"id\": None,\r\n   ...:     \"location\": {\r\n   ...:         \"country\": None\r\n   ...:     }\r\n   ...: }\r\n\r\nIn [5]: nested_to_record(data)\r\nOut[5]: {'location.country': None}\r\n```\r\n#### Problem description\r\n\r\nThe top level `None` value should not be dropped but rather preserved along with lower levels for consistency.\r\n\r\n#### Expected Output\r\n```python\r\nIn [5]: nested_to_record(data)\r\nOut[5]: {'id': None, 'location.country': None}\r\n```\r\n\r\nNote this will break a few tests in `pandas/test_normalize.py`\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: ab6aaf73a848a8725a23bb880be5221dd5ef5b3d\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 17.5.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.24.0.dev0+67.gab6aaf73a\r\npytest: 3.4.1\r\npip: 10.0.1\r\nsetuptools: 38.5.1\r\nCython: 0.27.3\r\nnumpy: 1.14.1\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: 0.10.0\r\nIPython: 6.2.1\r\nsphinx: 1.7.0\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: 0.4.0\r\nmatplotlib: 2.1.2\r\nopenpyxl: 2.5.0\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.5\r\npymysql: 0.8.0\r\npsycopg2: 2.7.4 (dt dec pq3 ext lo64)\r\njinja2: 2.10\r\ns3fs: 0.1.3\r\nfastparquet: 0.1.4\r\npandas_gbq: 0.4.1\r\npandas_datareader: None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-24607", "file_changes": [{"file": "pandas/_libs/missing.pyx", "changes": {}}, {"file": "pandas/_libs/tslibs/nattype.pxd", "changes": {}}, {"file": "pandas/_libs/tslibs/nattype.pyx", "changes": {}}, {"file": "pandas/_libs/tslibs/util.pxd", "changes": {}}, {"file": "pandas/tests/dtypes/test_missing.py", "changes": {"edited_modules": ["pandas/tests/dtypes/test_missing.py:TestNAObj"], "edited_entities": ["pandas/tests/dtypes/test_missing.py:TestNAObj.test_empty_like"]}}], "repo": "pandas-dev/pandas", "base_commit": "19f715c51d16995fc6cd0c102fdba2f213a83a0f", "problem_statement": "DES: Should util.is_nan check for complex('nan')?\n\nIt doesn't at the moment.  A handful of functions in libs.missing _do_ check for complex nan, and could be simplified/de-duplicated if we make util.is_nan also catch the complex case.", "patch": ""}
{"instance_id": "pandas-dev__pandas-7778", "file_changes": [{"file": "doc/source/v0.15.0.txt", "changes": {}}, {"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame._apply_standard"]}}, {"file": "pandas/core/internals.py", "changes": {"edited_modules": ["pandas/core/internals.py:BlockManager", "pandas/core/internals.py:_interleaved_dtype"], "edited_entities": ["pandas/core/internals.py:BlockManager.as_matrix", "pandas/core/internals.py:_interleaved_dtype"]}}, {"file": "pandas/core/series.py", "changes": {"edited_modules": ["pandas/core/series.py:Series"], "edited_entities": ["pandas/core/series.py:Series", "pandas/core/series.py:Series.from_array"]}}, {"file": "pandas/tests/test_frame.py", "changes": {"edited_modules": ["pandas/tests/test_frame.py:TestDataFrame"], "edited_entities": ["pandas/tests/test_frame.py:TestDataFrame"]}}, {"file": "pandas/tests/test_internals.py", "changes": {"edited_modules": ["pandas/tests/test_internals.py:create_block", "pandas/tests/test_internals.py:TestBlockManager"], "edited_entities": ["pandas/tests/test_internals.py:create_block", "pandas/tests/test_internals.py:TestBlockManager.test_interleave"]}}], "repo": "pandas-dev/pandas", "base_commit": "a797b28c87d90a439dfa2c12b4a11e62bf0d6db2", "problem_statement": "BUG: df.apply handles np.timedelta64 as timestamp, should be timedelta\n\nI think there may be a bug with the row-wise handling of `numpy.timedelta64` data types when using `DataFrame.apply`. As a check, the problem does not appear when using `DataFrame.applymap`. The problem may be related to #4532, but I'm unsure. I've included an example below.\n\nThis is only a minor problem for my use-case, which is cross-checking timestamps from a counter/timer card. I can easily work around the issue with `DataFrame.itertuples` etc.\n\nThank you for your time and for making such a useful package!\n#### Example\n##### Version\n\nImport and check versions.\n\n```\n$ date\nThu Jul 17 16:28:38 CDT 2014\n$ conda update pandas\nFetching package metadata: ..\n# All requested packages already installed.\n# packages in environment at /Users/harrold/anaconda:\n#\npandas                    0.14.1               np18py27_0  \n$ ipython\nPython 2.7.8 |Anaconda 2.0.1 (x86_64)| (default, Jul  2 2014, 15:36:00) \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython 2.1.0 -- An enhanced Interactive Python.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://binstar.org\n?         -> Introduction and overview of IPython's features.\n%quickref -> Quick reference.\nhelp      -> Python's own help system.\nobject?   -> Details about 'object', use 'object??' for extra details.\n\nIn [1]: from __future__ import print_function\n\nIn [2]: import numpy as np\n\nIn [3]: import pandas as pd\n\nIn [4]: pd.util.print_versions.show_versions()\n\nINSTALLED VERSIONS\n------------------\ncommit: None\npython: 2.7.8.final.0\npython-bits: 64\nOS: Darwin\nOS-release: 11.4.2\nmachine: x86_64\nprocessor: i386\nbyteorder: little\nLC_ALL: None\nLANG: en_US.UTF-8\n\npandas: 0.14.1\nnose: 1.3.3\nCython: 0.20.1\nnumpy: 1.8.1\nscipy: 0.14.0\nstatsmodels: 0.5.0\nIPython: 2.1.0\nsphinx: 1.2.2\npatsy: 0.2.1\nscikits.timeseries: None\ndateutil: 1.5\npytz: 2014.4\nbottleneck: None\ntables: 3.1.1\nnumexpr: 2.3.1\nmatplotlib: 1.3.1\nopenpyxl: 1.8.5\nxlrd: 0.9.3\nxlwt: 0.7.5\nxlsxwriter: 0.5.5\nlxml: 3.3.5\nbs4: 4.3.1\nhtml5lib: 0.999\nhttplib2: 0.8\napiclient: 1.2\nrpy2: None\nsqlalchemy: 0.9.4\npymysql: None\npsycopg2: None\n```\n##### Create test data\n\nUsing subset of original raw data as example.\n\n```\nIn [5]: datetime_start = np.datetime64(u'2014-05-31T01:23:19.9600345Z')\n\nIn [6]: timedeltas_elapsed = [30053400, 40053249, 50053098]\n```\n\nCompute datetimes from elapsed timedeltas, then create differential timedeltas from datetimes. All elements are either type `numpy.datetime64` or `numpy.timedelta64`.\n\n```\nIn [7]: df = pd.DataFrame(dict(datetimes = timedeltas_elapsed))\n\nIn [8]: df = df.applymap(lambda elt: np.timedelta64(elt, 'us'))\n\nIn [9]: df = df.applymap(lambda elt: np.datetime64(datetime_start + elt))\n\nIn [10]: df['differential_timedeltas'] = df['datetimes'] - df['datetimes'].shift()\n\nIn [11]: print(df)\n                      datetimes  differential_timedeltas\n0 2014-05-31 01:23:50.013434500                      NaT\n1 2014-05-31 01:24:00.013283500          00:00:09.999849\n2 2014-05-31 01:24:10.013132500          00:00:09.999849\n```\n##### Expected behavior\n\nWith element-wise handling using `DataFrame.applymap`, all elements are correctly identified as datetimes (timestamps) or timedeltas.\n\n```\nIn [12]: print(df.applymap(lambda elt: type(elt)))\n                          datetimes     differential_timedeltas\n0  <class 'pandas.tslib.Timestamp'>  <type 'numpy.timedelta64'>\n1  <class 'pandas.tslib.Timestamp'>  <type 'numpy.timedelta64'>\n2  <class 'pandas.tslib.Timestamp'>  <type 'numpy.timedelta64'>\n```\n##### Bug\n\nWith row-wise handling using `DataFrame.apply`, all elements are type `pandas.tslib.Timestamp`. I expected 'differential_timedeltas' to be type `numpy.timedelta64` or another type of timedelta, not a type of datetime (timestamp).\n\n```\nIn [13]: # For 'datetimes':\n\nIn [14]: print(df.apply(lambda row: type(row['datetimes']), axis=1))\n0    <class 'pandas.tslib.Timestamp'>\n1    <class 'pandas.tslib.Timestamp'>\n2    <class 'pandas.tslib.Timestamp'>\ndtype: object\n\nIn [15]: # For 'differential_timedeltas':\n\nIn [16]: print(df.apply(lambda row: type(row['differential_timedeltas']), axis=1))\n0      <class 'pandas.tslib.NaTType'>\n1    <class 'pandas.tslib.Timestamp'>\n2    <class 'pandas.tslib.Timestamp'>\ndtype: object\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-16991", "file_changes": [{"file": "doc/source/whatsnew/v0.21.0.txt", "changes": {}}, {"file": "pandas/core/algorithms.py", "changes": {"edited_modules": ["pandas/core/algorithms.py:_ensure_data"], "edited_entities": ["pandas/core/algorithms.py:_ensure_data"]}}, {"file": "pandas/tests/frame/test_analytics.py", "changes": {"edited_modules": ["pandas/tests/frame/test_analytics.py:TestDataFrameAnalytics"], "edited_entities": ["pandas/tests/frame/test_analytics.py:TestDataFrameAnalytics", "pandas/tests/frame/test_analytics.py:TestDataFrameAnalytics.test_isin_empty"]}}, {"file": "pandas/tests/indexes/test_base.py", "changes": {"edited_modules": ["pandas/tests/indexes/test_base.py:TestIndex"], "edited_entities": ["pandas/tests/indexes/test_base.py:TestIndex"]}}, {"file": "pandas/tests/series/test_analytics.py", "changes": {"edited_modules": ["pandas/tests/series/test_analytics.py:TestSeriesAnalytics"], "edited_entities": ["pandas/tests/series/test_analytics.py:TestSeriesAnalytics"]}}, {"file": "pandas/tests/test_algos.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "fcb0263762a31724ba6db39bf1564569dda068a0", "problem_statement": "ValueError on df.columns.isin(pd.Series())\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\n    df = pd.DataFrame(columns=list('ab'))\r\n    s1 = pd.Series(['a'])\r\n    s2 = pd.Series()\r\n    df.columns.isin(s1)\r\n    df.columns.isin(s2)\r\n\r\n```\r\n#### Problem description\r\n\r\nThe second call to `df.columns.isin(s2)` fails with \r\n\r\n    D:\\Anaconda\\envs\\py3k\\lib\\site-packages\\pandas\\core\\algorithms.py in <lambda>(x, y)\r\n        402     # work-around for numpy < 1.8 and comparisions on py3\r\n        403     # faster for larger cases to use np.in1d\r\n    --> 404     f = lambda x, y: htable.ismember_object(x, values)\r\n        405     if (_np_version_under1p8 and compat.PY3) or len(comps) > 1000000:\r\n        406         f = lambda x, y: np.in1d(x, y)\r\n\r\n    pandas\\_libs\\hashtable_func_helper.pxi in pandas._libs.hashtable.ismember_object (pandas\\_libs\\hashtable.c:30162)()\r\n\r\n    ValueError: Buffer dtype mismatch, expected 'Python object' but got 'double'\r\n\r\n#### Expected Output\r\n\r\n    array([ False, False], dtype=bool)\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n    INSTALLED VERSIONS\r\n    ------------------\r\n    commit: None\r\n    python: 3.5.3.final.0\r\n    python-bits: 64\r\n    OS: Windows\r\n    OS-release: 10\r\n    machine: AMD64\r\n\r\n    pandas: 0.20.3\r\n    numpy: 1.13.1\r\n\r\n\r\nMight be linked to [#16394](https://github.com/pandas-dev/pandas/issues/16394)", "patch": ""}
{"instance_id": "pandas-dev__pandas-51236", "file_changes": [{"file": "ci/code_checks.sh", "changes": {}}, {"file": "pandas/core/dtypes/common.py", "changes": {"edited_modules": ["pandas/core/dtypes/common.py:is_datetime64tz_dtype", "pandas/core/dtypes/common.py:is_datetime64_any_dtype", "pandas/core/dtypes/common.py:is_datetime64_ns_dtype"], "edited_entities": ["pandas/core/dtypes/common.py:is_datetime64tz_dtype", "pandas/core/dtypes/common.py:is_datetime64_any_dtype", "pandas/core/dtypes/common.py:is_datetime64_ns_dtype"]}}, {"file": "pandas/plotting/_core.py", "changes": {"edited_modules": ["pandas/plotting/_core.py:PlotAccessor"], "edited_entities": ["pandas/plotting/_core.py:PlotAccessor"]}}, {"file": "pandas/plotting/_misc.py", "changes": {"edited_modules": ["pandas/plotting/_misc.py:parallel_coordinates"], "edited_entities": ["pandas/plotting/_misc.py:parallel_coordinates"]}}], "repo": "pandas-dev/pandas", "base_commit": "0e8331f85cde8db2841aad92054d8e896e88fcef", "problem_statement": "DOC fix EX02 errors in docstrings\n\npandas has a script for validating docstrings\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/ced983358b06576af1a73c3e936171cc6dc98a6d/ci/code_checks.sh#L560-L568\r\n\r\nwhich can be run with\r\n```\r\n./ci/code_checks.sh docstrings\r\n```\r\n\r\nCurrently, many functions fail the EX02 check, and so are excluded from the check.\r\n\r\nThe task here is:\r\n1. pick 2-3 functions\r\n2. run `./ci/code_checks.sh docstrings`\r\n3. fixup the docstrings according to whatever error is reported\r\n4. stage, commit, push, open pull request \ud83d\ude80 \r\n\r\n**Please don't comment `take` as multiple people can work on this simultaneously**. You also don't need to ask for permission to work on this, feel free to just start \ud83d\ude04  Though if you're working on some set of functions you can comment that\r\n\r\nIf you're new here, please check the contributing guide https://pandas.pydata.org/docs/dev/development/contributing.html\r\n\r\nTIP: `./ci/code_checks.sh docstrings` may take a while to run - you may want to comment-out the `docstrings` check which checks `EX01` and the part which checks all the other codes (these are currently lines 86 - 577)", "patch": ""}
{"instance_id": "pandas-dev__pandas-10043", "file_changes": [{"file": "pandas/src/generate_code.py", "changes": {}}, {"file": "pandas/tests/test_common.py", "changes": {"edited_modules": ["pandas/tests/test_common.py:TestTake"], "edited_entities": ["pandas/tests/test_common.py:TestTake._test_dtype", "pandas/tests/test_common.py:TestTake.test_2d_with_out"]}}], "repo": "pandas-dev/pandas", "base_commit": "2e087c7841aec84030fb489cec9bfeb38fe8086f", "problem_statement": "iloc breaks on read-only dataframe\n\nThis is picking up #9928 again. I don't know if the behavior is expected, but it is a bit odd to me. Maybe I'm doing something wrong, I'm not that familiar with the pandas internals.\n\nWe call `df.iloc[indices]` and that breaks with a read-only dataframe. I feel that it shouldn't though, as it is not writing.\n\nMinimal reproducing example:\n\n``` python\nimport pandas as pd\nimport numpy as np\narray = np.eye(10)\narray.setflags(write=False)\n\nX = pd.DataFrame(array)\nX.iloc[[1, 2, 3]]\n```\n\n> ValueError buffer source array is read-only\n\nIs there a way to slice the rows of the dataframe in another way that doesn't need a writeable array?", "patch": ""}
{"instance_id": "pandas-dev__pandas-38495", "file_changes": [{"file": "asv_bench/benchmarks/groupby.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "89b3d6b201b5d429a202b5239054d5a70c8b5071", "problem_statement": "Major Performance regression of df.groupby(..).indices\n\nI'm experiencing major performance regressions with pandas=1.1.5 versus 1.1.3\r\n\r\nVersion 1.1.3:\r\n```\r\nPython 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 20:36:16) [MSC v.1916 64 bit (AMD64)]\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\nPyDev console: using IPython 7.19.0\r\nPython 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 20:36:16) [MSC v.1916 64 bit (AMD64)] on win32\r\nIn[2]: import time\r\n ... : import numpy as np\r\n ... : import pandas as pd\r\n ... : pd.__version__\r\nOut[2]: '1.1.3'\r\nIn[3]: numel = 10000000\r\n ... : df = pd.DataFrame(dict(a=np.random.rand(numel), b=np.random.randint(0,4000, numel)))\r\n ... : start = time.time()\r\n ... : groupby_indices = df.groupby('b').indices\r\n ... : time.time() - start\r\nOut[3]: 0.46085023880004883\r\n```\r\n\r\nVersion 1.1.5:\r\n```\r\nPython 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 20:36:16) [MSC v.1916 64 bit (AMD64)]\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.\r\nPyDev console: using IPython 7.19.0\r\nPython 3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 20:36:16) [MSC v.1916 64 bit (AMD64)] on win32\r\nIn[2]: import time\r\n ... : import numpy as np\r\n ... : import pandas as pd\r\n ... : pd.__version__\r\nOut[2]: '1.1.5'\r\nIn[3]: numel = 10000000\r\n ... : df = pd.DataFrame(dict(a=np.random.rand(numel), b=np.random.randint(0,4000, numel)))\r\n ... : start = time.time()\r\n ... : groupby_indices = df.groupby('b').indices\r\n ... : time.time() - start\r\nOut[3]: 57.36550998687744\r\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-37748", "file_changes": [{"file": "doc/source/whatsnew/v1.2.0.rst", "changes": {}}, {"file": "pandas/core/indexers.py", "changes": {"edited_modules": ["pandas/core/indexers.py:is_scalar_indexer"], "edited_entities": ["pandas/core/indexers.py:is_scalar_indexer"]}}, {"file": "pandas/tests/indexing/test_indexers.py", "changes": {}}, {"file": "pandas/tests/indexing/test_loc.py", "changes": {"edited_modules": ["pandas/tests/indexing/test_loc.py:TestLocSeries"], "edited_entities": ["pandas/tests/indexing/test_loc.py:TestLocSeries.test_loc_setitem_dt64tz_values"]}}], "repo": "pandas-dev/pandas", "base_commit": "03e58585036c83ca3d4c86d7d3d7ede955c15130", "problem_statement": "BUG: ValueError is mistakenly raised if a numpy array is assigned to a pd.Series of dtype=object and both have the same length\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\npd.__version__ #  '1.1.3'\r\npdseries = pd.Series(index=[1,2,3,4], dtype=object)\r\npdseries.loc[1] = np.zeros(100)  # this works fine\r\npdseries.loc[3] = np.zeros(4)     # this raises a value error because len(pdseries)==len(np.zeros(4))\r\n```\r\n\r\nTypeError: only size-1 arrays can be converted to Python scalars\r\nThe above exception was the direct cause of the following exception:\r\nTraceback (most recent call last):\r\n  File \"/Users/daniel/.conda/envs/production_system/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-40-460230264bf1>\", line 1, in <module>\r\n    pdseries.loc[3] = np.zeros(4)\r\n  File \"/Users/daniel/.conda/envs/production_system/lib/python3.7/site-packages/pandas/core/indexing.py\", line 670, in __setitem__\r\n    iloc._setitem_with_indexer(indexer, value)\r\n  File \"/Users/daniel/.conda/envs/production_system/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1802, in _setitem_with_indexer\r\n    self.obj._mgr = self.obj._mgr.setitem(indexer=indexer, value=value)\r\n  File \"/Users/daniel/.conda/envs/production_system/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 534, in setitem\r\n    return self.apply(\"setitem\", indexer=indexer, value=value)\r\n  File \"/Users/daniel/.conda/envs/production_system/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 406, in apply\r\n    applied = getattr(b, f)(**kwargs)\r\n  File \"/Users/daniel/.conda/envs/production_system/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 887, in setitem\r\n    values = values.astype(arr_value.dtype, copy=False)\r\nValueError: setting an array element with a sequence.\r\n\r\n#### Problem description\r\n\r\nIt is possible to assign (numpy) arrays to elements of pandas.Series ofd type=object. Unfortunately, in case the array is of the same size as the Series a ValueError is raised.\r\n\r\nHow can one avoid this error?\r\n\r\n#### Expected Output\r\n\r\nThe interesting thing is that the assignment takes place as expected:\r\nIn[42]: pdseries\r\nOut[42]: \r\n1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\r\n2                                                  NaN\r\n3                                 [0.0, 0.0, 0.0, 0.0]\r\n4                                                  NaN\r\n\r\nOne might argue that a warning could be useful but an error is misleading and tricky to debug.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : db08276bc116c438d3fdee492026f8223584c477\r\npython           : 3.7.8.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.6.0\r\nVersion          : Darwin Kernel Version 19.6.0: Mon Aug 31 22:12:52 PDT 2020; root:xnu-6153.141.2~1/RELEASE_X86_64\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : None\r\nLOCALE           : None.UTF-8\r\npandas           : 1.1.3\r\nnumpy            : 1.19.2\r\npytz             : 2020.1\r\ndateutil         : 2.8.1\r\npip              : 20.2.4\r\nsetuptools       : 49.6.0.post20201009\r\nCython           : 0.29.21\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : 2.8.6 (dt dec pq3 ext lo64)\r\njinja2           : 2.11.2\r\nIPython          : 5.8.0\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : 3.3.2\r\nnumexpr          : 2.7.1\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npytables         : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.2.1\r\nsqlalchemy       : 1.3.20\r\ntables           : 3.6.1\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-49247", "file_changes": [{"file": "pandas/core/reshape/pivot.py", "changes": {"edited_modules": ["pandas/core/reshape/pivot.py:__internal_pivot_table"], "edited_entities": ["pandas/core/reshape/pivot.py:__internal_pivot_table"]}}, {"file": "pandas/tests/reshape/test_pivot.py", "changes": {"edited_modules": ["pandas/tests/reshape/test_pivot.py:TestPivotTable"], "edited_entities": ["pandas/tests/reshape/test_pivot.py:TestPivotTable.test_pivot_table_nocols", "pandas/tests/reshape/test_pivot.py:TestPivotTable.test_no_col", "pandas/tests/reshape/test_pivot.py:TestPivotTable.test_margin_with_only_columns_defined", "pandas/tests/reshape/test_pivot.py:TestPivotTable.test_pivot_string_func_vs_func"]}}, {"file": "pandas/util/_exceptions.py", "changes": {"edited_modules": ["pandas/util/_exceptions.py:find_stack_level"], "edited_entities": ["pandas/util/_exceptions.py:find_stack_level"]}}], "repo": "pandas-dev/pandas", "base_commit": "f09d514cf0b09e65baf210a836de04e69b208cef", "problem_statement": "BUG: Getting FutureWarning for Groupby.mean when using .pivot_table\n\n### Pandas version checks\n\n- [X] I have checked that this issue has not already been reported.\n\n- [X] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.\n\n- [X] I have confirmed this bug exists on the main branch of pandas.\n\n\n### Reproducible Example\n\n```python\nimport pandas as pd\r\ndf = pd.DataFrame({\"C1\": [\"a\", \"b\", \"c\"],\r\n                   \"C2\": [1, 2, 3]})\r\ntable = pd.pivot_table(df, columns=['C2'])\n```\n\n\n### Issue Description\n\nGetting FutureWarning:\r\n\r\n\"<stdin>:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\"\n\n### Expected Behavior\n\npivot_table is internally using DataFrameGroupBy.mean, but does not allow a user to pass a numeric_only argument as suggested in the FutureWarning\n\n### Installed Versions\n\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 91111fd99898d9dcaa6bf6bedb662db4108da6e6\r\npython           : 3.9.13.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 4.4.0-19041-Microsoft\r\nVersion          : #1237-Microsoft Sat Sep 11 14:32:00 PST 2021\r\nmachine          : x86_64\r\nprocessor        : x86_64\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : C.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 1.5.1\r\nnumpy            : 1.23.4\r\npytz             : 2022.5\r\ndateutil         : 2.8.2\r\nsetuptools       : 65.5.0\r\npip              : 22.3\r\nCython           : None\r\npytest           : 7.1.3\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 3.1.2\r\nIPython          : 8.5.0\r\npandas_datareader: None\r\nbs4              : 4.11.1\r\nbottleneck       : None\r\nbrotli           :\r\nfastparquet      : None\r\nfsspec           : 2022.10.0\r\ngcsfs            : None\r\nmatplotlib       : 3.6.1\r\nnumba            : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : None\r\npyreadstat       : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.9.2\r\nsnappy           : None\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nzstandard        : None\r\ntzdata           : None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-8169", "file_changes": [{"file": "doc/source/v0.15.0.txt", "changes": {}}, {"file": "pandas/core/groupby.py", "changes": {"edited_modules": ["pandas/core/groupby.py:_count_compat", "pandas/core/groupby.py:BaseGrouper", "pandas/core/groupby.py:NDFrameGroupBy"], "edited_entities": ["pandas/core/groupby.py:_count_compat", "pandas/core/groupby.py:BaseGrouper.aggregate", "pandas/core/groupby.py:NDFrameGroupBy._cython_agg_blocks"]}}, {"file": "pandas/tests/test_groupby.py", "changes": {"edited_modules": ["pandas/tests/test_groupby.py:TestGroupBy"], "edited_entities": ["pandas/tests/test_groupby.py:TestGroupBy"]}}], "repo": "pandas-dev/pandas", "base_commit": "e226bacd9e0d69ce3a81abfa09ae850f4610f888", "problem_statement": "BUG: groupby.count() on different dtypes seems buggy\n\nfrom [SO](http://stackoverflow.com/questions/25648923/groupby-count-returns-different-values-for-pandas-dataframe-count-vs-describ)\n\nsomething odd going on here:\n\n```\nvals = np.hstack((np.random.randint(0,5,(100,2)), np.random.randint(0,2,(100,2))))\ndf = pd.DataFrame(vals, columns=['a', 'b', 'c', 'd'])\ndf[df==2] = np.nan\ndf2 = df.copy()\ndf2['a'] = df2['a'].astype('float32')\ndf2['b'] = df2['b'].astype('float32')\n```\n\n```\ndf.groupby(['c', 'd']).count()\ndf2.groupby(['c','d']).count()\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-4312", "file_changes": [{"file": "doc/source/release.rst", "changes": {}}, {"file": "pandas/core/common.py", "changes": {"edited_modules": ["pandas/core/common.py:_possibly_downcast_to_dtype", "pandas/core/common.py:_maybe_upcast_indexer"], "edited_entities": ["pandas/core/common.py:_possibly_downcast_to_dtype", "pandas/core/common.py:_maybe_upcast_indexer"]}}, {"file": "pandas/core/groupby.py", "changes": {"edited_modules": ["pandas/core/groupby.py:SeriesGroupBy"], "edited_entities": ["pandas/core/groupby.py:SeriesGroupBy.transform"]}}, {"file": "pandas/core/indexing.py", "changes": {"edited_modules": ["pandas/core/indexing.py:_NDFrameIndexer"], "edited_entities": ["pandas/core/indexing.py:_NDFrameIndexer.setter"]}}, {"file": "pandas/core/internals.py", "changes": {"edited_modules": ["pandas/core/internals.py:Block", "pandas/core/internals.py:DatetimeBlock", "pandas/core/internals.py:NumericBlock"], "edited_entities": ["pandas/core/internals.py:Block", "pandas/core/internals.py:DatetimeBlock", "pandas/core/internals.py:DatetimeBlock._try_coerce_args", "pandas/core/internals.py:Block._try_cast_result", "pandas/core/internals.py:Block.setitem", "pandas/core/internals.py:Block.create_block", "pandas/core/internals.py:NumericBlock", "pandas/core/internals.py:DatetimeBlock._can_hold_element"]}}, {"file": "pandas/tests/test_common.py", "changes": {"edited_modules": ["pandas/tests/test_common.py:test_nan_to_nat_conversions"], "edited_entities": ["pandas/tests/test_common.py:test_nan_to_nat_conversions"]}}, {"file": "pandas/tests/test_frame.py", "changes": {"edited_modules": ["pandas/tests/test_frame.py:TestDataFrame"], "edited_entities": ["pandas/tests/test_frame.py:TestDataFrame.test_where"]}}, {"file": "pandas/tests/test_indexing.py", "changes": {"edited_modules": ["pandas/tests/test_indexing.py:TestIndexing"], "edited_entities": ["pandas/tests/test_indexing.py:TestIndexing.test_ix_assign_column_mixed"]}}], "repo": "pandas-dev/pandas", "base_commit": "9ea0d4485e77c95ff0d8766990ab55d43472b66e", "problem_statement": "BUG: astype assignment via iloc/loc not working\n\nhttp://stackoverflow.com/questions/17778139/pandas-unable-to-change-column-data-type/17778560#17778560\n\nThis might be trying to coerce `object` dtype to a real dtype (int/float) and is failing\nShould prob raise for now (or work). Not working with iloc/loc.\n\n```\nIn [66]: df = DataFrame([['1','2','3','.4',5,6.,'foo']],columns=list('ABCDEFG'))\n\nIn [67]: df.dtypes\nOut[67]: \nA     object\nB     object\nC     object\nD     object\nE      int64\nF    float64\nG     object\ndtype: object\n\nIn [68]: df.iloc[:,0:3] = df.iloc[:,0:3].astype(int)\n\nIn [69]: df.dtypes\nOut[69]: \nA     object\nB     object\nC     object\nD     object\nE      int64\nF    float64\nG     object\ndtype: object\n\nIn [70]: df.iloc[:,0:3] = df.iloc[:,0:3].convert_objects(convert_numeric=True)\n\nIn [71]: df.dtypes\nOut[71]: \nA     object\nB     object\nC     object\nD     object\nE      int64\nF    float64\nG     object\ndtype: object\n\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-40730", "file_changes": [{"file": "doc/source/whatsnew/v1.3.0.rst", "changes": {}}, {"file": "pandas/core/reshape/tile.py", "changes": {"edited_modules": ["pandas/core/reshape/tile.py:_coerce_to_type"], "edited_entities": ["pandas/core/reshape/tile.py:_coerce_to_type"]}}, {"file": "pandas/tests/reshape/test_qcut.py", "changes": {"edited_modules": ["pandas/tests/reshape/test_qcut.py:test_qcut_nullable_integer"], "edited_entities": ["pandas/tests/reshape/test_qcut.py:test_qcut_nullable_integer"]}}], "repo": "pandas-dev/pandas", "base_commit": "70435eba769c6bcf57332306455eb70db9fa1111", "problem_statement": "BUG: qcut fails with Float64Dtype\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\nseries = pd.Series([1.0, 2.0, 3.0, 4.4], dtype=pd.Float64Dtype())\r\npd.qcut(series, 2)\r\n```\r\n\r\n#### Problem description\r\n`pd.qcut` currently accepts the nullable `Int64Dtype` as well as `'float64'`, so I would expect it to work with the `Float64Dtype` as well. Instead the following error is produced:\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-29-1db98f70db38> in <module>\r\n      1 series = pd.Series([1.0,2.0,3.0,4.0], dtype=pd.Float64Dtype())\r\n----> 2 pd.qcut(series, 2)\r\n\r\n~/.pyenv/versions/3.8.2/envs/woodwork/lib/python3.8/site-packages/pandas/core/reshape/tile.py in qcut(x, q, labels, retbins, precision, duplicates)\r\n    356         quantiles = q\r\n    357     bins = algos.quantile(x, quantiles)\r\n--> 358     fac, bins = _bins_to_cuts(\r\n    359         x,\r\n    360         bins,\r\n\r\n~/.pyenv/versions/3.8.2/envs/woodwork/lib/python3.8/site-packages/pandas/core/reshape/tile.py in _bins_to_cuts(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\r\n    408 \r\n    409     if include_lowest:\r\n--> 410         ids[x == bins[0]] = 1\r\n    411 \r\n    412     na_mask = isna(x) | (ids == len(bins)) | (ids == 0)\r\n\r\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\r\n```\r\n\r\n#### Expected Output\r\nShould match that of `float64`\r\n\r\n```\r\n0    (0.999, 2.5]\r\n1    (0.999, 2.5]\r\n2      (2.5, 4.0]\r\n3      (2.5, 4.0]\r\ndtype: category\r\nCategories (2, interval[float64]): [(0.999, 2.5] < (2.5, 4.0]]\r\n```\r\n\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : f2c8480af2f25efdbd803218b9d87980f416563e\r\npython           : 3.8.2.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.6.0\r\nVersion          : Darwin Kernel Version 19.6.0: Sun Jul  5 00:43:10 PDT 2020; root:xnu-6153.141.1~9/RELEASE_X86_64\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 1.2.3\r\nnumpy            : 1.19.5\r\npytz             : 2021.1\r\ndateutil         : 2.8.1\r\npip              : 21.0.1\r\nsetuptools       : 41.2.0\r\nCython           : None\r\npytest           : 6.0.1\r\nhypothesis       : None\r\nsphinx           : 3.2.1\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.11.3\r\nIPython          : 7.18.1\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : 0.8.7\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : 3.0.0\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : 1.6.2\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-19787", "file_changes": [{"file": ".gitignore", "changes": {}}, {"file": "pandas/core/arrays/categorical.py", "changes": {"edited_modules": ["pandas/core/arrays/categorical.py:Categorical"], "edited_entities": ["pandas/core/arrays/categorical.py:Categorical.fillna"]}}], "repo": "pandas-dev/pandas", "base_commit": "38afa9310040f1bd4fb122008e96fe6d719b12a2", "problem_statement": "Clean: Categorical.fillna NaN in categories checking\n\nWe don't allow NaN in the categories anymore, so this block should be unreachable.\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/8bfcddc7728deaf8e840416d83c8feda86630d27/pandas/core/arrays/categorical.py#L1622-L1628\r\n\r\nIf anyone wants to remove it and test things out.", "patch": ""}
{"instance_id": "pandas-dev__pandas-9570", "file_changes": [{"file": "doc/source/whatsnew/v0.16.1.txt", "changes": {}}, {"file": "pandas/tseries/tests/test_timedeltas.py", "changes": {"edited_modules": ["pandas/tseries/tests/test_timedeltas.py:TestTimedeltas"], "edited_entities": ["pandas/tseries/tests/test_timedeltas.py:TestTimedeltas.test_construction"]}}, {"file": "pandas/tseries/timedeltas.py", "changes": {"edited_modules": ["pandas/tseries/timedeltas.py:convert"], "edited_entities": ["pandas/tseries/timedeltas.py:convert"]}}], "repo": "pandas-dev/pandas", "base_commit": "2dad23f766790510d09e66f1e02b57a395d479b1", "problem_statement": "timedelta string conversion requires two-digit hour value\n\n`Timedelta('00:00:00')` works fine whereas `Timedelta('0:00:00')` raises and error. Unsure whether to call this a bug, but under some circumstances the `datetime` module in pure python will produce time delta strings without the leading 0.", "patch": ""}
{"instance_id": "pandas-dev__pandas-3925", "file_changes": [{"file": "RELEASE.rst", "changes": {}}, {"file": "pandas/core/indexing.py", "changes": {}}, {"file": "pandas/tseries/index.py", "changes": {"edited_modules": ["pandas/tseries/index.py:DatetimeIndex"], "edited_entities": ["pandas/tseries/index.py:DatetimeIndex._partial_date_slice"]}}, {"file": "pandas/tseries/tests/test_timeseries.py", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "b03df731095154e94d23db51d11df5dd736622f8", "problem_statement": "Access DateTimeIndexed dataframe by timestamp\n\nHello, \n\nI am new to pandas and thanks for this great library!\n\nI have a data frame like this: \n\n```\nGold_2012.head()\n\n                              open  high    low close   volume\ndate_time                   \n2012-01-02 18:01:00  1571.0  1571.0  1569.1  1569.8  351\n2012-01-02 18:02:00  1569.8  1570.0  1569.7  1569.8  54\n2012-01-02 18:03:00  1570.0  1570.0  1569.1  1569.9  247\n2012-01-02 18:04:00  1570.0  1570.0  1569.8  1569.9  55\n2012-01-02 18:05:00  1569.8  1569.9  1568.5  1568.5  48\n```\n\nI am trying to access the first element of this dataframe. If I use loc function, everything works out:\n\n```\nGold_2012.loc[Gold_2012.index[0]]\n\n\nopen      1571.0\nhigh      1571.0\nlow       1569.1\nclose     1569.8\nvolume     351.0\nName: 2012-01-02 18:01:00-06:00, dtype: float64\n```\n\nBut if I do something like this, an error is thrown. Is this expected?\n\n```\nGold_2012[Gold_2012.index[0]]\n```\n\n---\n\nKeyError                                  Traceback (most recent call last)\n<ipython-input-30-bb7117766fdd> in <module>()\n----> 1 Gold_2012[Gold_2012.index[0]]\n\n/Users/chen/Virtualenvs/python3Env/lib/python3.3/site-packages/pandas/core/frame.py in **getitem**(self, key)\n   1926         else:\n   1927             # get column\n-> 1928             return self._get_item_cache(key)\n   1929 \n   1930     def _getitem_slice(self, key):\n\n/Users/chen/Virtualenvs/python3Env/lib/python3.3/site-packages/pandas/core/generic.py in _get_item_cache(self, item)\n    568             return cache[item]\n    569         except Exception:\n--> 570             values = self._data.get(item)\n    571             res = self._box_item_values(item, values)\n    572             cache[item] = res\n\n/Users/chen/Virtualenvs/python3Env/lib/python3.3/site-packages/pandas/core/internals.py in get(self, item)\n   1382 \n   1383     def get(self, item):\n-> 1384         _, block = self._find_block(item)\n   1385         return block.get(item)\n   1386 \n\n/Users/chen/Virtualenvs/python3Env/lib/python3.3/site-packages/pandas/core/internals.py in _find_block(self, item)\n   1524 \n   1525     def _find_block(self, item):\n-> 1526         self._check_have(item)\n   1527         for i, block in enumerate(self.blocks):\n   1528             if item in block:\n\n/Users/chen/Virtualenvs/python3Env/lib/python3.3/site-packages/pandas/core/internals.py in _check_have(self, item)\n   1531     def _check_have(self, item):\n   1532         if item not in self.items:\n-> 1533             raise KeyError('no item named %s' % com.pprint_thing(item))\n   1534 \n   1535     def reindex_axis(self, new_axis, method=None, axis=0, copy=True):\n\nKeyError: 'no item named 2012-01-02 18:01:00-06:00'", "patch": ""}
{"instance_id": "pandas-dev__pandas-35331", "file_changes": [{"file": "pandas/tests/series/test_npfuncs.py", "changes": {"edited_modules": ["pandas/tests/series/test_npfuncs.py:test_numpy_unique"], "edited_entities": ["pandas/tests/series/test_npfuncs.py:test_numpy_unique"]}}], "repo": "pandas-dev/pandas", "base_commit": "f231c9a74a544ec94cd12e813cb2543fb5a18556", "problem_statement": "BUG: np.argwhere on pandas series\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\nnumpy/numpy#15555 reports an issue with `np.argwhere` on pandas Series. Reporting here for visibility.\r\n\r\nMRE:\r\n```python\r\n>>> import numpy as np\r\n>>> import pandas as pd\r\n>>> s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\r\n>>> np.argwhere(s < 0)\r\n```\r\nwhich, with `numpy.__version__ ==1.20.0.dev0+046a736`  gives:\r\n**pd.__version__ == 0.25.3:**\r\n```\r\nFutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\r\narray([[3]])\r\n```\r\n**pd.__version__ == 1.0.5:**\r\n```\r\nValueError: Length of passed values is 1, index implies 5.\r\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-12081", "file_changes": [{"file": "doc/source/whatsnew/v0.18.0.txt", "changes": {}}, {"file": "pandas/tools/merge.py", "changes": {"edited_modules": ["pandas/tools/merge.py:_MergeOperation"], "edited_entities": ["pandas/tools/merge.py:_MergeOperation.__init__"]}}, {"file": "pandas/tools/tests/test_merge.py", "changes": {"edited_modules": ["pandas/tools/tests/test_merge.py:TestMerge"], "edited_entities": ["pandas/tools/tests/test_merge.py:TestMerge"]}}], "repo": "pandas-dev/pandas", "base_commit": "5de6b84f5117b005a8f010d4510a758b50f3d14e", "problem_statement": "DataFrame.merge with Series should give nice error message\n\nRight now trying this results in \"IndexError: list index out of range\". It should say can't merge DataFrame with a Series...\n\nI know this for quite a while now, but still get trapped on it every once in a while. This would be very helpful for beginners.\n\nOther people also get confused: http://stackoverflow.com/questions/27281734/pandas-merge-on-index-not-working", "patch": ""}
{"instance_id": "pandas-dev__pandas-44597", "file_changes": [{"file": "doc/source/whatsnew/v1.4.0.rst", "changes": {}}, {"file": "pandas/core/internals/blocks.py", "changes": {"edited_modules": ["pandas/core/internals/blocks.py:Block"], "edited_entities": ["pandas/core/internals/blocks.py:Block.where"]}}, {"file": "pandas/tests/frame/indexing/test_where.py", "changes": {"edited_modules": ["pandas/tests/frame/indexing/test_where.py:TestDataFrameIndexingWhere"], "edited_entities": ["pandas/tests/frame/indexing/test_where.py:TestDataFrameIndexingWhere.test_where_axis", "pandas/tests/frame/indexing/test_where.py:TestDataFrameIndexingWhere", "pandas/tests/frame/indexing/test_where.py:TestDataFrameIndexingWhere.test_where_alignment"]}}, {"file": "pandas/tests/frame/methods/test_clip.py", "changes": {"edited_modules": ["pandas/tests/frame/methods/test_clip.py:TestDataFrameClip"], "edited_entities": ["pandas/tests/frame/methods/test_clip.py:TestDataFrameClip", "pandas/tests/frame/methods/test_clip.py:TestDataFrameClip.test_clip_with_na_args"]}}], "repo": "pandas-dev/pandas", "base_commit": "a3c0e7bcfb8bbe9ca45df7e571a305d403e0f066", "problem_statement": "API/DEPR: int downcasting in DataFrame.where\n\n`Block.where` has special downcasting logic that splits blocks differently from any other Block methods.  I would like to deprecate and eventually remove this bespoke logic.\r\n\r\nThe relevant logic is only reached AFAICT when we have integer dtype (non-int64) and an integer `other` too big for this dtype, AND the passed `cond` has all-`True` columns.\r\n\r\n(Identifying the affected behavior is difficult in part because it relies on `can_hold_element` incorrectly returning `True` in these cases)\r\n\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\narr = np.arange(6).astype(np.int16).reshape(3, 2)\r\ndf = pd.DataFrame(arr)\r\n\r\nmask = np.zeros(arr.shape, dtype=bool)\r\nmask[:, 0] = True\r\n\r\nres = df.where(mask, 2**17)\r\n\r\n>>> res.dtypes\r\n0    int16\r\n1    int32\r\ndtype: object\r\n```\r\n\r\nThe simplest thing to do would be to not do any downcasting in these cases, in which case we would end up with all-int32.  The next simplest would be to downcast column-wise, which would give the same end result but with less consolidation.\r\n\r\nWe do not have any test cases that fail if I disable this downcasting (after I fix a problem with an expressions.where call that the downcasting somehow makes irrelevant).  This makes me think the current behavior is not intentional, or at least not a priority.\r\n\r\nAny objection to deprecating the integer downcasting entirely?", "patch": ""}
{"instance_id": "pandas-dev__pandas-52151", "file_changes": [{"file": "pandas/core/groupby/ops.py", "changes": {"edited_modules": ["pandas/core/groupby/ops.py:WrappedCythonOp"], "edited_entities": ["pandas/core/groupby/ops.py:WrappedCythonOp._ea_wrap_cython_operation"]}}, {"file": "pandas/tests/groupby/test_min_max.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_min_max.py:test_min_max_nullable_uint64_empty_group"], "edited_entities": ["pandas/tests/groupby/test_min_max.py:test_min_max_nullable_uint64_empty_group"]}}], "repo": "pandas-dev/pandas", "base_commit": "32f789fbc5d5a72d9d1ac14935635289eeac9009", "problem_statement": "BUG: Inconsistent behavior with `groupby/min` and `observed=False` on categoricals between 2.0 and 2.1\n\n### Pandas version checks\r\n\r\n- [X] I have checked that this issue has not already been reported.\r\n\r\n- [X] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.\r\n\r\n- [X] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.\r\n\r\n\r\n### Reproducible Example\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndf = pd.DataFrame({\r\n    \"cat_1\": pd.Categorical(list(\"AB\"), categories=list(\"ABCDE\"), ordered=True),\r\n    \"cat_2\": pd.Categorical([1, 2], categories=[1, 2, 3], ordered=True),\r\n    \"value_1\": np.random.uniform(size=2),\r\n})\r\n\r\nchunk1 = df[df.cat_1 == \"A\"]\r\nchunk2 = df[df.cat_1 == \"B\"]\r\n\r\ndf1 = chunk1.groupby(\"cat_1\", observed=False).min()\r\ndf2 = chunk2.groupby(\"cat_1\", observed=False).min()\r\ndf3 = pd.concat([df1, df2], ignore_index=False)\r\n\r\nres3 = df3.groupby(level=0, observed=False).min()\r\nprint(f\"\\n{res3}\")\r\n```\r\n\r\n\r\n### Issue Description\r\n\r\nWhen performing a `groupby/min` with a categorical dtype and `observed=False`, the results differ between `1.5.3` (and `2.0`) and 2.1.\r\n\r\nOutput with 1.5.3 or 2.0:\r\n\r\n```python\r\n      cat_2   value_1\r\ncat_1\r\nA         1  0.384993\r\nB         2  0.955231\r\nC       NaN       NaN\r\nD       NaN       NaN\r\nE       NaN       NaN\r\n```\r\n\r\nOutput with the latest `main`:\r\n\r\n```python\r\n      cat_2   value_1\r\ncat_1\r\nA         1  0.297557\r\nB         1  0.081856\r\nC         1       NaN\r\nD         1       NaN\r\nE         1       NaN\r\n```\r\n\r\nThe change can be traced to this PR:\r\n\r\n* https://github.com/pandas-dev/pandas/pull/52120\r\n\r\n### Expected Behavior\r\n\r\nI'm not sure if the changed behavior is intended. Please advise.\r\n\r\n### Installed Versions\r\n\r\n<details>\r\n\r\ncommit           : d22d1f2db0bc7846f679b2b0a572216f23fa83cc\r\npython           : 3.8.16.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 22.3.0\r\nVersion          : Darwin Kernel Version 22.3.0: Thu Jan  5 20:50:36 PST 2023; root:xnu-8792.81.2~2/RELEASE_ARM64_T6020\r\nmachine          : arm64\r\nprocessor        : arm\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : en_US.UTF-8\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 2.1.0.dev0+293.gd22d1f2db0\r\nnumpy            : 1.23.5\r\npytz             : 2022.7.1\r\ndateutil         : 2.8.2\r\nsetuptools       : 67.4.0\r\npip              : 23.0.1\r\nCython           : 0.29.33\r\npytest           : 7.2.1\r\nhypothesis       : 6.68.2\r\nsphinx           : 4.5.0\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : 3.0.8\r\nlxml.etree       : 4.9.2\r\nhtml5lib         : 1.1\r\npymysql          : 1.0.2\r\npsycopg2         : 2.9.3\r\njinja2           : 3.1.2\r\nIPython          : 8.11.0\r\npandas_datareader: None\r\nbs4              : 4.11.2\r\nbottleneck       : 1.3.6\r\nbrotli           :\r\nfastparquet      : 2023.2.0\r\nfsspec           : 2023.1.0\r\ngcsfs            : 2023.1.0\r\nmatplotlib       : 3.6.3\r\nnumba            : 0.56.4\r\nnumexpr          : 2.8.3\r\nodfpy            : None\r\nopenpyxl         : 3.1.0\r\npandas_gbq       : None\r\npyarrow          : 11.0.0\r\npyreadstat       : 1.2.1\r\npyxlsb           : 1.0.10\r\ns3fs             : 2023.1.0\r\nscipy            : 1.10.1\r\nsnappy           :\r\nsqlalchemy       : 2.0.4\r\ntables           : 3.7.0\r\ntabulate         : 0.9.0\r\nxarray           : 2023.1.0\r\nxlrd             : 2.0.1\r\nzstandard        : 0.19.0\r\ntzdata           : None\r\nqtpy             : None\r\npyqt5            : None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-41556", "file_changes": [{"file": "asv_bench/benchmarks/groupby.py", "changes": {}}, {"file": "doc/source/whatsnew/v1.4.0.rst", "changes": {}}, {"file": "pandas/core/groupby/groupby.py", "changes": {"edited_modules": ["pandas/core/groupby/groupby.py:GroupBy"], "edited_entities": ["pandas/core/groupby/groupby.py:GroupBy._get_cythonized_result", "pandas/core/groupby/groupby.py:GroupBy.shift", "pandas/core/groupby/groupby.py:GroupBy.blk_func"]}}, {"file": "pandas/tests/groupby/test_groupby_shift_diff.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_groupby_shift_diff.py:test_group_shift_with_fill_value"], "edited_entities": ["pandas/tests/groupby/test_groupby_shift_diff.py:test_group_shift_with_fill_value"]}}], "repo": "pandas-dev/pandas", "base_commit": "8924277fa3dbe775f46e679ab8bd97b293e465ea", "problem_statement": "BUG: groupby.shift return keys filled with `fill_value` when `fill_value` is specified\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\nIn [2]: df = pd.DataFrame({'a': [2, 1, 2, 1], 'b': ['x', 'x', 'y', 'y']})\r\n\r\nIn [3]: df.groupby('a').shift(1)\r\nOut[3]: \r\n     b\r\n0  NaN\r\n1  NaN\r\n2    x\r\n3    x\r\n\r\nIn [4]: df.groupby('a').shift(1, fill_value='fill')\r\nOut[4]: \r\n      a     b\r\n0  fill  fill\r\n1  fill  fill\r\n2     2     x\r\n3     1     x\r\n```\r\n\r\n#### Problem description\r\nWhen specifying `fill_value` in `groupby.shift`, the returned result includes the key column with keys filled with `fill_value`. When `fill_value` is unspecified (None), the key column is not included.\r\n\r\n#### Expected Output\r\nIt seems pretty strange that keys are to be filled with `fill_value`. This makes more sense to me:\r\n```python\r\nIn [4]: df.groupby('a').shift(1, fill_value='fill')\r\nOut[4]: \r\n      b\r\n0  fill\r\n1  fill\r\n2    x\r\n3    x\r\n```\r\n\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 2cb96529396d93b46abab7bbc73a208e708c642e\r\npython           : 3.7.10.final.0\r\npython-bits      : 64\r\nOS               : Linux\r\nOS-release       : 4.15.0-76-generic\r\nVersion          : #86-Ubuntu SMP Fri Jan 17 17:24:28 UTC 2020\r\nmachine          : x86_64\r\nprocessor        : x86_64\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : None\r\nLOCALE           : en_US.UTF-8\r\n\r\npandas           : 1.2.4\r\nnumpy            : 1.20.2\r\npytz             : 2021.1\r\ndateutil         : 2.8.1\r\npip              : 21.1.1\r\nsetuptools       : 52.0.0.post20210125\r\nCython           : 0.29.23\r\npytest           : 6.2.4\r\nhypothesis       : 6.12.0\r\nsphinx           : 3.5.4\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : 2.11.3\r\nIPython          : 7.23.1\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : 2021.04.0\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : 1.0.1\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : None\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : 0.53.1\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-3573", "file_changes": [{"file": "RELEASE.rst", "changes": {}}, {"file": "doc/source/faq.rst", "changes": {}}, {"file": "pandas/core/common.py", "changes": {"edited_modules": ["pandas/core/common.py:in_qtconsole", "pandas/core/common.py:in_ipnb_frontend"], "edited_entities": ["pandas/core/common.py:in_qtconsole", "pandas/core/common.py:in_ipnb_frontend"]}}, {"file": "pandas/core/config_init.py", "changes": {}}, {"file": "pandas/core/format.py", "changes": {"edited_modules": ["pandas/core/format.py:get_console_size"], "edited_entities": ["pandas/core/format.py:get_console_size"]}}, {"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame._repr_fits_vertical_", "pandas/core/frame.py:DataFrame._repr_fits_horizontal_", "pandas/core/frame.py:DataFrame._repr_html_", "pandas/core/frame.py:DataFrame.__unicode__"]}}, {"file": "pandas/tests/test_format.py", "changes": {"edited_modules": ["pandas/tests/test_format.py:TestDataFrameFormatting"], "edited_entities": ["pandas/tests/test_format.py:TestDataFrameFormatting.test_repr_max_columns_max_rows", "pandas/tests/test_format.py:TestDataFrameFormatting.test_wide_repr_multiindex_cols", "pandas/tests/test_format.py:TestDataFrameFormatting.test_expand_frame_repr", "pandas/tests/test_format.py:TestDataFrameFormatting.test_wide_repr", "pandas/tests/test_format.py:TestDataFrameFormatting.test_wide_repr_named", "pandas/tests/test_format.py:TestDataFrameFormatting.test_wide_repr_multiindex", "pandas/tests/test_format.py:TestDataFrameFormatting.test_wide_repr_unicode"]}}], "repo": "pandas-dev/pandas", "base_commit": "92093457ca13ba037257d0b8d41735268535c84f", "problem_statement": "Unintuitive default behavior with wide DataFrames in the IPython notebook\n\nIn the IPython notebook, HTML output it the default and whether summary view is displayed should not be governed by hypothetical line width. I ran into this problem in a demo recently and it took me a minute to figure out what was wrong, definitely a bad change in 0.11.", "patch": ""}
{"instance_id": "pandas-dev__pandas-19482", "file_changes": [{"file": "doc/source/whatsnew/v0.23.0.txt", "changes": {}}, {"file": "pandas/_libs/algos.pxd", "changes": {}}, {"file": "pandas/_libs/algos.pyx", "changes": {}}, {"file": "pandas/_libs/groupby.pyx", "changes": {}}, {"file": "pandas/_libs/groupby_helper.pxi.in", "changes": {}}, {"file": "pandas/core/groupby.py", "changes": {"edited_modules": ["pandas/core/groupby.py:GroupBy", "pandas/core/groupby.py:BaseGrouper", "pandas/core/groupby.py:_GroupBy"], "edited_entities": ["pandas/core/groupby.py:GroupBy", "pandas/core/groupby.py:BaseGrouper", "pandas/core/groupby.py:_GroupBy", "pandas/core/groupby.py:_GroupBy._cython_transform", "pandas/core/groupby.py:BaseGrouper._cython_operation", "pandas/core/groupby.py:BaseGrouper._transform"]}}, {"file": "pandas/tests/groupby/test_groupby.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_groupby.py:TestGroupBy"], "edited_entities": ["pandas/tests/groupby/test_groupby.py:TestGroupBy"]}}], "repo": "pandas-dev/pandas", "base_commit": "a214915e241ea15f3d072d54930d0e0c8f42ee10", "problem_statement": "Rank With 'method=first' Broken for Objects\n\nCame across this working on #15779\r\n\r\n\r\n```python\r\nIn []: df = pd.DataFrame({'key': ['a'] * 5, 'val': ['bar', 'bar', 'foo', 'bar', 'baz']})\r\nIn []: df.groupby('key').rank(method='first')\r\n\r\nOut []: \r\nEmpty DataFrame\r\nColumns: []\r\nIndex: []\r\n\r\n```\r\n\r\n#### Expected Output\r\n\r\n```python\r\n\r\nOut[]: \r\n   val\r\n0  1.0\r\n1  2.0\r\n2  5.0\r\n3  3.0\r\n4  4.0\r\n\r\n```\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: d3f7d2a666aa824e2df98083aa5c1fd9bb63252e\r\npython: 3.6.3.final.0\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 17.4.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.23.0.dev0+169.gd3f7d2a66.dirty\r\npytest: 3.2.1\r\npip: 9.0.1\r\nsetuptools: 36.5.0.post20170921\r\nCython: 0.26.1\r\nnumpy: 1.13.3\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: 0.10.0\r\nIPython: 6.2.1\r\nsphinx: 1.6.3\r\npatsy: 0.4.1\r\ndateutil: 2.6.1\r\npytz: 2017.2\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: 0.4.0\r\nmatplotlib: 2.1.1\r\nopenpyxl: 2.5.0b1\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.1.13\r\npymysql: 0.7.11.None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: 0.1.2\r\nfastparquet: 0.1.3\r\npandas_gbq: None\r\npandas_datareader: None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-21687", "file_changes": [{"file": "pandas/core/window.py", "changes": {"edited_modules": ["pandas/core/window.py:Window"], "edited_entities": ["pandas/core/window.py:Window"]}}], "repo": "pandas-dev/pandas", "base_commit": "679dbd021eccc238e422057009365e2ee1c04b25", "problem_statement": "\"on\" argument of DataFrame.rolling only works for datetime columns\n\nthe `on=` argument of `DataFrame.rolling` only works for datetime columns.\r\n\r\n```\r\ndf = pd.DataFrame([\r\n    [18, 0],\r\n    [2, 0],\r\n    [1, 0],\r\n    [9, 1],\r\n    [8, 1],\r\n], columns=['value', 'roll'])\r\n```\r\n\r\n```\r\ndf.roll = pd.to_datetime(df.roll, unit='s')\r\ndf.rolling('1s', on='roll').value.max()\r\n```\r\n\r\nreturns:\r\n\r\n```\r\n0    18.0\r\n1    18.0\r\n2    18.0\r\n3     9.0\r\n4     9.0\r\nName: value, dtype: float64\r\n```\r\nas expected.\r\n\r\nBut \r\n\r\n```df.rolling(1, on='roll').value.max()```\r\n\r\nreturns:\r\n\r\n```\r\n0    18.0\r\n1     2.0\r\n2     1.0\r\n3     9.0\r\n4     8.0\r\nName: value, dtype: float64\r\n```\r\n\r\nIf this is intentional behavior, I'd be happy to change the docs to note this (the docs currently imply that `on=` can be used for any column).", "patch": ""}
{"instance_id": "pandas-dev__pandas-20452", "file_changes": [{"file": "doc/source/merging.rst", "changes": {}}, {"file": "doc/source/whatsnew/v0.24.0.rst", "changes": {}}, {"file": "pandas/core/reshape/merge.py", "changes": {"edited_modules": ["pandas/core/reshape/merge.py:_MergeOperation"], "edited_entities": ["pandas/core/reshape/merge.py:_MergeOperation._maybe_add_join_keys"]}}, {"file": "pandas/tests/reshape/merge/test_join.py", "changes": {}}, {"file": "pandas/tests/reshape/merge/test_merge.py", "changes": {"edited_modules": ["pandas/tests/reshape/merge/test_merge.py:test_merge_series"], "edited_entities": ["pandas/tests/reshape/merge/test_merge.py:test_merge_series"]}}], "repo": "pandas-dev/pandas", "base_commit": "940104efc9e708bc93744dfaa36c9492b03b1ca4", "problem_statement": "BUG: New feature allowing merging on combination of columns and index levels drops levels of index\n\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [1]: import pandas as pd\r\n\r\nIn [2]: pd.__version__\r\nOut[2]: '0.23.0.dev0+657.g01882ba5b'\r\n\r\nIn [3]: df1 =  pd.DataFrame({'v1' : range(12)}, index=pd.MultiIndex.from_product([list('abc'),list('xy'),[1,2]], names=['abc','xy','num']))\r\n   ...: df1\r\n   ...:\r\nOut[3]:\r\n            v1\r\nabc xy num\r\na   x  1     0\r\n       2     1\r\n    y  1     2\r\n       2     3\r\nb   x  1     4\r\n       2     5\r\n    y  1     6\r\n       2     7\r\nc   x  1     8\r\n       2     9\r\n    y  1    10\r\n       2    11\r\n\r\nIn [4]: df2 = pd.DataFrame({'v2': [100*i for i in range(1,7)]}, index=pd.MultiIndex.from_product([list('abc'), list('xy')],names=['abc','xy']))\r\n\r\nIn [5]: df2\r\nOut[5]:\r\n         v2\r\nabc xy\r\na   x   100\r\n    y   200\r\nb   x   300\r\n    y   400\r\nc   x   500\r\n    y   600\r\n\r\nIn [6]: df1.merge(df2, on=['abc','xy'])  # 'num' disappears\r\nOut[6]:\r\n        v1   v2\r\nabc xy\r\na   x    0  100\r\n    x    1  100\r\n    y    2  200\r\n    y    3  200\r\nb   x    4  300\r\n    x    5  300\r\n    y    6  400\r\n    y    7  400\r\nc   x    8  500\r\n    x    9  500\r\n    y   10  600\r\n    y   11  600\r\n\r\nIn [7]: df1.reset_index().merge(df2, on=['abc','xy']) # This preserves 'num'\r\nOut[7]:\r\n   abc xy  num  v1   v2\r\n0    a  x    1   0  100\r\n1    a  x    2   1  100\r\n2    a  y    1   2  200\r\n3    a  y    2   3  200\r\n4    b  x    1   4  300\r\n5    b  x    2   5  300\r\n6    b  y    1   6  400\r\n7    b  y    2   7  400\r\n8    c  x    1   8  500\r\n9    c  x    2   9  500\r\n10   c  y    1  10  600\r\n11   c  y    2  11  600\r\n\r\nIn [8]: df1.merge(df2, on='xy')  # 'abc' and 'num' disappear\r\nOut[8]:\r\n    v1   v2\r\nxy\r\nx    0  100\r\nx    0  300\r\nx    0  500\r\nx    1  100\r\nx    1  300\r\nx    1  500\r\nx    4  100\r\nx    4  300\r\nx    4  500\r\nx    5  100\r\nx    5  300\r\nx    5  500\r\nx    8  100\r\nx    8  300\r\nx    8  500\r\nx    9  100\r\nx    9  300\r\nx    9  500\r\ny    2  200\r\ny    2  400\r\ny    2  600\r\ny    3  200\r\ny    3  400\r\ny    3  600\r\ny    6  200\r\ny    6  400\r\ny    6  600\r\ny    7  200\r\ny    7  400\r\ny    7  600\r\ny   10  200\r\ny   10  400\r\ny   10  600\r\ny   11  200\r\ny   11  400\r\ny   11  600\r\n\r\n```\r\n#### Problem description\r\n\r\nIt seems that the new feature implemented in #17484 that allows merging on a combination of columns and index levels can drop index levels, which is really non-intuitive.  In the first example, the index level named \"num\" gets dropped, while in the last example, both \"abc\" and \"xy\" are dropped.\r\n\r\nIf this is the desired behavior, then it needs to be carefully documented.\r\n\r\nN.B. There is also an error in the docs of merging.rst that says this feature was introduced in v.0.22, but it will be introduced in v0.23\r\n\r\nI'm guessing @jmmease will need to look at this.\r\n\r\n#### Expected Output\r\n\r\n```python\r\nIn [6]: df1.merge(df2, on=['abc','xy'])\r\nOut[6]:\r\n            v1   v2\r\nabc xy num\r\na   x  1     0  100\r\n       2     1  100\r\n    y  1     2  200\r\n       2     3  200\r\nb   x  1     4  300\r\n       2     5  300\r\n    y  1     6  400\r\n       2     7  400\r\nc   x  1     8  500\r\n       2     9  500\r\n    y  1    10  600\r\n       2    11  600\r\n\r\nIn [8]: df1.merge(df2, on='xy')\r\nOut[8]:\r\n   abc_x  num  v1 abc_y   v2\r\nxy\r\nx      a    1   0     a  100\r\nx      a    1   0     b  300\r\nx      a    1   0     c  500\r\nx      a    2   1     a  100\r\nx      a    2   1     b  300\r\nx      a    2   1     c  500\r\nx      b    1   4     a  100\r\nx      b    1   4     b  300\r\nx      b    1   4     c  500\r\nx      b    2   5     a  100\r\nx      b    2   5     b  300\r\nx      b    2   5     c  500\r\nx      c    1   8     a  100\r\nx      c    1   8     b  300\r\nx      c    1   8     c  500\r\nx      c    2   9     a  100\r\nx      c    2   9     b  300\r\nx      c    2   9     c  500\r\ny      a    1   2     a  200\r\ny      a    1   2     b  400\r\ny      a    1   2     c  600\r\ny      a    2   3     a  200\r\ny      a    2   3     b  400\r\ny      a    2   3     c  600\r\ny      b    1   6     a  200\r\ny      b    1   6     b  400\r\ny      b    1   6     c  600\r\ny      b    2   7     a  200\r\ny      b    2   7     b  400\r\ny      b    2   7     c  600\r\ny      c    1  10     a  200\r\ny      c    1  10     b  400\r\ny      c    1  10     c  600\r\ny      c    2  11     a  200\r\ny      c    2  11     b  400\r\ny      c    2  11     c  600\r\n```\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.4.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: None\r\nLOCALE: None.None\r\n\r\npandas: 0.23.0.dev0+657.g01882ba5b\r\npytest: 3.4.0\r\npip: 9.0.1\r\nsetuptools: 38.5.1\r\nCython: 0.25.1\r\nnumpy: 1.14.1\r\nscipy: 1.0.0\r\npyarrow: 0.8.0\r\nxarray: None\r\nIPython: 6.2.1\r\nsphinx: 1.7.1\r\npatsy: 0.5.0\r\ndateutil: 2.6.1\r\npytz: 2018.3\r\nblosc: 1.5.1\r\nbottleneck: 1.2.1\r\ntables: 3.4.2\r\nnumexpr: 2.6.4\r\nfeather: None\r\nmatplotlib: 2.2.0\r\nopenpyxl: 2.5.0\r\nxlrd: 1.1.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.0.2\r\nlxml: 4.1.1\r\nbs4: 4.6.0\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.5\r\npymysql: 0.8.0\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: 0.1.3\r\nfastparquet: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-35650", "file_changes": [{"file": "pandas/tests/test_algos.py", "changes": {"edited_modules": ["pandas/tests/test_algos.py:TestFactorize"], "edited_entities": ["pandas/tests/test_algos.py:TestFactorize.test_object_factorize"]}}], "repo": "pandas-dev/pandas", "base_commit": "13940c7f3c0371d6799bbd88b9c6546392b418a1", "problem_statement": "BUG: pd.factorize with read-only datetime64 numpy array raises ValueError\n\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\n\r\nIn [1]: pandas.__version__\r\n[PYFLYBY] import pandas\r\nOut[1]: u'0.24.2'\r\n\r\nIn [2]: arr = numpy.array([numpy.datetime64('2015-11-20T15:06:58.000')])\r\n\r\nIn [3]: arr.dtype\r\nOut[3]: dtype('<M8[ms]')\r\n\r\nIn [4]: arr.flags.writeable = False\r\n\r\n[PYFLYBY] import pandas as pd\r\nIn [5]: pd.factorize(arr)\r\n```\r\n\r\n#### Problem description\r\n\r\n[Construction with non-mutable datetime64 strings]\r\n\r\n#### Expected Output\r\n(array([0]), array(['2015-11-20T15:06:58.000000000'], dtype='datetime64[ns]'))\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\npandas/_libs/tslibs/conversion.pyx in pandas._libs.tslibs.conversion.ensure_datetime64ns()\r\n\r\n/usr/local/python/python-2.7/std/lib/python2.7/site-packages/pandas/_libs/tslibs/conversion.so in View.MemoryView.memoryview_cwrapper()\r\n\r\n/usr/local/python/python-2.7/std/lib/python2.7/site-packages/pandas/_libs/tslibs/conversion.so in View.MemoryView.memoryview.__cinit__()\r\n\r\nValueError: buffer source array is read-only\r\n</details>", "patch": ""}
{"instance_id": "pandas-dev__pandas-16033", "file_changes": [{"file": "pandas/tests/io/formats/test_css.py", "changes": {"edited_modules": ["pandas/tests/io/formats/test_css.py:test_css_parse_strings", "pandas/tests/io/formats/test_css.py:test_css_parse_invalid", "pandas/tests/io/formats/test_css.py:test_css_side_shorthands"], "edited_entities": ["pandas/tests/io/formats/test_css.py:test_css_parse_strings", "pandas/tests/io/formats/test_css.py:test_css_parse_invalid", "pandas/tests/io/formats/test_css.py:test_css_side_shorthands"]}}], "repo": "pandas-dev/pandas", "base_commit": "816f94575c9ec1af2169a28536217c4d16dd6b4b", "problem_statement": "DOC: styler warnings in doc-build\n\nhttps://travis-ci.org/pandas-dev/pandas/jobs/222779268\r\n\r\n```\r\n/tmp/doc/source/generated/pandas.io.formats.style.Styler.rst:74: WARNING: failed to import template:\r\n/tmp/doc/source/generated/pandas.io.formats.style.Styler.rst:74: WARNING: toctree references unknown document 'generated/template:'\r\n```\r\n\r\ncc @TomAugspurger @jorisvandenbossche \r\n\r\nI just pushed a change to fix the path of the imports (after ``pandas.formats`` change), but I think it still needs something.", "patch": ""}
{"instance_id": "pandas-dev__pandas-35811", "file_changes": [{"file": "doc/source/whatsnew/v1.2.0.rst", "changes": {}}, {"file": "pandas/core/aggregation.py", "changes": {"edited_modules": ["pandas/core/aggregation.py:validate_func_kwargs"], "edited_entities": ["pandas/core/aggregation.py:validate_func_kwargs"]}}, {"file": "pandas/core/base.py", "changes": {"edited_modules": ["pandas/core/base.py:SelectionMixin"], "edited_entities": ["pandas/core/base.py:SelectionMixin"]}}, {"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame"]}}, {"file": "pandas/core/generic.py", "changes": {"edited_modules": ["pandas/core/generic.py:NDFrame"], "edited_entities": ["pandas/core/generic.py:NDFrame"]}}, {"file": "pandas/core/series.py", "changes": {"edited_modules": ["pandas/core/series.py:Series"], "edited_entities": ["pandas/core/series.py:Series"]}}, {"file": "pandas/core/shared_docs.py", "changes": {}}, {"file": "pandas/tests/frame/apply/test_frame_transform.py", "changes": {"edited_modules": ["pandas/tests/frame/apply/test_frame_transform.py:test_agg_transform", "pandas/tests/frame/apply/test_frame_transform.py:test_transform_method_name", "pandas/tests/frame/apply/test_frame_transform.py:test_transform_and_agg_err"], "edited_entities": ["pandas/tests/frame/apply/test_frame_transform.py:test_agg_transform", "pandas/tests/frame/apply/test_frame_transform.py:test_transform_method_name", "pandas/tests/frame/apply/test_frame_transform.py:test_transform_and_agg_err"]}}, {"file": "pandas/tests/series/apply/test_series_apply.py", "changes": {"edited_modules": ["pandas/tests/series/apply/test_series_apply.py:TestSeriesAggregate"], "edited_entities": ["pandas/tests/series/apply/test_series_apply.py:TestSeriesAggregate.test_transform"]}}, {"file": "pandas/tests/series/apply/test_series_transform.py", "changes": {"edited_modules": ["pandas/tests/series/apply/test_series_transform.py:test_transform_none_to_type", "pandas/tests/series/apply/test_series_transform.py:test_transform", "pandas/tests/series/apply/test_series_transform.py:test_transform_and_agg_error"], "edited_entities": ["pandas/tests/series/apply/test_series_transform.py:test_transform_none_to_type", "pandas/tests/series/apply/test_series_transform.py:test_transform", "pandas/tests/series/apply/test_series_transform.py:test_transform_and_agg_error"]}}], "repo": "pandas-dev/pandas", "base_commit": "2067d7e306ae720d455f356e4da21f282a8a762e", "problem_statement": "BUG/QST: Series.transform with a dictionary\n\nWhat is the expected output of passing a dictionary to `Series.transform`? For example:\r\n\r\n    s = pd.Series([1, 2, 3])\r\n    result1 = s.transform({'a': lambda x: x + 1})\r\n    result2 = s.transform({'a': lambda x: x + 1, 'b': lambda x: x + 2})\r\n\r\nThe docs say that `dict of axis labels -> functions` is acceptable, but I can't find any example in the docs where the output is described/shown. Under the hood, `Series.transform` is just calling `Series.aggregate` which produces the following outputs for `result1` and `result2`.\r\n\r\n````\r\n# result1\r\na  0    2\r\n   1    3\r\n   2    4\r\ndtype: int64\r\n\r\n# result2\r\na  0    2\r\n   1    3\r\n   2    4\r\nb  0    3\r\n   1    4\r\n   2    5\r\ndtype: int64\r\n````\r\n\r\n`result1` is deemed acceptable (the length of the result equals the length of the input) and is returned, but `result2` raises; it is not a transformation.\r\n\r\nI am wondering if a better return would be a DataFrame where the keys are the column names ('a' and 'b' in this example).", "patch": ""}
{"instance_id": "pandas-dev__pandas-33810", "file_changes": [{"file": "doc/source/conf.py", "changes": {}}, {"file": "doc/source/user_guide/io.rst", "changes": {}}, {"file": "doc/source/whatsnew/v1.1.0.rst", "changes": {}}, {"file": "pandas/core/frame.py", "changes": {"edited_modules": ["pandas/core/frame.py:DataFrame"], "edited_entities": ["pandas/core/frame.py:DataFrame.to_feather", "pandas/core/frame.py:DataFrame"]}}, {"file": "pandas/io/feather_format.py", "changes": {"edited_modules": ["pandas/io/feather_format.py:to_feather"], "edited_entities": ["pandas/io/feather_format.py:to_feather"]}}, {"file": "pandas/tests/io/test_feather.py", "changes": {"edited_modules": ["pandas/tests/io/test_feather.py:TestFeather"], "edited_entities": ["pandas/tests/io/test_feather.py:TestFeather.test_basic", "pandas/tests/io/test_feather.py:TestFeather.test_path_localpath", "pandas/tests/io/test_feather.py:TestFeather", "pandas/tests/io/test_feather.py:TestFeather.check_round_trip", "pandas/tests/io/test_feather.py:TestFeather.test_unsupported_other"]}}], "repo": "pandas-dev/pandas", "base_commit": "889c2ff67af14213e8ed065df2957b07e34ac95b", "problem_statement": "TST: add Feather V2 round-trip test\n\nno that pyarrow 0.17 has landed, we should have a round-trip Feather V2 test to ensure we have dtype preservation (we can likely re-use some of our test frames from the parquet tests).", "patch": ""}
{"instance_id": "pandas-dev__pandas-15630", "file_changes": [{"file": "doc/source/whatsnew/v0.23.0.txt", "changes": {}}, {"file": "pandas/_libs/algos_rank_helper.pxi.in", "changes": {}}, {"file": "pandas/tests/frame/test_rank.py", "changes": {"edited_modules": ["pandas/tests/frame/test_rank.py:TestRank"], "edited_entities": ["pandas/tests/frame/test_rank.py:TestRank.test_rank_2d_tie_methods"]}}, {"file": "pandas/tests/series/test_rank.py", "changes": {"edited_modules": ["pandas/tests/series/test_rank.py:TestSeriesRank"], "edited_entities": ["pandas/tests/series/test_rank.py:TestSeriesRank.test_rank_modify_inplace"]}}], "repo": "pandas-dev/pandas", "base_commit": "b6691127523f965003dbf877a358c81af5012989", "problem_statement": "Pandas (0.18) Rank: unexpected behavior for method = 'dense' and pct = True\n\nI find the behavior of rank function with method = 'dense' and pct = True unexpected as it looks like, in order to calculate percentile ranks, the function is using the total number of observations instead of the number of _distinct_ observations.\r\n\r\n#### Code Sample, a copy-pastable example if possible\r\n\r\n```\r\nimport pandas as pd\r\nn_rep = 2\r\nts = pd.Series([1,2,3,4] * n_rep )\r\noutput = ts.rank(method = 'dense', pct = True)\r\n```\r\n\r\n#### Problem description\r\n\r\n```\r\nts.rank(method = 'dense', pct = True)\r\nOut[116]: \r\n0    0.125\r\n1    0.250\r\n2    0.375\r\n3    0.500\r\n4    0.125\r\n5    0.250\r\n6    0.375\r\n7    0.500\r\n```\r\n\r\n#### Expected Output\r\nSomething similar to:\r\n\r\n```\r\npd.Series([1,2,3,4] * 2).rank(method = 'dense', pct = True) * n_rep \r\nOut[118]: \r\n0    0.25\r\n1    0.50\r\n2    0.75\r\n3    1.00\r\n4    0.25\r\n5    0.50\r\n6    0.75\r\n7    1.00\r\n```\r\n\r\nAlso, I would expected the result above to be invariant to n_rep.\r\ni.e. I would expect a \"mapping\" {value -> pct_rank} that would not depend on how many times the value is repeated, while it is not the case here.", "patch": ""}
{"instance_id": "pandas-dev__pandas-13420", "file_changes": [{"file": "pandas/tests/groupby/test_categorical.py", "changes": {"edited_modules": ["pandas/tests/groupby/test_categorical.py:test_seriesgroupby_observed_apply_dict"], "edited_entities": ["pandas/tests/groupby/test_categorical.py:test_seriesgroupby_observed_apply_dict"]}}], "repo": "pandas-dev/pandas", "base_commit": "95be01dbc060f405b7928cc6e4ba4d6d6181c22a", "problem_statement": "DataFrame.groupby(grp, axis=1) with categorical grp breaks\n\nWhile attempting to use `pd.qcut` (which returned a Categorical) to bin some data in groups for plotting, I encountered the following error. The idea is to group a DataFrame by columns (`axis=1`) using a Categorical.\n#### Minimal breaking example\n\n```\n>>> import pandas\n>>> df = pandas.DataFrame({'a':[1,2,3,4], 'b':[-1,-2,-3,-4], 'c':[5,6,7,8]})\n>>> df\n   a  b  c\n0  1 -1  5\n1  2 -2  6\n2  3 -3  7\n3  4 -4  8\n>>> grp = pandas.Categorical([1,0,1])\n>>> df.groupby(grp, axis=1).mean()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/ntawolf/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\", line 3778, in groupby\n    **kwargs)\n  File \"/home/ntawolf/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 1427, in groupby\n    return klass(obj, by, **kwds)\n  File \"/home/ntawolf/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 354, in __init__\n    mutated=self.mutated)\n  File \"/home/ntawolf/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 2390, in _get_grouper\n    raise ValueError(\"Categorical dtype grouper must \"\nValueError: Categorical dtype grouper must have len(grouper) == len(data)\n```\n#### Expected behaviour\n\nSame as\n\n```\n>>> df.T.groupby(grp, axis=0).mean().T\n   0  1\n0 -1  3\n1 -2  4\n2 -3  5\n3 -4  6\n```\n\nSo, it works as expected when doubly transposed. This makes it appear as a bug to me.\n#### Proposed solution\n\nIn [`if is_categorical_dtype(gpr) and len(gpr) != len(obj):`](https://github.com/pydata/pandas/blob/master/pandas/core/groupby.py#L2406), change `len(obj)` to `obj.shape[axis]`. This assumes that `len(obj) == obj.shape[0]` for all `obj`.\n\nSo, supposing you agree that this is a bug, should a test be put in [`test_groupby_categorical`](https://github.com/pydata/pandas/blob/master/pandas/tests/test_groupby.py#L3968)?\n#### output of `pd.show_versions()`\n\n```\nINSTALLED VERSIONS\n------------------\ncommit: None\npython: 3.5.1.final.0\npython-bits: 64\nOS: Linux\nOS-release: 3.19.0-59-generic\nmachine: x86_64\nprocessor: x86_64\nbyteorder: little\nLC_ALL: None\nLANG: en_US.UTF-8\n\npandas: 0.18.1\nnose: 1.3.7\npip: 8.1.2\nsetuptools: 22.0.5\nCython: 0.24\nnumpy: 1.10.4\nscipy: 0.17.1\nstatsmodels: 0.6.1\nxarray: None\nIPython: 4.2.0\nsphinx: 1.4.1\npatsy: 0.4.1\ndateutil: 2.5.3\npytz: 2016.4\nblosc: None\nbottleneck: 1.0.0\ntables: 3.2.2\nnumexpr: 2.5.2\nmatplotlib: 1.5.1\nopenpyxl: 2.3.2\nxlrd: 1.0.0\nxlwt: 1.1.1\nxlsxwriter: 0.8.9\nlxml: 3.6.0\nbs4: 4.4.1\nhtml5lib: None\nhttplib2: None\napiclient: None\nsqlalchemy: 1.0.13\npymysql: None\npsycopg2: None\njinja2: 2.8\nboto: 2.40.0\npandas_datareader: None\n```", "patch": ""}
{"instance_id": "pandas-dev__pandas-13565", "file_changes": [{"file": "doc/source/whatsnew/v0.19.0.txt", "changes": {}}, {"file": "pandas/core/base.py", "changes": {"edited_modules": ["pandas/core/base.py:IndexOpsMixin"], "edited_entities": ["pandas/core/base.py:IndexOpsMixin", "pandas/core/base.py:IndexOpsMixin.unique"]}}, {"file": "pandas/core/series.py", "changes": {"edited_modules": ["pandas/core/series.py:Series"], "edited_entities": ["pandas/core/series.py:Series"]}}, {"file": "pandas/indexes/base.py", "changes": {"edited_modules": ["pandas/indexes/base.py:Index"], "edited_entities": ["pandas/indexes/base.py:Index"]}}, {"file": "pandas/indexes/category.py", "changes": {"edited_modules": ["pandas/indexes/category.py:CategoricalIndex"], "edited_entities": ["pandas/indexes/category.py:CategoricalIndex"]}}, {"file": "pandas/tests/indexes/test_category.py", "changes": {"edited_modules": ["pandas/tests/indexes/test_category.py:TestCategoricalIndex"], "edited_entities": ["pandas/tests/indexes/test_category.py:TestCategoricalIndex.test_duplicates"]}}, {"file": "pandas/tests/indexes/test_multi.py", "changes": {"edited_modules": ["pandas/tests/indexes/test_multi.py:TestMultiIndex"], "edited_entities": ["pandas/tests/indexes/test_multi.py:TestMultiIndex"]}}, {"file": "pandas/tests/test_base.py", "changes": {"edited_modules": ["pandas/tests/test_base.py:TestIndexOps"], "edited_entities": ["pandas/tests/test_base.py:TestIndexOps.test_value_counts_unique_nunique", "pandas/tests/test_base.py:TestIndexOps.test_value_counts_inferred", "pandas/tests/test_base.py:TestIndexOps.test_value_counts_bins", "pandas/tests/test_base.py:TestIndexOps.test_value_counts_datetime64"]}}, {"file": "pandas/tests/test_categorical.py", "changes": {"edited_modules": ["pandas/tests/test_categorical.py:TestCategorical"], "edited_entities": ["pandas/tests/test_categorical.py:TestCategorical"]}}, {"file": "pandas/tseries/base.py", "changes": {"edited_modules": ["pandas/tseries/base.py:DatetimeIndexOpsMixin"], "edited_entities": ["pandas/tseries/base.py:DatetimeIndexOpsMixin"]}}, {"file": "pandas/util/testing.py", "changes": {"edited_modules": ["pandas/util/testing.py:makeUnicodeIndex"], "edited_entities": ["pandas/util/testing.py:makeUnicodeIndex"]}}], "repo": "pandas-dev/pandas", "base_commit": "be61825986ba565bc038beb2f5df2750fc1aca30", "problem_statement": "Call unique() on a timezone aware datetime series returns non timezone aware result\n\nCall unique() on a timezone aware datetime series returns non timezone aware result. \n#### Code Sample\n\nimport pandas as pd\nimport pytz\nimport datetime\n\nIn [242]: ts = pd.Series([datetime.datetime(2011,2,11,20,0,0,0,pytz.utc), datetime.datetime(2011,2,11,20,0,0,0,pytz.utc), datetime.datetime(2011,2,11,21,0,0,0,pytz.utc)])\n\nIn [243]: ts\nOut[243]: \n0   2011-02-11 20:00:00+00:00\n1   2011-02-11 20:00:00+00:00\n2   2011-02-11 21:00:00+00:00\ndtype: datetime64[ns, UTC]\n\nIn [244]: ts.unique()\nOut[244]: array(['2011-02-11T20:00:00.000000000', '2011-02-11T21:00:00.000000000'], dtype='datetime64[ns]')\n#### output of `pd.show_versions()`\n## INSTALLED VERSIONS\n\ncommit: None\npython: 2.7.9.final.0\npython-bits: 64\nOS: Linux\nOS-release: 3.16.0-4-amd64\nmachine: x86_64\nprocessor: \nbyteorder: little\nLC_ALL: None\nLANG: de_AT.UTF-8\n\npandas: 0.18.1\nnose: 1.3.4\npip: 8.1.2\nsetuptools: 22.0.5\nCython: 0.21.1\nnumpy: 1.11.0\nscipy: 0.14.0\nstatsmodels: None\nxarray: None\nIPython: 4.2.0\nsphinx: 1.2.3\npatsy: None\ndateutil: 2.5.3\npytz: 2016.4\nblosc: None\nbottleneck: None\ntables: 3.1.1\nnumexpr: 2.4\nmatplotlib: 1.4.2\nopenpyxl: 2.3.5\nxlrd: 0.9.2\nxlwt: 0.7.4\nxlsxwriter: None\nlxml: 3.6.0\nbs4: None\nhtml5lib: 1.0b3\nhttplib2: 0.9\napiclient: None\nsqlalchemy: 0.9.8\npymysql: None\npsycopg2: None\njinja2: 2.7.3\nboto: None\npandas_datareader: None", "patch": ""}
{"instance_id": "pandas-dev__pandas-9400", "file_changes": [{"file": "pandas/tools/plotting.py", "changes": {"edited_modules": ["pandas/tools/plotting.py:_plot"], "edited_entities": ["pandas/tools/plotting.py:_plot"]}}], "repo": "pandas-dev/pandas", "base_commit": "c4a996adfc91f023b46ce3cb67e33fc8b2ca3627", "problem_statement": "Improve error message in plotting.py's _plot\n\nThis a minor enhancement proposal. At the moment I cannot submit a pull request. I will probably have time to create one during the next week. \n\nThis is a snippet from `tools/plotting.py`: https://github.com/pydata/pandas/blob/master/pandas/tools/plotting.py#L2269-2283\n\n``` python\ndef _plot(data, x=None, y=None, subplots=False,\n          ax=None, kind='line', **kwds):\n    kind = _get_standard_kind(kind.lower().strip())\n    if kind in _all_kinds:\n        klass = _plot_klass[kind]\n    else:\n        raise ValueError('Invalid chart type given %s' % kind)\n\n    from pandas import DataFrame\n    if kind in _dataframe_kinds:\n        if isinstance(data, DataFrame):\n            plot_obj = klass(data, x=x, y=y, subplots=subplots, ax=ax,\n                             kind=kind, **kwds)\n        else:\n            raise ValueError('Invalid chart type given %s' % kind)\n```\n\nWhich results in following error message:\n\n```\nC:\\Anaconda3\\lib\\site-packages\\pandas\\tools\\plotting.py in plot_series(series, label, kind, use_index, rot, xticks, yticks, xlim, ylim, ax, style, grid, legend, logx, logy, secondary_y, **kwds)\n   2231         klass = _plot_klass[kind]\n   2232     else:\n-> 2233         raise ValueError('Invalid chart type given %s' % kind)\n   2234 \n   2235     \"\"\"\n\nValueError: Invalid chart type given hist\n```\n\nI would suggest using the format string `\"Invalid chart type given: '%s'\"` instead.", "patch": ""}
{"instance_id": "pandas-dev__pandas-54889", "file_changes": [{"file": "pandas/_libs/meson.build", "changes": {}}], "repo": "pandas-dev/pandas", "base_commit": "53243e8ec73ecf5035a63f426a9c703d6835e9a7", "problem_statement": "BUILD: Race condition between .pxi.in and .pyx compiles in parallel build of 2.1.0\n\n### Installation check\n\n- [X] I have read the [installation guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-pandas).\n\n\n### Platform\n\nLinux-6.4.7-gentoo-dist-x86_64-AMD_Ryzen_5_3600_6-Core_Processor-with-glibc2.38\n\n### Installation Method\n\nBuilt from source\n\n### pandas Version\n\n2.1.0\n\n### Python Version\n\n3.11.5\n\n### Installation Logs\n\n<details>\r\n<summary>Build log excerpt</summary>\r\n\r\n```\r\ngpep517 build-wheel --backend mesonpy --output-fd 3 --wheel-dir /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/wheel --config-json {\"builddir\": \"/tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10\", \"setup-args\": [], \"compile-args\": [\"-v\", \"-j12\", \"-l0\"]}\r\n2023-08-31 07:02:26,275 gpep517 INFO Building wheel via backend mesonpy\r\n+ meson setup /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0 /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=/tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/meson-python-native-file.ini\r\nThe Meson build system\r\nVersion: 1.2.1\r\nSource dir: /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0\r\nBuild dir: /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10\r\nBuild type: native build\r\nProject name: pandas\r\nProject version: 2.1.0\r\nC compiler for the host machine: x86_64-pc-linux-gnu-gcc (gcc 13.2.1 \"x86_64-pc-linux-gnu-gcc (Gentoo 13.2.1_p20230826 p7) 13.2.1 20230826\")\r\nC linker for the host machine: x86_64-pc-linux-gnu-gcc ld.bfd 2.41\r\nC++ compiler for the host machine: x86_64-pc-linux-gnu-g++ (gcc 13.2.1 \"x86_64-pc-linux-gnu-g++ (Gentoo 13.2.1_p20230826 p7) 13.2.1 20230826\")\r\nC++ linker for the host machine: x86_64-pc-linux-gnu-g++ ld.bfd 2.41\r\nCython compiler for the host machine: cython (cython 0.29.36)\r\nHost machine cpu family: x86_64\r\nHost machine cpu: x86_64\r\nProgram python found: YES (/usr/bin/python3.10)\r\nFound pkg-config: /usr/bin/pkg-config (1.8.1)\r\nRun-time dependency python found: YES 3.10\r\nBuild targets in project: 53\r\n\r\npandas 2.1.0\r\n\r\n  User defined options\r\n    Native files: /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/meson-python-native-file.ini\r\n    buildtype   : release\r\n    vsenv       : True\r\n    b_ndebug    : if-release\r\n    b_vscrt     : md\r\n\r\nFound samurai-1.9 at /usr/bin/samu\r\n\r\nVisual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:\r\n/usr/lib/python-exec/python3.10/meson compile -C .\r\n\r\nGenerating targets:   0%|          | 0/53 eta ?\r\nGenerating targets:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 52/53 eta 00:00\r\n                                                    \r\n\r\nWriting build.ninja:   0%|          | 0/225 eta ?\r\n                                                 \r\n+ /usr/bin/samu -v -j12 -l0\r\n[\u2026]\r\nsamu: job failed: cython -M --fast-fail -3 --include-dir /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/pandas/_libs '-X always_allow_keywords=true' /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0/pandas/_libs/interval.pyx -o pandas/_libs/interval.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/interval.pyx.c\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.binomial\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.bytes\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.chisquare\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.choice\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.dirichlet\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.exponential\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.f\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.gamma\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.geometric\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.pareto\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.gumbel\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.poisson\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.negative_binomial\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.normal\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.laplace\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.logistic\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.lognormal\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.logseries\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.power\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.ranf\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.randint\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.random\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.random_integers\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.random_sample\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.rayleigh\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.sample\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.standard_exponential\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.standard_gamma\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.standard_normal\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.uniform\u001b[0m\r\n\u001b[33mWARNING \u001b[0m \u001b[34mOverriding pythran description with argspec information for: numpy.random.weibull\u001b[0m\r\n\r\nError compiling Cython file:\r\n------------------------------------------------------------\r\n...\r\n    bint kh_exist_strbox(kh_strbox_t*, khiter_t) nogil\r\n\r\n    khuint_t kh_needed_n_buckets(khuint_t element_n) nogil\r\n\r\n\r\ninclude \"khash_for_primitive_helper.pxi\"\r\n^\r\n------------------------------------------------------------\r\n\r\n/tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0/pandas/_libs/khash.pxd:129:0: 'khash_for_primitive_helper.pxi' not found\r\n```\r\n</details>\r\n\r\nFull build log: [dev-python:pandas-2.1.0:20230831-050223.log](https://github.com/pandas-dev/pandas/files/12482393/dev-python.pandas-2.1.0.20230831-050223.log)\r\n\r\n```\r\n$ find /tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/ -name '*.pxi'\r\n/tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/pandas/_libs/intervaltree.pxi\r\n/tmp/portage/dev-python/pandas-2.1.0/work/pandas-2.1.0-python3_10/pandas/_libs/sparse_op_helper.pxi\r\n```\r\n\r\nIt looks that meson files do not declare dependencies between `khash_for_primitive_helper.pxi` and `khash.pxd` files, so the former isn't necessarily created before the latter is attempt to be compiled.", "patch": ""}
{"instance_id": "pallets__flask-1224", "file_changes": [{"file": "flask/views.py", "changes": {}}], "repo": "pallets/flask", "base_commit": "f88765d504ce2fa9bc3926c76910b11510522892", "problem_statement": "Starting up a public server.\n\nI ran into this problem today with one of my applications trying to make it public to my local network.  \n\nC:\\Users\\Savion\\Documents\\GitHub\\Example-Flask-Website>flask\\Scripts\\python run.\npy\n- Running on http://127.0.0.1:5000/\n- Restarting with reloader\n  10.101.37.124 - - [26/Oct/2014 15:51:23] \"GET / HTTP/1.1\" 404 -\n- Running on http://0.0.0.0:5000/\n  10.101.37.124 - - [26/Oct/2014 15:51:38] \"GET / HTTP/1.1\" 404 -\n\nThe problem that i run into is the fact that this app continuously attempts to default to localhost. It is not until 2 Ctrl + C, that it goes to 0.0.0.0, then I still receive a 404 error in my browser.  I do have routes that are valid when running locally. I have tried to create a new virtualenv and i still recieve the same error, I reset the firewall rule on this application.  All effort that did not return rewarded.\n\nAny Ideas onto why my app makes an attempt to startup on the localhost first then moves over, but then returns a 404?", "patch": ""}
{"instance_id": "pallets__flask-834", "file_changes": [{"file": "flask/sessions.py", "changes": {"edited_modules": ["flask/sessions.py:SecureCookieSessionInterface", "flask/sessions.py:TaggedJSONSerializer"], "edited_entities": ["flask/sessions.py:SecureCookieSessionInterface.get_signing_serializer", "flask/sessions.py:TaggedJSONSerializer.dumps"]}}], "repo": "pallets/flask", "base_commit": "2d8a21c7321a9ead8e27208b49a18f4b8b27e2c1", "problem_statement": "How to get the serialized version of the session cookie in 0.10?\n\nIn version 0.9 I could simply get the value of the `session` like this: \n\n```\nflask.session.serialize()\n```\n\nBut after upgrading to 0.10 this is not working anymore.. what's the alternative? How can I get the session value?\n\n(`flask.request.cookies.get('session')` is not good for me, because I would like to get the session right after login, so it's not part of the request yet)", "patch": ""}
{"instance_id": "pallets__flask-4015", "file_changes": [{"file": "setup.py", "changes": {}}], "repo": "pallets/flask", "base_commit": "22d82e70b3647ed16c7d959a939daf533377382b", "problem_statement": "2.0.0: build requires ContextVar module\n\nSimple I cannot find it.\r\n```console\r\n+ /usr/bin/python3 setup.py build '--executable=/usr/bin/python3 -s'\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 4, in <module>\r\n    setup(\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/__init__.py\", line 144, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/usr/lib64/python3.8/distutils/core.py\", line 121, in setup\r\n    dist.parse_config_files()\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/dist.py\", line 689, in parse_config_files\r\n    parse_configuration(self, self.command_options,\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/config.py\", line 121, in parse_configuration\r\n    meta.parse()\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/config.py\", line 426, in parse\r\n    section_parser_method(section_options)\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/config.py\", line 399, in parse_section\r\n    self[name] = value\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/config.py\", line 184, in __setitem__\r\n    value = parser(value)\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/config.py\", line 515, in _parse_version\r\n    version = self._parse_attr(value, self.package_dir)\r\n  File \"/usr/lib/python3.8/site-packages/setuptools/config.py\", line 349, in _parse_attr\r\n    module = import_module(module_name)\r\n  File \"/usr/lib64/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/tkloczko/rpmbuild/BUILD/Flask-2.0.0/src/flask/__init__.py\", line 7, in <module>\r\n    from .app import Flask\r\n  File \"/home/tkloczko/rpmbuild/BUILD/Flask-2.0.0/src/flask/app.py\", line 19, in <module>\r\n    from werkzeug.local import ContextVar\r\nImportError: cannot import name 'ContextVar' from 'werkzeug.local' (/usr/lib/python3.8/site-packages/werkzeug/local.py)\r\n```", "patch": ""}
{"instance_id": "pallets__flask-2977", "file_changes": [], "repo": "pallets/flask", "base_commit": "43e2d7518d2e89dc7ed0b4ac49b2d20211ad1bfa", "problem_statement": "Serial port access problem in DEBUG mode.\n\n### Expected Behavior\r\n\r\nSending commands through the serial port.\r\n\r\n```python\r\napp = Flask(__name__)\r\nserialPort = serial.Serial(port = \"COM5\", baudrate=1000000,\r\n                           bytesize=8, timeout=2, stopbits=serial.STOPBITS_ONE)\r\n\r\nlamp = {\r\n   1 : {'name' : 'n1', 'state' : True},\r\n   2 : {'name' : 'n2', 'state' : True} \r\n}\r\n\r\n@app.route(\"/\")\r\ndef hello():\r\n   templateData = {\r\n      'lamp': lamp\r\n      }\r\n\r\n   \r\n   return render_template('main.html', **templateData)\r\n\r\n\r\n@app.route(\"/setPin/<action>\")\r\ndef action(action):\r\n\r\n   if action == \"on\":\r\n\r\n      serialPort.write(b\"n2c1111\\r\\n\")\r\n      lamp[1][\"state\"] = True\r\n\r\n   if action == \"off\":\r\n      serialPort.write(b\"n2c0000\\r\\n\")\r\n      lamp[1][\"state\"] = False\r\n\r\n\r\n   templateData = {\r\n      'lamp': lamp\r\n   }\r\n\r\n   return render_template('main.html', **templateData)\r\n\r\nif __name__ == \"__main__\":\r\n   app.run(host='0.0.0.0', port=5000, debug=True)\r\n```\r\n\r\n\r\n### Actual Behavior\r\n\r\nI can not access the serial port with  FLASK_ENV = development and FLASK_DEBUG = 1. Everything works fine with DEBUG mode disabled.\r\n\r\n```pytb\r\nFLASK_APP = app.py\r\nFLASK_ENV = development\r\nFLASK_DEBUG = 1\r\nIn folder C:/Users/user/PycharmProjects/Ho_server\r\nC:\\Users\\user\\Anaconda3\\python.exe -m flask run\r\n * Serving Flask app \"app.py\" (lazy loading)\r\n * Environment: development\r\n * Debug mode: on\r\n * Restarting with stat\r\n * Debugger is active!\r\n * Debugger PIN: 138-068-963\r\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\r\n127.0.0.1 - - [30/Oct/2018 10:49:27] \"GET /setPin/on HTTP/1.1\" 500 -\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 35, in reraise\r\n    raise value\r\n  File \"C:\\Users\\user\\PycharmProjects\\H_server\\app.py\", line 8, in <module>\r\n    bytesize=8, timeout=2, stopbits=serial.STOPBITS_ONE)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\serial\\serialwin32.py\", line 31, in __init__\r\n    super(Serial, self).__init__(*args, **kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\serial\\serialutil.py\", line 240, in __init__\r\n    self.open()\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\serial\\serialwin32.py\", line 62, in open\r\n    raise SerialException(\"could not open port {!r}: {!r}\".format(self.portstr, ctypes.WinError()))\r\nserial.serialutil.SerialException: could not open port 'COM5': PermissionError(13, 'Access is denied.', None, 5)\r\n```\r\n\r\n### Environment\r\n\r\n* Python version: 3.6.5\r\n* Flask version: 1.0.2", "patch": ""}
{"instance_id": "pallets__flask-1749", "file_changes": [{"file": "flask/json.py", "changes": {"edited_modules": ["flask/json.py:JSONEncoder"], "edited_entities": ["flask/json.py:JSONEncoder.default"]}}], "repo": "pallets/flask", "base_commit": "1a7fd980f8579bd7d7d53c812a77c1dc64be52ba", "problem_statement": "JSONEncoder and aware datetimes\n\nI was surprised to see that though flask.json.JSONEncoder accepts datetime objects, it ignores the timezone. I checked werkzeug.http.http_date and it can handle timezone aware dates just fine if they are passed in, but the JSONEncoder insists on transforming the datetime to a timetuple, like this\n\n `return http_date(o.timetuple())`\n\nThis means i have to convert all my dates to utc before encoding them, otherwise I should overwrite the dafault() method in the encoder. Can you help me understand why the encoder was made to function with naive dates only?\nThx", "patch": ""}
{"instance_id": "psf__requests-775", "file_changes": [{"file": "requests/models.py", "changes": {"edited_modules": ["requests/models.py:Request"], "edited_entities": ["requests/models.py:Request.__init__"]}}], "repo": "psf/requests", "base_commit": "27b55a74d7b9bd2f8c60fd0ee342bcbbf40e0a66", "problem_statement": "Content marked as consumed in 0.13.6\n\nContent is immediately marked as consumed in 0.13.6, causing calls to e.g. response.iter_content() to throw an error.\n\nTest code (tested with python 2.6):\n\n```\nimport requests\n\nr = requests.get('http://docs.python-requests.org/')\nif r._content_consumed:\n    print 'consumed'\nelse:\n    print 'not consumed'\n```\n\nIn 0.13.5 this prints:\nnot consumed\n\nIn 0.13.6 this prints:\nconsumed", "patch": ""}
{"instance_id": "psf__requests-4602", "file_changes": [], "repo": "psf/requests", "base_commit": "2de907ad778de270911acaffe93883f0e2729a4a", "problem_statement": "Chunk-encoded request doesn't recognize iter_content generator\n\nPassing a generator created by iter_content() as request data raises \"TypeError: sendall() argument 1 must be string or buffer, not generator\".\r\n\r\n## Expected Result\r\n\r\nThe POST request successfully delives the content from the GET request.\r\n\r\n## Actual Result\r\n\r\nA TypeError is raised:\r\n```\r\nTraceback (most recent call last):\r\n  File \"..\\test.py\", line 7, in <module>\r\n    PostForward(\"http://myhost/img/foo.png\", \"http://myotherhost/convert\")\r\n  File \"..\\test.py\", line 6, in PostForward\r\n    return requests.post(url=dst, data=data, headers={'Content-Length': length})\r\n  File \"C:\\Python27\\lib\\site-packages\\requests\\api.py\", line 112, in post\r\n    return request('post', url, data=data, json=json, **kwargs)\r\n  File \"C:\\Python27\\lib\\site-packages\\requests\\api.py\", line 58, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"C:\\Python27\\lib\\site-packages\\requests\\sessions.py\", line 508, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"C:\\Python27\\lib\\site-packages\\requests\\sessions.py\", line 618, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"C:\\Python27\\lib\\site-packages\\requests\\adapters.py\", line 440, in send\r\n    timeout=timeout\r\n  File \"C:\\Python27\\lib\\site-packages\\urllib3\\connectionpool.py\", line 601, in urlopen\r\n    chunked=chunked)\r\n  File \"C:\\Python27\\lib\\site-packages\\urllib3\\connectionpool.py\", line 357, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"C:\\Python27\\lib\\httplib.py\", line 1042, in request\r\n    self._send_request(method, url, body, headers)\r\n  File \"C:\\Python27\\lib\\httplib.py\", line 1082, in _send_request\r\n    self.endheaders(body)\r\n  File \"C:\\Python27\\lib\\httplib.py\", line 1038, in endheaders\r\n    self._send_output(message_body)\r\n  File \"C:\\Python27\\lib\\httplib.py\", line 886, in _send_output\r\n    self.send(message_body)\r\n  File \"C:\\Python27\\lib\\httplib.py\", line 858, in send\r\n    self.sock.sendall(data)\r\n  File \"C:\\Python27\\lib\\socket.py\", line 228, in meth\r\n    return getattr(self._sock,name)(*args)\r\nTypeError: sendall() argument 1 must be string or buffer, not generator\r\n```\r\n\r\n## Reproduction Steps\r\n\r\n```python\r\nimport requests\r\ndef PostForward(src, dst):\r\n\twith requests.get(url=src, stream=True) as srcResponse:\r\n\t\tlength = srcResponse.headers['Content-Length']\r\n\t\tdata = srcResponse.iter_content(1024)\r\n\t\treturn requests.post(url=dst, data=data, headers={'Content-Length': length})\r\nPostForward(\"http://myhost/img/foo.png\", \"http://myotherhost/convert\")\r\n```\r\n\r\n## System Information\r\n\r\n    $ python -m requests.help\r\n\r\n```\r\n{\r\n  \"chardet\": {\r\n    \"version\": \"3.0.4\"\r\n  },\r\n  \"cryptography\": {\r\n    \"version\": \"\"\r\n  },\r\n  \"idna\": {\r\n    \"version\": \"2.6\"\r\n  },\r\n  \"implementation\": {\r\n    \"name\": \"CPython\",\r\n    \"version\": \"2.7.14\"\r\n  },\r\n  \"platform\": {\r\n    \"release\": \"10\",\r\n    \"system\": \"Windows\"\r\n  },\r\n  \"pyOpenSSL\": {\r\n    \"openssl_version\": \"\",\r\n    \"version\": null\r\n  },\r\n  \"requests\": {\r\n    \"version\": \"2.18.4\"\r\n  },\r\n  \"system_ssl\": {\r\n    \"version\": \"100020bf\"\r\n  },\r\n  \"urllib3\": {\r\n    \"version\": \"1.22\"\r\n  },\r\n  \"using_pyopenssl\": false\r\n}\r\n```", "patch": ""}
{"instance_id": "psf__requests-3031", "file_changes": [], "repo": "psf/requests", "base_commit": "f17ef753d2c1f4db0d7f5aec51261da1db20d611", "problem_statement": "[WinError 10048] Only one usage of each socket address ...\n\nI notice that despite using requests.Session() - I still seem to be creating new connections/sockets which eventually exhaust (TIME_WAIT) and I get the following error:\n\n> [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted',))\n\n```\ns = requests.Session()\ndata = zip(url_routes, cycle(s))\ncalc_routes = pool.map(processRequest, data)\n\n```\n\nI posted a bit more [here](http://stackoverflow.com/questions/35793908/python-multiprocessing-associate-a-process-with-a-session), however not sure how to address this", "patch": ""}
{"instance_id": "psf__requests-3740", "file_changes": [{"file": "docs/user/quickstart.rst", "changes": {}}], "repo": "psf/requests", "base_commit": "6f659a41794045292b836859f1281d33eeed8260", "problem_statement": "File download weirdness\n\nI noticed this issue building conda recipes.  Conda uses requests to download files from the internet.\r\n\r\nThe file that is being fetched is: https://dakota.sandia.gov/sites/default/files/distributions/public/dakota-6.5-public.src.tar.gz\r\n(link found here: https://dakota.sandia.gov/download.html)\r\n\r\nDownloading with curl -O\r\nfilesize: 78MB\r\nmd5: 02c46e904d40bba6b308065db34c1ad7\r\n\r\nDownloading with urllib2 (from the standard library):\r\nfilesize: 78MB\r\nmd5: 02c46e904d40bba6b308065db34c1ad7\r\n\r\nDownloading with requests-2.12.1 (supplied with conda)\r\nfilesize: 248MB\r\nmd5: 41e4268140d850756812510512d8eee8\r\ntar -tf doesn't indicate any corruption.\r\n\r\nI'm not sure what is different with this particular URL, but the other  files I tried with requests worked.  I don't know where the extra 170MB is coming from?\r\n\r\ncode used to download files:\r\n```python\r\ndef download_file(url, fn):\r\n    r = requests.get(url, stream=True)\r\n    with open(fn, 'wb') as f:\r\n        for chunk in r.iter_content(chunk_size=1024): \r\n            if chunk:\r\n                f.write(chunk)\r\n\r\ndef download_urllib2(url, fn):\r\n    f = urllib2.urlopen(url)\r\n    with open(fn, 'wb') as fh:\r\n        for x in iter(lambda: f.read(1024), b''):\r\n            fh.write(x)\r\n```", "patch": ""}
{"instance_id": "psf__requests-3849", "file_changes": [{"file": "src/requests/api.py", "changes": {"edited_modules": ["src/requests/api.py:request"], "edited_entities": ["src/requests/api.py:request"]}}], "repo": "psf/requests", "base_commit": "62176a1ca7207db37273365b4691ed599203b828", "problem_statement": "Received response with content-encoding: gzip, but failed to decode it\n\n```python\r\nimport requests\r\n\r\nrequests.get('http://gett.bike/')\r\n```\r\nThis code raises the following exception:\r\n```python\r\nContentDecodingError: ('Received response with content-encoding: gzip, but failed to decode it.',\r\nerror('Error -3 while decompressing data: incorrect data check',))\r\n```\r\nArch linux x64\r\nrequests==2.13.0\r\npython=3.6.0", "patch": ""}
{"instance_id": "psf__requests-3015", "file_changes": [], "repo": "psf/requests", "base_commit": "057722af23edf3f69bf7bdfed7c6c32cbe1ce2e7", "problem_statement": "Ability to set timeout after response\n\nFor devs who use this great library, it would be very beneficial to be able to set the timeout AFTER initial connection. There are a few scenarios where this is useful but one of the main patterns/use cases is this:\n\n```\n\nimport requests\nimport socket\n\n# May or may not subclass threading.Thread\nclass Getter(object):\n    def __init__(self):\n        self.request = requests.get(url, stream=True)\n\n    def run(self):\n        with open(path, 'r+b') as file:\n\n            bytes_consumed = 0\n            while True:\n                try:\n\n                    chunk = self.request.raw.read(size)\n                    if not chunk:\n                        break\n                    chunk_length = len(chunk)\n\n                    file.write(chunk)\n                    bytes_consumed += chunk_length\n\n                except socket.timeout:\n                    # handle incomplete download by using range header next time, etc.\n```\n\nHandling incomplete downloads due to connection loss is common and especially important when downloading large or many files (or both). As you can see, this can be achieved in a fairly straightforward way. The issue is there is really no good way to write tests for this. Each method would involve OS specific code which would also be a no-go for CI services.\n\nWhat would be an option is the ability to set the timeout after establishing a connection. This way in a test you could do \"r.timeout = (None, 0.00001)\" and during reading it would simulate a timeout.\n\nTo my knowledge this is no way currently to inject a new Timeout class retroactively. Is this correct?", "patch": ""}
{"instance_id": "psf__requests-3774", "file_changes": [], "repo": "psf/requests", "base_commit": "1285f576ae0a848de27af10d917c19b60940d1fa", "problem_statement": "bad handshake error with ssl3\n\nI have an inhouse IIS server with ssl3 but an expired certificate, so I used requests without certificate verification and it was working fine with requests 2.11.1. But after I upgrade requests to 2.12.0, there was an error occured. \r\n\r\nthe code is:\r\n...\r\nrequests.get('https://10.192.8.89:8080/yps_report', verify=False)\r\n...\r\n\r\nerror message:\r\nTraceback (most recent call last):\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\contrib\\pyopenssl.py\", line 417, in wrap_socket\r\n    cnx.do_handshake()\r\n  File \"c:\\python35\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1426, in do_handshake\r\n    self._raise_ssl_error(self._ssl, result)\r\n  File \"c:\\python35\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1167, in _raise_ssl_error\r\n    raise SysCallError(-1, \"Unexpected EOF\")\r\nOpenSSL.SSL.SysCallError: (-1, 'Unexpected EOF')\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 594, in urlopen\r\n    chunked=chunked)\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 350, in _make_request\r\n    self._validate_conn(conn)\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 835, in _validate_conn\r\n    conn.connect()\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 323, in connect\r\n    ssl_context=context)\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\util\\ssl_.py\", line 324, in ssl_wrap_socket\r\n    return context.wrap_socket(sock, server_hostname=server_hostname)\r\n  File \"c:\\python35\\lib\\site-packages\\requests\\packages\\urllib3\\contrib\\pyopenssl.py\", line 424, in wrap_socket\r\n    raise ssl.SSLError('bad handshake: %r' % e)\r\nssl.SSLError: (\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\r\n...\r\n\r\nI tried  to downgrade requests to 2.11.1 and the error was gone. I have no idea how to fix this.\r\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.ssl_ import create_urllib3_context\n\n# This is the 2.11 Requests cipher string.\nCIPHERS = (\n    'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+HIGH:'\n    'DH+HIGH:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+HIGH:RSA+3DES:!aNULL:'\n    '!eNULL:!MD5'\n)\n\nclass DESAdapter(HTTPAdapter):\n    def init_poolmanager(self, *args, **kwargs):\n        context = create_urllib3_context(ciphers=CIPHERS)\n        kwargs['ssl_context'] = context\n        return super(HTTPAdapter, self).init_poolmanager(*args, **kwargs)\n\ns = requests.Session()\ns.mount('https://10.192.8.89', DESAdapter())", "patch": ""}
{"instance_id": "huggingface__transformers-1225", "file_changes": [{"file": "src/transformers/models/bert/modeling_bert.py", "changes": {"edited_modules": ["src/transformers/models/bert/modeling_bert.py:BertSelfAttention"], "edited_entities": ["src/transformers/models/bert/modeling_bert.py:BertSelfAttention.forward"]}}], "repo": "huggingface/transformers", "base_commit": "34f28b2a1342fd72c2e4d4e5613855bfb9f35d34", "problem_statement": "Bert output last hidden state\n\n## \u2753 Questions & Help\r\n\r\nHi,\r\n\r\nSuppose we have an utterance of length 24 (considering special tokens) and we right-pad it with 0 to max length of 64.\r\nIf we use Bert pertained model to get the last hidden states, the output would be of size [1, 64, 768]. \r\nCan we use just the first 24 as the hidden states of the utterance? I mean is it right to say that the output[0, :24, :] has all the required information?\r\nI realized that from index 24:64, the outputs has float values as well.", "patch": ""}
{"instance_id": "huggingface__transformers-27200", "file_changes": [{"file": "examples/pytorch/speech-recognition/README.md", "changes": {}}], "repo": "huggingface/transformers", "base_commit": "82c7e879876822864b5ceaf2c99eb01159266bcd", "problem_statement": "dataset download error in speech recognition examples\n\n### System Info\n\n- `transformers` version: 4.35.0.dev0\r\n- Platform: Linux-5.15.0-43-generic-x86_64-with-glibc2.17\r\n- Python version: 3.8.18\r\n- Huggingface_hub version: 0.17.3\r\n- Safetensors version: 0.4.0\r\n- Accelerate version: 0.24.1\r\n- Accelerate config:    not found\r\n- PyTorch version (GPU?): 1.10.0+cu111 (True)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Flax version (CPU?/GPU?/TPU?): not installed (NA)\r\n- Jax version: not installed\r\n- JaxLib version: not installed\r\n- Using GPU in script?: <fill in>\r\n- Using distributed or parallel set-up in script?: <fill in>\n\n### Who can help?\n\n@stevhliu and @MKhalusova\n\n### Information\n\n- [x] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [X] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\nCUDA_VISIBLE_DEVICES=0 python run_speech_recognition_ctc.py \\\r\n\t--dataset_name=\"common_voice\" \\\r\n\t--model_name_or_path=\"facebook/wav2vec2-large-xlsr-53\" \\\r\n\t--dataset_config_name=\"tr\" \\\r\n\t--output_dir=\"./wav2vec2-common_voice-tr-demo\" \\\r\n\t--overwrite_output_dir \\\r\n\t--num_train_epochs=\"15\" \\\r\n\t--per_device_train_batch_size=\"16\" \\\r\n\t--gradient_accumulation_steps=\"2\" \\\r\n\t--learning_rate=\"3e-4\" \\\r\n\t--warmup_steps=\"500\" \\\r\n\t--evaluation_strategy=\"steps\" \\\r\n\t--text_column_name=\"sentence\" \\\r\n\t--length_column_name=\"input_length\" \\\r\n\t--save_steps=\"400\" \\\r\n\t--eval_steps=\"100\" \\\r\n\t--layerdrop=\"0.0\" \\\r\n\t--save_total_limit=\"3\" \\\r\n\t--freeze_feature_encoder \\\r\n\t--gradient_checkpointing \\\r\n\t--chars_to_ignore , ? . ! - \\; \\: \\\" \u201c % \u2018 \u201d \ufffd \\\r\n\t--fp16 \\\r\n\t--group_by_length \\\r\n\t--push_to_hub \\\r\n\t--do_train --do_eval \n\n### Expected behavior\n\nWhen I run the default command, which set `dataset_name` as \"common_voice\", and I got a warning:\r\n```\r\n/home/xintong/.cache/huggingface/modules/datasets_modules/datasets/common_voice/220833898d6a60c50f621126e51fb22eb2dfe5244392c70dccd8e6e2f055f4bf/common_voice.py:634: FutureWarning: \r\n            This version of the Common Voice dataset is deprecated.\r\n            You can download the latest one with\r\n            >>> load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\")\r\n            \r\n  warnings.warn(\r\nGenerating train split:   0%|                                                                                                                                                   | 0/1831 [00:00<?, ? examples/s]\r\nTraceback (most recent call last):\r\n  File \"/home/xintong/miniconda3/envs/test/lib/python3.8/tarfile.py\", line 2578, in next\r\n    tarinfo = self.tarinfo.fromtarfile(self)\r\n  File \"/home/xintong/miniconda3/envs/test/lib/python3.8/tarfile.py\", line 1283, in fromtarfile\r\n    obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)\r\n  File \"/home/xintong/miniconda3/envs/test/lib/python3.8/tarfile.py\", line 1221, in frombuf\r\n    raise TruncatedHeaderError(\"truncated header\")\r\ntarfile.TruncatedHeaderError: truncated header\r\n```\r\nI modified this into `mozilla-foundation/common_voice_11_0`, it passed. \r\n```\r\nDownloading builder script: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8.13k/8.13k [00:00<00:00, 30.3MB/s]\r\nDownloading readme: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.4k/14.4k [00:00<00:00, 19.2MB/s]\r\nDownloading extra modules: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.44k/3.44k [00:00<00:00, 19.9MB/s]\r\nDownloading extra modules: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60.9k/60.9k [00:00<00:00, 304kB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.2k/12.2k [00:00<00:00, 25.6MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 568M/568M [00:07<00:00, 71.7MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 233M/233M [00:02<00:00, 78.6MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 285M/285M [00:04<00:00, 67.7MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.86M/4.86M [00:00<00:00, 73.3MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 109M/109M [00:01<00:00, 80.4MB/s]\r\nDownloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:21<00:00,  4.24s/it]\r\nExtracting data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:07<00:00,  1.54s/it]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.76M/5.76M [00:00<00:00, 56.0MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.17M/2.17M [00:00<00:00, 54.1MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.18M/2.18M [00:00<00:00, 64.3MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 32.8k/32.8k [00:00<00:00, 53.1MB/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 800k/800k [00:00<00:00, 59.8MB/s]\r\nDownloading data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:05<00:00,  1.01s/it]\r\nExtracting data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00<00:00, 2954.98it/s]\r\n```", "patch": ""}
{"instance_id": "huggingface__transformers-12081", "file_changes": [{"file": "src/transformers/models/gpt2/modeling_flax_gpt2.py", "changes": {"edited_modules": ["src/transformers/models/gpt2/modeling_flax_gpt2.py:FlaxGPT2LMHeadModule"], "edited_entities": ["src/transformers/models/gpt2/modeling_flax_gpt2.py:FlaxGPT2LMHeadModule"]}}, {"file": "src/transformers/models/gpt2/tokenization_gpt2_fast.py", "changes": {"edited_modules": ["src/transformers/models/gpt2/tokenization_gpt2_fast.py:GPT2TokenizerFast"], "edited_entities": ["src/transformers/models/gpt2/tokenization_gpt2_fast.py:GPT2TokenizerFast"]}}], "repo": "huggingface/transformers", "base_commit": "0e82f0cbc28b41b3d87a5e4069dc0e20bacc2494", "problem_statement": "GPT2 Flax \"TypeError: JAX only supports number and bool dtypes, got dtype object in array\"\n\nOn GPU\r\n\r\n```\r\n>>> from transformers import AutoTokenizer, FlaxAutoModelForCausalLM\r\n\r\n>>> tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\r\n>>> model = FlaxAutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\r\n>>> input_context = \"The dog\"\r\n>>> # encode input context\r\n>>> input_ids = tokenizer(input_context, return_tensors=\"jax\").input_ids\r\n>>> # generate candidates using sampling\r\n>>> outputs = model.generate(input_ids=input_ids, max_length=20, top_k=30, do_sample=True)\r\n\r\nTypeError: JAX only supports number and bool dtypes, got dtype object in array\r\n```\r\n\r\n@patrickvonplaten @patil-suraj", "patch": ""}
{"instance_id": "huggingface__transformers-10079", "file_changes": [{"file": "src/transformers/tokenization_utils_fast.py", "changes": {"edited_modules": ["src/transformers/tokenization_utils_fast.py:PreTrainedTokenizerFast"], "edited_entities": ["src/transformers/tokenization_utils_fast.py:PreTrainedTokenizerFast._save_pretrained"]}}], "repo": "huggingface/transformers", "base_commit": "322037e842e5e89080918c824998c17722df6f19", "problem_statement": "Unclear error \"NotImplementedError:  \"while saving tokenizer. How fix it?\n\nHere is my tokenizer code and how I save it to a json file\" /content/bert-datas7.json\"\r\n\r\n````\r\nfrom tokenizers import normalizers\r\nfrom tokenizers.normalizers import Lowercase, NFD, StripAccents\r\n\r\nbert_tokenizer.pre_tokenizer = Whitespace()\r\n\r\nfrom tokenizers.processors import TemplateProcessing\r\n\r\nbert_tokenizer.post_processor = TemplateProcessing(\r\n    single=\"[CLS] $A [SEP]\",\r\n    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\r\n    special_tokens=[\r\n        (\"[CLS]\", 1),\r\n        (\"[SEP]\", 2),\r\n        (\"[PAD]\", 3),\r\n    ],\r\n    \r\n)\r\nfrom tokenizers.trainers import WordPieceTrainer\r\n\r\ntrainer = WordPieceTrainer(\r\n    vocab_size=30522, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], pad_to_max_length=True\r\n)\r\nfiles = [f\"/content/For_ITMO.txt\" for split in [\"test\", \"train\", \"valid\"]]\r\nbert_tokenizer.train(trainer, files)\r\n\r\nmodel_files = bert_tokenizer.model.save(\"data\", \"/content/For_ITMO.txt\")\r\n\r\nbert_tokenizer.model = WordPiece.from_file(*model_files, unk_token=\"[UNK]\",  pad_to_max_length=True)\r\n\r\nbert_tokenizer.save(\"/content/bert-datas7.json\") \r\n````\r\n\r\nWhen I output tokenizer name_or_path = nothing is displayed. This is normal?\r\n\r\n\r\n````\r\ntokenizer = PreTrainedTokenizerFast(tokenizer_file='/content/bert-datas7.json')\r\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\r\n\r\nprint(tokenizer)\r\n>>> PreTrainedTokenizerFast(name_or_path='', vocab_size=1435, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'pad_token': '[PAD]'})\r\n````\r\nAlso, when I try to save my tokenizer, I get an error without explanation. How can I rewrite the code so that all this???\r\n#9658 \r\n#10039 \r\n[For_ITMO.txt-vocab (1) (1).txt](https://github.com/huggingface/transformers/files/5945659/For_ITMO.txt-vocab.1.1.txt)\r\n  \r\n````\r\ntokenizer.save_pretrained(\"/content/tokennizerrrr\")\r\n\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-11-efc48254a528> in <module>()\r\n----> 1 tokenizer.save_pretrained(\"/content/tokennizerrrr\")\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py in save_vocabulary(self, save_directory, filename_prefix)\r\n   2042             :obj:`Tuple(str)`: Paths to the files saved.\r\n   2043         \"\"\"\r\n-> 2044         raise NotImplementedError\r\n   2045 \r\n   2046     def tokenize(self, text: str, pair: Optional[str] = None, add_special_tokens: bool = False, **kwargs) -> List[str]:\r\n\r\nNotImplementedError: \r\n````", "patch": ""}
{"instance_id": "huggingface__transformers-8403", "file_changes": [], "repo": "huggingface/transformers", "base_commit": "77a257fc210a56f1fd0d75166ecd654cf58111f3", "problem_statement": "[s2s finetune] huge increase in memory demands with --fp16 native amp\n\nWhile working on https://github.com/huggingface/transformers/issues/8353 I discovered that `--fp16` causes a 10x+ increase in gpu memory demands.\r\n\r\ne.g. I can run bs=12 w/o  `--fp16` \r\n\r\n```\r\ncd examples/seq2seq\r\nexport BS=12; rm -rf distilbart-cnn-12-6; python finetune.py --learning_rate=3e-5 --gpus 1 \\\r\n--do_train --do_predict --val_check_interval 0.25 --n_val 500 --num_train_epochs 2 --freeze_encoder \\\r\n--freeze_embeds --data_dir cnn_dm --max_target_length 142 --val_max_target_length=142 \\\r\n--train_batch_size=$BS --eval_batch_size=$BS --gradient_accumulation_steps 1 \\\r\n--model_name_or_path sshleifer/student_cnn_12_6 --tokenizer_name facebook/bart-large \\\r\n--warmup_steps 500 --output_dir distilbart-cnn-12-6\r\n\r\n```\r\nBut if I add:\r\n```\r\n--fp16\r\n```\r\n\r\n(w/ or w/o `--fp16_opt_level O1`)\r\n\r\nI get OOM even with bs=1 on a 8GB card and it barely manages on a 24GB card - I think the increase in memory demand is more than 10x.\r\n\r\nThe OOM either right away when it does the sanity check step, or after just 10-20 batches - so within a few secs\r\n\r\nThis is with pytorch-1.6. Same goes for pytorch-1.7 and 1.8-nightly.\r\n\r\nI wasn't able to test `--fp16` with pytorch-1.5, since I can't build apex on ubuntu-20.04. Without `--fp16` pytorch-1.5 works the same as pytorch-1.6 gpu memory-wise.\r\n\r\nI tested with pytorch-1.5 + apex and there is no problem there. Memory consumption is about half.\r\n\r\nHere is the table of the batch sizes that fit into a 8gb rtx-1070 (bigger BS leads to an instant OOM):\r\n\r\nbs | version\r\n---|--------\r\n12 | pt15\r\n20 | pt15+fp16\r\n12 | pt16\r\n1 | pt16+fp16\r\n\r\n\r\n\r\nIf you'd like to reproduce the problem here are the full steps:\r\n\r\n```\r\n# prep library\r\ngit clone https://github.com/huggingface/transformers\r\ncd transformers\r\npip install -e .[dev]\r\npip install -r examples/requirements.txt\r\ncd examples/seq2seq\r\n\r\n# prep data\r\nwget https://cdn-datasets.huggingface.co/summarization/cnn_dm_v2.tgz\r\ntar -xzvf cnn_dm_v2.tgz  # empty lines removed\r\nmv cnn_cln cnn_dm\r\n\r\n# run\r\nexport BS=12; \r\nrm -rf distilbart-cnn-12-6\r\npython finetune.py --learning_rate=3e-5 --gpus 1 \\\r\n--do_train --do_predict --val_check_interval 0.25 --n_val 500 --num_train_epochs 2 --freeze_encoder \\\r\n--freeze_embeds --data_dir cnn_dm --max_target_length 142 --val_max_target_length=142 \\\r\n--train_batch_size=$BS --eval_batch_size=$BS --gradient_accumulation_steps 1 \\\r\n--model_name_or_path sshleifer/student_cnn_12_6 --tokenizer_name facebook/bart-large \\\r\n--warmup_steps 500 --output_dir distilbart-cnn-12-6 \r\n```\r\n\r\nThis issue is to track the problem and hopefully finding a solution.\r\n\r\n@sshleifer", "patch": ""}
{"instance_id": "huggingface__transformers-17201", "file_changes": [{"file": "src/transformers/trainer.py", "changes": {"edited_modules": ["src/transformers/trainer.py:Trainer"], "edited_entities": ["src/transformers/trainer.py:Trainer.evaluation_loop"]}}], "repo": "huggingface/transformers", "base_commit": "1a688709b34b10bd372e3e0860c8d39d170ebf53", "problem_statement": "a memory leak in qqp prediction using bart\n\n### System Info\n\n```shell\n- `transformers` version: 4.19.0.dev0\r\n- Platform: Linux-5.11.0-43-generic-x86_64-with-glibc2.17\r\n- Python version: 3.8.10\r\n- Huggingface_hub version: 0.4.0\r\n- PyTorch version (GPU?): 1.10.1 (True)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Flax version (CPU?/GPU?/TPU?): not installed (NA)\r\n- Jax version: not installed\r\n- JaxLib version: not installed\r\n- Using GPU in script?: Yes\r\n- Using distributed or parallel set-up in script?: No\n```\n\n\n### Who can help?\n\n@sgugger\n\n### Information\n\n- [X] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [X] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\nI met the same issue #11011. If not using `--eval_accumulation_steps`, it caused CUDA out of memory. If using it, it caused out of RAM and killed by system.\r\n\r\nI only did prediction on GLUE QQP dataset using bart without fine-tuning. Considering QQP having a large test set (300k), the prediction got slower and slower, and finally got out of memory.\r\n\r\nThis is the script to reproduce:\r\n```\r\nCUDA_VISIBLE_DEVICES=0 python run_glue.py   --model_name_or_path facebook/bart-large   --task_name qqp   --output_dir bart-large_qqp --eval_accumulation_steps 100 --do_predict --per_device_eval_batch_size 24\r\n```\n\n### Expected behavior\n\n```shell\nPrediction without out memory.\n```", "patch": ""}
{"instance_id": "huggingface__transformers-28435", "file_changes": [{"file": "src/transformers/modeling_utils.py", "changes": {"edited_modules": ["src/transformers/modeling_utils.py:PreTrainedModel"], "edited_entities": ["src/transformers/modeling_utils.py:PreTrainedModel.from_pretrained"]}}, {"file": "src/transformers/utils/quantization_config.py", "changes": {"edited_modules": ["src/transformers/utils/quantization_config.py:BitsAndBytesConfig"], "edited_entities": ["src/transformers/utils/quantization_config.py:BitsAndBytesConfig"]}}], "repo": "huggingface/transformers", "base_commit": "cef2e40e0f8eaad13b8d32817a48fdddc32eb2a5", "problem_statement": "Skip some weights for load_in_8bit and keep them as fp16/32?\n\n### Feature request\r\n\r\nHello,\r\n\r\nI am looking for a way to load a checkpoint where I only load some of the weights in 8 bit and keep others in 16/32 bit.\r\n\r\n### Motivation\r\n\r\nMy motivation is for vision-language models like Llava or BLIP2 where I want to load the LLM part in 8 bit but the image encoder should stay in 16 bit because I notice performance degradations with CLIP in 8 bit and also want to be able to train this part without LoRA.\r\n\r\nAs far as I can see in the documentation, issues and with Google (both here and for bitsandbytes), there is currently no way to do this.\r\n\r\n### Your contribution\r\n\r\nI can in theory help implement something like this but I don't know where and how in the code this should be done.", "patch": ""}
{"instance_id": "huggingface__transformers-14938", "file_changes": [], "repo": "huggingface/transformers", "base_commit": "705ca7f21b2b557e0cfd5d0853b297fa53489d20", "problem_statement": "Question: Object of type EncoderDecoderConfig is not JSON serializable\n\nHi.\r\nAn error occurred when I used Trainer to train and save EncoderDecoderModel.\r\n\r\n```python\r\n  File \"/home/jwli/ljw/study/hotpotqa/roberta_seq2seq/roberta_for_seq2seq.py\", line 482, in <module>\r\n    run(model_args, data_args, training_args)\r\n  File \"/home/jwli/ljw/study/hotpotqa/roberta_seq2seq/roberta_for_seq2seq.py\", line 465, in run\r\n    train_result = trainer.train(resume_from_checkpoint=checkpoint)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/trainer.py\", line 1391, in train\r\n    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/trainer.py\", line 1495, in _maybe_log_save_evaluate\r\n    self._save_checkpoint(model, trial, metrics=metrics)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/trainer.py\", line 1557, in _save_checkpoint\r\n    self.save_model(output_dir)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/trainer.py\", line 1961, in save_model\r\n    self._save(output_dir)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/trainer.py\", line 2009, in _save\r\n    self.model.save_pretrained(output_dir, state_dict=state_dict)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 1053, in save_pretrained\r\n    model_to_save.config.save_pretrained(save_directory)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/configuration_utils.py\", line 416, in save_pretrained\r\n    self.to_json_file(output_config_file, use_diff=True)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/configuration_utils.py\", line 739, in to_json_file\r\n    writer.write(self.to_json_string(use_diff=use_diff))\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/site-packages/transformers/configuration_utils.py\", line 725, in to_json_string\r\n    return json.dumps(config_dict, indent=2, sort_keys=True) + \"\\n\"\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/json/__init__.py\", line 238, in dumps\r\n    **kw).encode(obj)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/json/encoder.py\", line 201, in encode\r\n    chunks = list(chunks)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/json/encoder.py\", line 431, in _iterencode\r\n    yield from _iterencode_dict(o, _current_indent_level)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/json/encoder.py\", line 405, in _iterencode_dict\r\n    yield from chunks\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/json/encoder.py\", line 438, in _iterencode\r\n    o = _default(o)\r\n  File \"/home/jwli/anaconda3/envs/study/lib/python3.7/json/encoder.py\", line 179, in default\r\n    raise TypeError(f'Object of type {o.__class__.__name__} '\r\nTypeError: Object of type EncoderDecoderConfig is not JSON serializable\r\n```\r\nMy model and Config define the following code. \r\n```python\r\n    tokenizer = RobertaTokenizerFast.from_pretrained(model_args.tokenizer_name)\r\n    encoder_config = RobertaConfig.from_pretrained(model_args.encoder_model_name_or_path)\r\n    decoder_config = RobertaConfig.from_pretrained(model_args.decoder_model_name_or_path)\r\n    encoder_decoder_config = EncoderDecoderConfig.from_encoder_decoder_configs(encoder_config, decoder_config)\r\n    model = RobertaForSeq2Seq.from_encoder_decoder_pretrained(model_args.encoder_model_name_or_path,\r\n                                                              model_args.decoder_model_name_or_path,\r\n                                                              config=encoder_decoder_config, tie_encoder_decoder=True)\r\n    model.config.decoder_start_token_id = tokenizer.bos_token_id\r\n    model.config.eos_token_id = tokenizer.eos_token_id\r\n    model.config.max_length = 64\r\n    model.config.early_stopping = True\r\n    model.config.no_repeat_ngram_size = 3\r\n    model.config.length_penalty = 2.0\r\n    model.config.num_beams = 4\r\n    model.config.pad_token_id = tokenizer.pad_token_id\r\n```\r\nThis error occurred because EncoderDecoderConfig cannot be converted to json format. But I don't know how to modify it.\r\n```python\r\nERROR OCCURRED:\r\n\r\n        if use_diff is True:\r\n            config_dict = self.to_diff_dict()\r\n        else:\r\n            config_dict = self.to_dict()\r\n        return json.dumps(config_dict, indent=2, sort_keys=True) + \"\\n\"\r\n```\r\n\r\nI look forward to your help! Thanks!\r\n @jplu  @patrickvonplaten", "patch": ""}
{"instance_id": "huggingface__transformers-653", "file_changes": [{"file": "pytorch_pretrained_bert/modeling.py", "changes": {"edited_modules": ["pytorch_pretrained_bert/modeling.py:BertPreTrainedModel"], "edited_entities": ["pytorch_pretrained_bert/modeling.py:BertPreTrainedModel.init_bert_weights"]}}], "repo": "huggingface/transformers", "base_commit": "45d21502f0b67eb8a5ad244d469dcc0dfb7517a7", "problem_statement": "Different Results from version 0.4.0 to version 0.5.0\n\nHi, I found the results after training is different from version 0.4.0 to version 0.5.0. I have fixed all initialization to reproduce the results. And I also test version 0.2.0 and 0.3.0, the results are the same to version 0.4.0, but from version 0.5.0 +, the results is different. I am wondering that have you trained a new model, so the weights changed?", "patch": ""}
{"instance_id": "huggingface__transformers-10202", "file_changes": [{"file": "src/transformers/tokenization_utils_base.py", "changes": {"edited_modules": ["src/transformers/tokenization_utils_base.py:SpecialTokensMixin"], "edited_entities": ["src/transformers/tokenization_utils_base.py:SpecialTokensMixin.add_special_tokens"]}}], "repo": "huggingface/transformers", "base_commit": "1c8c2d9ab34b8c8d326db9e0608f8e54cfccb885", "problem_statement": "Fast Tokenizers instantiated via vocab/merge files do not respect skip_special_tokens=True\n\n## Environment info\r\n- `transformers` version: 4.3.2\r\n- Platform: macOS-11.2.1-x86_64-i386-64bit\r\n- Python version: 3.9.1\r\n- PyTorch version (GPU?): 1.7.1 (False)\r\n- Tensorflow version (GPU?): not installed (NA)\r\n- Using GPU in script?: No\r\n- Using distributed or parallel set-up in script?: No\r\n\r\n## Information\r\n\r\nSee title; this issue does not reproduce with slow tokenizers. Does not reproduce with serialized tokenizers.\r\n\r\nFound while investigating https://github.com/minimaxir/aitextgen/issues/88\r\n\r\n## To reproduce\r\n\r\nUsing [gpt2_merges.txt](https://github.com/minimaxir/aitextgen/blob/master/aitextgen/static/gpt2_merges.txt) and [gpt2_vocab.json](https://github.com/minimaxir/aitextgen/blob/master/aitextgen/static/gpt2_vocab.json) as linked:\r\n\r\n```py\r\nfrom transformers import AutoModelForCausalLM, GPT2Tokenizer, GPT2TokenizerFast\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\r\n\r\noutputs = model.generate(max_length=40)\r\n\r\n# tensor([[50256,   383,   471,    13,    50,    13,  2732,   286,  4796,   468,\r\n#           587, 10240,   262,  1918,   286,   257,  1966,  5349,  5797,   508,\r\n#           373,  2823,   290,  2923,   416,   257, 23128,   287,   262,   471,\r\n#            13,    50,    13, 13241,   319,  3583,    13,   198,   198,   198]])\r\n\r\ntokenizer_fast = GPT2TokenizerFast(vocab_file=\"gpt2_vocab.json\", merges_file=\"gpt2_merges.txt\")\r\ntokenizer_fast.decode(outputs[0], skip_special_tokens=True)\r\n\r\n# '<|endoftext|> The U.S. Department of Justice has been investigating the death of a former FBI agent who was shot and killed by a gunman in the U.S. Capitol on Wednesday.\\n\\n\\n'\r\n\r\ntokenizer_slow = GPT2Tokenizer(vocab_file=\"gpt2_vocab.json\", merges_file=\"gpt2_merges.txt\")\r\ntokenizer_slow.decode(outputs[0], skip_special_tokens=True)\r\n\r\n# ' The U.S. Department of Justice has been investigating the death of a former FBI agent who was shot and killed by a gunman in the U.S. Capitol on Wednesday.\\n\\n\\n'\r\n\r\n```", "patch": ""}
{"instance_id": "huggingface__transformers-32661", "file_changes": [{"file": "src/transformers/models/roberta/configuration_roberta.py", "changes": {"edited_modules": ["src/transformers/models/roberta/configuration_roberta.py:RobertaConfig"], "edited_entities": ["src/transformers/models/roberta/configuration_roberta.py:RobertaConfig"]}}], "repo": "huggingface/transformers", "base_commit": "5bcbdff15922b1d0eeb035879630ca61c292122a", "problem_statement": "RoBERTa config defaults are inconsistent with fairseq implementation\n\n### System Info\n\n python 3.12, transformers 4.14, latest mac os\n\n### Who can help?\n\n_No response_\n\n### Information\n\n- [ ] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\nfrom transformers import RobertaConfig\r\nmy_config = RobertaConfig()\r\nroberta_config = RobertaConfig.from_pretrained(\"roberta-base\")\r\n\r\nassert (\r\n  my_config.max_position_embeddings == roberta_config.max_position_embeddings\r\n), \"%d %d\" % (my_config.max_position_embeddings, roberta_config.max_position_embeddings)\n\n### Expected behavior\n\nThe config defaults should correspond the the base model?\r\n\r\nThis is an implementation detail, but it did send me on a debugging spree as it hid as a sticky CUDA assertion error.\r\n```Assertion `srcIndex < srcSelectDimSize` failed```\r\n\r\nThe problem is that by default if you create the position_ids yourself or if you let transformers roberta_modelling take care of it (it also does it the way fairseq implemented it), it will create indeces that are out of bounds with the default configuration as everything is shifted by pad_token_id.\r\n\r\nThis is more of a heads up. Do transformers generally provide defaults aligned with the original models, or are the defaults here meant to be agnostic of that?", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-2475", "file_changes": [{"file": "sklearn/cross_validation.py", "changes": {"edited_modules": ["sklearn/cross_validation.py:cross_val_score"], "edited_entities": ["sklearn/cross_validation.py:cross_val_score"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "f7026b04f5e5909aa15848b25de2becd675871a9", "problem_statement": "Multinomial Naive Bayes: Scikit and Weka have different results\n\nHi All,\nI used the sklearn.naive_bayes.MultinomialNB on a toy example.\nComparing the results with WEKA, I've noticed a quite different AUC.\nScikit (0.579) - Weka (0.664)", "patch": ""}
{"instance_id": "scikit-learn__scikit-learn-8470", "file_changes": [{"file": "sklearn/preprocessing/_encoders.py", "changes": {"edited_modules": ["sklearn/preprocessing/_encoders.py:OneHotEncoder"], "edited_entities": ["sklearn/preprocessing/_encoders.py:OneHotEncoder"]}}], "repo": "scikit-learn/scikit-learn", "base_commit": "0ab5c678bba02888b62b777b4c757e367b3458d5", "problem_statement": "How to let gbdt = GradientBoostingRegressor(), gbdt.fit(X_feature, X_label) know whether the feature of input X is categorical or numerical?", "patch": ""}
{"instance_id": "pandas-dev__pandas-3209", "file_changes": [], "repo": "pandas-dev/pandas", "base_commit": "184f2dba255f279697cb1d7567428b3e6403c2d0", "problem_statement": "BUG: read_csv: dtype={'id' : np.str}: Datatype not understood\n\nI have a CSV with several columns. The first of which is a field called `id` with entries of the type `0001`, `0002`, etc. \n\nWhen loading this file, the following works:\n\n``` python\npd.read_csv(my_path, dtype={'id' : np.int})\n```\n\nbut the following doesn't:\n\n``` python\npd.read_csv(my_path, dtype={'id' : np.str})\n```\n\nnor does this either:\n\n``` python\npd.read_csv(my_path, dtype={'id' : str})\n```\n\nI get: `Datatype not understood`\n\nThis is with `pandas-0.10.1`", "patch": ""}
